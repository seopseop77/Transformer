{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["PDK-TIgSpuKN","At76I0aX3hk7","uh1W-aF21n9f","j-dsSzJF9ozE","HDsnbpXxIqx6","cMbY3HxBKtoK","GWmNMEj2QWTV","0m_717bEVpaZ","jaeMy2zret51"],"machine_shape":"hm","authorship_tag":"ABX9TyNYEsSL/uN6Ysk33S6vto2I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 0. 준비 단계"],"metadata":{"id":"PDK-TIgSpuKN"}},{"cell_type":"markdown","source":["## 패키지 설치 & 버전 확인"],"metadata":{"id":"5l6Z3C4krba9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KcMGq2wRpVtI","executionInfo":{"status":"ok","timestamp":1761289771480,"user_tz":-540,"elapsed":4021,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"58404213-50f8-415a-8826-68f7b5df4a1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip -q install torch sentencepiece sacrebleu tqdm PyYAML"]},{"cell_type":"code","source":["import torch, platform\n","print(\"PyTorch:\", torch.__version__)\n","print(\"Python:\", platform.python_version())\n","print(\"CUDA available:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU name:\", torch.cuda.get_device_name(0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1lXXS9UqRC6","executionInfo":{"status":"ok","timestamp":1761289775137,"user_tz":-540,"elapsed":3650,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"100efbf3-ca48-45f0-fb2a-07007c81d4c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch: 2.8.0+cu126\n","Python: 3.12.12\n","CUDA available: True\n","GPU name: NVIDIA L4\n"]}]},{"cell_type":"markdown","source":["## 폴더 구조 설정"],"metadata":{"id":"5SnaxLH_rdgJ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QV6j3VayrLZ0","executionInfo":{"status":"ok","timestamp":1761289794384,"user_tz":-540,"elapsed":19245,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"f8138430-8d4c-4028-e48e-74f2a5cb73ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from pathlib import Path\n","import torch, random, numpy as np\n","BASE = Path('/content/drive/MyDrive/서울대/snuann/Transform')  # 기본 폴더명 설정 필요\n","DATA_DIR = BASE / \"data\"\n","RAW_DIR  = DATA_DIR / \"raw\"\n","SPM_DIR  = DATA_DIR / \"spm\"\n","CACHE_DIR = DATA_DIR / \"cache\"\n","CKPT_DIR = BASE / \"ckpt\"\n","RUNS_DIR = BASE / \"runs\"\n","OUT_DEC_DIR = BASE / \"outputs\" / \"decode\"\n","OUT_EVAL_DIR = BASE / \"outputs\" / \"eval\"\n","\n","for p in [RAW_DIR, SPM_DIR, CACHE_DIR, CKPT_DIR, RUNS_DIR, OUT_DEC_DIR, OUT_EVAL_DIR]:\n","    p.mkdir(parents=True, exist_ok=True)\n","\n","# 재현성 시드 & 디바이스\n","def set_seed(seed: int = 42):\n","    random.seed(seed); np.random.seed(seed)\n","    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","SEED = 42\n","set_seed(SEED)\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(\"BASE        :\", BASE.resolve())\n","print(\"DATA/raw    :\", RAW_DIR.resolve())\n","print(\"DATA/spm    :\", SPM_DIR.resolve())\n","print(\"CKPT        :\", CKPT_DIR.resolve())\n","print(\"DEVICE      :\", DEVICE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdW9Y1vVq7GH","executionInfo":{"status":"ok","timestamp":1761289795776,"user_tz":-540,"elapsed":1390,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"b224eeac-6c13-45b1-ffd6-f471d30ecefd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BASE        : /content/drive/MyDrive/서울대/snuann/Transform\n","DATA/raw    : /content/drive/MyDrive/서울대/snuann/Transform/data/raw\n","DATA/spm    : /content/drive/MyDrive/서울대/snuann/Transform/data/spm\n","CKPT        : /content/drive/MyDrive/서울대/snuann/Transform/ckpt\n","DEVICE      : cuda\n"]}]},{"cell_type":"markdown","source":["## Tokenizer 준비"],"metadata":{"id":"zPAfg3wxtvKe"}},{"cell_type":"code","source":["# === SentencePiece 공용 BPE 학습 ===\n","import sentencepiece as spm\n","\n","SPM_MODEL = SPM_DIR / \"spm.model\"\n","SPM_VOCAB = SPM_DIR / \"spm.vocab\"\n","INPUT_EN = RAW_DIR / \"train.en\" # 별도 파일에서 생성\n","INPUT_KO = RAW_DIR / \"train.ko\" # 각 문장이 대응되며 한 줄씩 쓰여져 있는 형태\n","\n","PAD_ID = 0\n","BOS_ID = 1\n","EOS_ID = 2\n","UNK_ID = 3\n","\n","if not SPM_MODEL.exists():\n","    arg_str = \" \".join([\n","        f\"--input={INPUT_EN},{INPUT_KO}\",\n","        f\"--model_prefix={SPM_DIR/'spm'}\",    # 모델 저장 경로\n","        \"--model_type=bpe\",\n","        \"--vocab_size=16000\",                 # 필요시 8k~32k로 조절\n","        \"--character_coverage=0.9995\",\n","        \"--normalization_rule_name=nmt_nfkc\", # 유니코드 정규화\n","        \"--byte_fallback=true\",               # 희귀 문자 안전 처리(OOV 방지)\n","        \"--input_sentence_size=10000000\",\n","        \"--shuffle_input_sentence=true\",\n","        f\"--pad_id={PAD_ID}\", # Padding Token\n","        f\"--bos_id={BOS_ID}\", # 시작 Token\n","        f\"--eos_id={EOS_ID}\", # 끝 Token\n","        f\"--unk_id={UNK_ID}\"\n","    ])\n","    spm.SentencePieceTrainer.Train(arg_str)\n","    print(\"SPM trained:\", SPM_MODEL)\n","else:\n","    print(\"SPM exists:\", SPM_MODEL)\n"],"metadata":{"id":"7j_FOGI_t78g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761289795963,"user_tz":-540,"elapsed":179,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"78e72eb0-e478-4aa3-fb1a-3d76895b757c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SPM exists: /content/drive/MyDrive/서울대/snuann/Transform/data/spm/spm.model\n"]}]},{"cell_type":"code","source":["# === 간단 래퍼 & 스모크 테스트 ===\n","class SPMTokenizer:\n","    def __init__(self, model_path):\n","        self.sp = spm.SentencePieceProcessor()\n","        self.sp.load(str(model_path))\n","    def encode(self, text):\n","        return self.sp.encode(text, out_type=int)\n","    def decode(self, ids):\n","        # 우리가 붙인 특수토큰은 제거하고 복원\n","        ids = [i for i in ids if i not in (PAD_ID, BOS_ID, EOS_ID)]\n","        return self.sp.decode(ids)\n","    @property\n","    def vocab_size(self):\n","        return self.sp.get_piece_size()\n","\n","tok = SPMTokenizer(SPM_MODEL)\n","print(\"vocab_size:\", tok.vocab_size)\n","\n","# 샘플 인코딩/디코딩 확인\n","sample_en = \"This is a small tokenizer test.\"\n","sample_ko = \"이것은 작은 토크나이저 테스트입니다.\"\n","en_ids = [BOS_ID] + tok.encode(sample_en) + [EOS_ID]\n","ko_ids = [BOS_ID] + tok.encode(sample_ko) + [EOS_ID]\n","print(\"EN ids (head):\", en_ids[:12], \"... len=\", len(en_ids))\n","print(\"KO ids (head):\", ko_ids[:12], \"... len=\", len(ko_ids))\n","print(\"EN decoded:\", tok.decode(en_ids))\n","print(\"KO decoded:\", tok.decode(ko_ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNShohj9rI8f","executionInfo":{"status":"ok","timestamp":1761289797275,"user_tz":-540,"elapsed":1310,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"157a767d-d4f0-42e3-f5d6-f505f8f15d76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["vocab_size: 16000\n","EN ids (head): [1, 974, 312, 262, 1675, 290, 14914, 272, 477, 268, 2299, 14900] ... len= 13\n","KO ids (head): [1, 5682, 4880, 1767, 15178, 14954, 14904, 15096, 10273, 955, 14900, 2] ... len= 12\n","EN decoded: This is a small tokenizer test.\n","KO decoded: 이것은 작은 토크나이저 테스트입니다.\n"]}]},{"cell_type":"markdown","source":["# 1. 데이터 로드 & 모델 생성"],"metadata":{"id":"At76I0aX3hk7"}},{"cell_type":"markdown","source":["## Dataset 준비"],"metadata":{"id":"ShlmgWMo8AS8"}},{"cell_type":"code","source":["# # === Token length distribution for En↔Ko with your SentencePiece ===\n","# # - 입력: data/raw/train.en, data/raw/train.ko, data/spm/spm.model\n","# # - 출력: 길이 통계(퍼센타일) + 히스토그램 + 권장 max_src_len/max_tgt_len\n","\n","# from pathlib import Path\n","# import math\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# import sentencepiece as spm\n","\n","# # ---- 옵션 ----\n","# ADD_BOS_EOS = True      # BOS/EOS 붙였을 때 길이도 함께 리포팅\n","# SAMPLE_MAX = None       # 샘플링 개수 제한. None=전체, 예: 200000\n","# BINS = 80               # 히스토그램 bin 수\n","# PERCENTILES = [50, 90, 95, 98, 99, 100]\n","\n","# assert INPUT_EN.exists() and INPUT_KO.exists(), \"train.en / train.ko 파일이 필요합니다.\"\n","# assert SPM_MODEL.exists(), \"SentencePiece 모델(spm.model)을 먼저 학습해 주세요.\"\n","\n","# sp = spm.SentencePieceProcessor()\n","# sp.load(str(SPM_MODEL))\n","\n","# def iter_lines(path, limit=None):\n","#     with open(path, encoding=\"utf-8\") as f:\n","#         for i, line in enumerate(f):\n","#             if limit is not None and i >= limit:\n","#                 break\n","#             yield line.strip()\n","\n","# def token_lengths(path):\n","#     lens_no_special = []\n","#     lens_with_special = []\n","#     for s in iter_lines(path, limit=SAMPLE_MAX):\n","#         ids = sp.encode(s, out_type=int)\n","#         lens_no_special.append(len(ids))\n","#         if ADD_BOS_EOS:\n","#             lens_with_special.append(len(ids) + 2)  # BOS+EOS\n","#     a_no = np.array(lens_no_special, dtype=np.int32)\n","#     a_with = np.array(lens_with_special, dtype=np.int32) if ADD_BOS_EOS else None\n","#     return a_no, a_with\n","\n","# en_no, en_with = token_lengths(INPUT_EN)\n","# ko_no, ko_with = token_lengths(INPUT_KO)\n","\n","# def describe(arr):\n","#     arr = np.asarray(arr, dtype=np.int32)\n","#     stats = {\n","#         \"min\": int(arr.min()), \"mean\": float(arr.mean()),\n","#         \"std\": float(arr.std()), \"max\": int(arr.max())\n","#     }\n","#     for p in PERCENTILES:\n","#         stats[f\"p{p}\"] = float(np.percentile(arr, p if p < 100 else 100))\n","#     return stats\n","\n","# en_stats_no = describe(en_no)\n","# ko_stats_no = describe(ko_no)\n","# en_stats_with = describe(en_with) if ADD_BOS_EOS else None\n","# ko_stats_with = describe(ko_with) if ADD_BOS_EOS else None\n","\n","# def suggest_max_len(stats):\n","#     # p98 근처를 권장 상한으로. 8 단위 올림(패딩/버킷팅에 유리)\n","#     return int(math.ceil(stats[\"p98\"] / 8.0) * 8)\n","\n","# suggest_src = suggest_max_len(en_stats_with if ADD_BOS_EOS else en_stats_no)\n","# suggest_tgt = suggest_max_len(ko_stats_with if ADD_BOS_EOS else ko_stats_no)\n","\n","# print(\"=== EN (source) lengths — WITHOUT specials ===\")\n","# print(en_stats_no)\n","# print(\"\\n=== KO (target) lengths — WITHOUT specials ===\")\n","# print(ko_stats_no)\n","# if ADD_BOS_EOS:\n","#     print(\"\\n=== EN (source) lengths — WITH BOS/EOS ===\")\n","#     print(en_stats_with)\n","#     print(\"\\n=== KO (target) lengths — WITH BOS/EOS ===\")\n","#     print(ko_stats_with)\n","\n","# print(\"\\n=== Suggested max lengths (≈ p98, rounded to /8) ===\")\n","# print(f\"max_src_len ≈ {suggest_src}\")\n","# print(f\"max_tgt_len ≈ {suggest_tgt}\")\n","\n","# # ---- Histograms ----\n","# plt.figure(figsize=(7,4))\n","# plt.hist(en_with if ADD_BOS_EOS else en_no, bins=BINS)\n","# plt.title(\"EN token length distribution (with BOS/EOS)\" if ADD_BOS_EOS else \"EN token length distribution\")\n","# plt.xlabel(\"tokens\"); plt.ylabel(\"sentences\")\n","# plt.show()\n","\n","# plt.figure(figsize=(7,4))\n","# plt.hist(ko_with if ADD_BOS_EOS else ko_no, bins=BINS)\n","# plt.title(\"KO token length distribution (with BOS/EOS)\" if ADD_BOS_EOS else \"KO token length distribution\")\n","# plt.xlabel(\"tokens\"); plt.ylabel(\"sentences\")\n","# plt.show()\n","\n","# # ---- CDF (누적분포) ----\n","# plt.figure(figsize=(7,4))\n","# vals = np.sort(en_no); y = np.arange(1, len(vals)+1) / len(vals)\n","# plt.plot(vals, y, label=\"EN (no specials)\")\n","# if ADD_BOS_EOS:\n","#     vals2 = np.sort(en_with); y2 = np.arange(1, len(vals2)+1) / len(vals2)\n","#     plt.plot(vals2, y2, label=\"EN (with BOS/EOS)\")\n","# plt.title(\"EN token length CDF\"); plt.xlabel(\"tokens\"); plt.ylabel(\"cdf\"); plt.legend()\n","# plt.show()\n","\n","# plt.figure(figsize=(7,4))\n","# vals = np.sort(ko_no); y = np.arange(1, len(vals)+1) / len(vals)\n","# plt.plot(vals, y, label=\"KO (no specials)\")\n","# if ADD_BOS_EOS:\n","#     vals2 = np.sort(ko_with); y2 = np.arange(1, len(vals2)+1) / len(vals2)\n","#     plt.plot(vals2, y2, label=\"KO (with BOS/EOS)\")\n","# plt.title(\"KO token length CDF\"); plt.xlabel(\"tokens\"); plt.ylabel(\"cdf\"); plt.legend()\n","# plt.show()\n"],"metadata":{"id":"i1iXCQcQdbB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 필요 모듈\n","import torch, math, re\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import sentencepiece as spm\n","from pathlib import Path\n","\n","# ===== 토크나이저 래퍼 =====\n","SPM_MODEL = (SPM_DIR / \"spm.model\")\n","sp = spm.SentencePieceProcessor(); sp.load(str(SPM_MODEL))\n","\n","def sp_encode(text):  # SPM encode (BOS/EOS는 여기서 붙이지 않음)\n","    return sp.encode(text, out_type=int)\n","\n","def sp_decode(ids):  # 안전하게 특수토큰 제거 후 디코드\n","    ids = [i for i in ids if i not in (PAD_ID, BOS_ID, EOS_ID)]\n","    return sp.decode(ids)\n","\n","# ===== Dataset =====\n","class ParallelText(Dataset):\n","    def __init__(self, en_path, ko_path, max_src_len=96, max_tgt_len=80):\n","        self.en_lines = [l.rstrip(\"\\n\") for l in open(en_path, encoding=\"utf-8\")]\n","        self.ko_lines = [l.rstrip(\"\\n\") for l in open(ko_path, encoding=\"utf-8\")]\n","        assert len(self.en_lines) == len(self.ko_lines), \"en/ko line counts must match\"\n","        self.max_src_len = max_src_len\n","        self.max_tgt_len = max_tgt_len\n","\n","    def __len__(self): return len(self.en_lines)\n","\n","    def __getitem__(self, i):\n","        src_ids = [BOS_ID] + sp_encode(self.en_lines[i])[:self.max_src_len-2] + [EOS_ID]\n","        tgt_ids = [BOS_ID] + sp_encode(self.ko_lines[i])[:self.max_tgt_len-2] + [EOS_ID]\n","        return {\"src\": torch.tensor(src_ids, dtype=torch.long),\n","                \"tgt\": torch.tensor(tgt_ids, dtype=torch.long)}\n","\n","# ===== 마스크 유틸 (True == mask) =====\n","def make_padding_mask(lengths, max_len, device=None):\n","    rng = torch.arange(max_len, device=device).unsqueeze(0)        # [1,T]\n","    return rng >= lengths.unsqueeze(1)                              # [B,T]  True at PAD\n","\n","def make_causal_mask(T, device=None):\n","    i = torch.arange(T, device=device).unsqueeze(1)                 # [T,1]\n","    j = torch.arange(T, device=device).unsqueeze(0)                 # [1,T]\n","    return j > i                                                    # [T,T]  upper-tri True\n","\n","# ===== Collate: 패딩 & 마스크 & 디코더 입출 분리 =====\n","def collate_fn(batch):\n","    B = len(batch)\n","    device = torch.device(\"cpu\")\n","\n","    src_lens = torch.tensor([len(x[\"src\"]) for x in batch])\n","    tgt_lens = torch.tensor([len(x[\"tgt\"]) for x in batch])\n","    S, T = int(src_lens.max()), int(tgt_lens.max())\n","\n","    src_ids = torch.full((B, S), PAD_ID, dtype=torch.long)\n","    tgt_ids = torch.full((B, T), PAD_ID, dtype=torch.long)\n","    for i, x in enumerate(batch):\n","        src_ids[i, :len(x[\"src\"])] = x[\"src\"]\n","        tgt_ids[i, :len(x[\"tgt\"])] = x[\"tgt\"]\n","\n","    # 디코더 입력/라벨\n","    tgt_in  = tgt_ids[:, :-1]              # [B, T-1]  (BOS 포함, 마지막 제거)\n","    tgt_out = tgt_ids[:, 1:]               # [B, T-1]  (첫 토큰 제거, EOS 포함)\n","\n","    # 마스크(True==mask)\n","    src_pad  = make_padding_mask(src_lens, S, device=device)        # [B,S]\n","    tgt_pad  = make_padding_mask(tgt_lens, T, device=device)        # [B,T]\n","    causal   = make_causal_mask(T-1, device=device)                 # [T-1, T-1]\n","\n","    src_mask = src_pad.unsqueeze(1).unsqueeze(2)                    # [B,1,1,S]\n","    tgt_mask = (tgt_pad[:, :-1].unsqueeze(1).unsqueeze(2) |\n","                causal.unsqueeze(0).unsqueeze(1))                   # [B,1,T-1,T-1]\n","    mem_mask = src_pad.unsqueeze(1).unsqueeze(2).expand(B,1,T-1,S)  # [B,1,T-1,S]\n","\n","    return {\n","        \"src_ids\": src_ids, \"tgt_ids\": tgt_ids,\n","        \"tgt_in\": tgt_in, \"tgt_out\": tgt_out,\n","        \"src_lens\": src_lens, \"tgt_lens\": tgt_lens,\n","        \"src_mask\": src_mask, \"tgt_mask\": tgt_mask, \"mem_mask\": mem_mask,\n","    }\n","\n","# ===== DataLoader 만들기 & 스모크 테스트 =====\n","EN_TRAIN_PATH = RAW_DIR / \"train.en\"\n","KO_TRAIN_PATH = RAW_DIR / \"train.ko\"\n","max_src_len, max_tgt_len = 96, 80\n","batch_size = 64\n","valid_ratio = 0.2\n","\n","# 재현성을 위함\n","def _worker_init_fn(worker_id):\n","    worker_seed = SEED + worker_id\n","    np.random.seed(worker_seed); random.seed(worker_seed); torch.manual_seed(worker_seed)\n","\n","torch_dl_generator = torch.Generator()\n","torch_dl_generator.manual_seed(SEED)\n","\n","dataset = ParallelText(EN_TRAIN_PATH, KO_TRAIN_PATH, max_src_len, max_tgt_len)\n","n_total = len(dataset)\n","n_valid = int(n_total * valid_ratio)\n","n_train = n_total - n_valid\n","train_ds, valid_ds = random_split(dataset, [n_train, n_valid])\n","train_dl = DataLoader(\n","    train_ds, batch_size=64, shuffle=True,\n","    worker_init_fn=_worker_init_fn,\n","    generator=torch_dl_generator,\n","    collate_fn=collate_fn\n",")\n","valid_dl = DataLoader(\n","    valid_ds, batch_size=64, shuffle=False,\n","    worker_init_fn=_worker_init_fn,\n","    generator=torch_dl_generator,\n","    collate_fn=collate_fn\n",")\n","\n","batch = next(iter(train_dl))\n","for k, v in batch.items():\n","    if torch.is_tensor(v):\n","        print(f\"{k:9s}\", tuple(v.shape), v.dtype)\n"],"metadata":{"id":"1uWvptS17y0n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761289808253,"user_tz":-540,"elapsed":9756,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"385a6b65-cde0-4df9-9a02-139d41cb1022"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["src_ids   (64, 66) torch.int64\n","tgt_ids   (64, 69) torch.int64\n","tgt_in    (64, 68) torch.int64\n","tgt_out   (64, 68) torch.int64\n","src_lens  (64,) torch.int64\n","tgt_lens  (64,) torch.int64\n","src_mask  (64, 1, 1, 66) torch.bool\n","tgt_mask  (64, 1, 68, 68) torch.bool\n","mem_mask  (64, 1, 68, 66) torch.bool\n"]}]},{"cell_type":"markdown","source":["## 모델 구축"],"metadata":{"id":"8Qcu8qwHvQLl"}},{"cell_type":"markdown","source":["### Positional Encoding"],"metadata":{"id":"N7TEHfT-vR-e"}},{"cell_type":"code","source":["class SinePositionalEncoding(nn.Module):\n","    def __init__(self, d_model, n_tokens = 100):\n","        '''\n","        d_model: 하나의 단어를 표현하는 임베딩 벡터의 길이\n","        n_tokens: 가능한 최대 토큰의 수\n","        register_buffer : parameter가 아닌 고정된 값으로써 모델에 저장하는 것, 이후에 load로 모델을 불러올 떄도 불러와짐\n","        '''\n","        super().__init__()\n","        self.register_buffer('pos_table', self._get_encoding_table(d_model, n_tokens)) # pos_table이라는 속성에 저장하는 것\n","\n","    def _get_encoding_table(self, d_model, n_tokens):\n","        def _get_position_vector(pos):\n","            return np.array([pos / np.power(10000, 2*(i//2) / d_model) for i in range(d_model)])\n","\n","        sinusoid_table = np.array([_get_position_vector(pos) for pos in range(n_tokens)]) # (n_tokens, d_model)\n","        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n","        sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n","\n","        return torch.FloatTensor(sinusoid_table).unsqueeze(0)        # (1, n_tokens, d_model)\n","\n","    def forward(self, x):                                            # x : (B, T, d_model), T : 문장 내에서 토큰의 개수\n","        return x + self.pos_table[:,:x.size(1),:].clone().detach()   # (1, T, d_model)로 바뀌어서 BroadCasting됨\n","                                                                     # (참고) detach()는 grad 계산 대상에서 제외하기 위함. 사실 이미 register_buffer로 처리가 되있어서 이중 방어? 인 셈\n"],"metadata":{"id":"eR8rAoRNrV3u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Scaled Dot-Product Attention"],"metadata":{"id":"uh1W-aF21n9f"}},{"cell_type":"code","source":["class ScaledDotProductAttention(nn.Module):\n","    def __init__(self, d_k, attn_dropout = 0.1):\n","        '''\n","        d_k = d_model / H (H : head 개수) -> 가중치로 사용\n","        '''\n","        super().__init__()\n","        self.temperature = np.sqrt(d_k)\n","        self.dropout = nn.Dropout(attn_dropout)\n","\n","    def forward(self, q, k, v, mask = None):\n","        '''\n","        q : (B, H, Tq, d_k)\n","        k : (B, H, Tk, d_k)\n","        v : (B, H, Tk, d_v) (d_v = d_k) (모든 경우에서 Key와 Value는 같은 종류이므로 Token의 최대 개수가 Tk로 동일)\n","        mask : (B, 1, Tq, Tk)\n","        '''\n","        attn = torch.matmul(q, k.transpose(2,3)) / self.temperature # (B, H, Tq, Tk)\n","\n","        if mask is not None:\n","            attn = attn.masked_fill(mask, float('-inf')) # mask에서 True인 값은 가중치를 매우 작게 주어 Attention 가중치에 영향 안 주도록 함\n","\n","        attn = self.dropout(F.softmax(attn, dim=-1))\n","\n","        output = torch.matmul(attn, v) # (B, H, Tq, d_v)\n","        return output, attn"],"metadata":{"id":"jw5jRkro1nfe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Multi-Head Attention"],"metadata":{"id":"j-dsSzJF9ozE"}},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, n_head, d_model, d_k, d_v, dropout = 0.1):\n","        super().__init__()\n","\n","        self.n_head = n_head # H\n","        self.d_k = d_k\n","        self.d_v = d_v\n","\n","        assert d_model % n_head == 0, \"d_model must be divisible by n_head\"\n","\n","        self.w_q = nn.Linear(d_model, n_head * d_k, bias = False)\n","        self.w_k = nn.Linear(d_model, n_head * d_k, bias = False)\n","        self.w_v = nn.Linear(d_model, n_head * d_v, bias = False)\n","        self.fc = nn.Linear(n_head * d_v, d_model, bias = False)\n","\n","        self.attention = ScaledDotProductAttention(d_k)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, q, k, v, mask = None):\n","        '''\n","        q : (B, Tq, d_model)\n","        k : (B, Tk, d_model)\n","        v : (B, Tk, d_model)\n","        mask : (B, 1, Tq, Tk)\n","        '''\n","\n","        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n","        B, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1) # B, Tq, Tk, Tk\n","\n","        q = self.w_q(q).view(B, len_q, n_head, d_k).transpose(1,2) # (B, H, Tq, d_k)\n","        k = self.w_k(k).view(B, len_k, n_head, d_k).transpose(1,2) # (B, H, Tk, d_k)\n","        v = self.w_v(v).view(B, len_v, n_head, d_v).transpose(1,2) # (B, H, Tk, d_v)\n","\n","        out, attn = self.attention(q, k, v, mask = mask)             # (B, H, Tq, d_v), (B, H, Tq, Tk)\n","\n","        q = out.transpose(1,2).reshape(B, len_q, -1)                 # (B, Tq, H * d_v) / .contiguous().view(B, len_q, -1)은 좀 더 안전한 버전\n","        q = self.dropout(self.fc(q))                               # (B, Tq, d_model) -> multi-head attention을 통해 q의 새로운 embedding vector를 얻어낸 것\n","\n","        return q, attn\n","\n"],"metadata":{"id":"n6yrvFS89pZ-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Position-wise FFN"],"metadata":{"id":"HDsnbpXxIqx6"}},{"cell_type":"code","source":["class PositionWiseFFN(nn.Module): # FFN + Residual Connect + LayerNorm\n","    def __init__(self, d_in, d_hid, dropout = 0.1):\n","        super().__init__()\n","        self.w_1 = nn.Linear(d_in, d_hid)\n","        self.w_2 = nn.Linear(d_hid, d_in)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        # x의 마지막 차원: d_model, 즉, 각 단어별로 임베딩 벡터를 FFN을 통해 변환하는 과정\n","        x = self.w_2(self.dropout(F.relu(self.w_1(x))))\n","\n","        return x"],"metadata":{"id":"F5HM7odmI2Xo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Encoder Layer (Pre-LN)"],"metadata":{"id":"cMbY3HxBKtoK"}},{"cell_type":"code","source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, d_hid, n_head, d_k, d_v, dropout = 0.1):\n","        super().__init__()\n","        self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout = dropout)\n","        self.FFN = PositionWiseFFN(d_model, d_hid, dropout = dropout)\n","        self.layer_norm1 = nn.LayerNorm(d_model, eps = 1e-6)\n","        self.layer_norm2 = nn.LayerNorm(d_model, eps = 1e-6)\n","        self.drop = nn.Dropout(dropout)\n","\n","\n","    def forward(self, enc_input, src_mask = None):\n","        '''\n","        enc_input : (B, S, d_model)\n","        src_mask : (B, 1, 1, S)\n","        enc_output : (B, S, d_model)\n","\n","        기존 논문 : SubLayer -> Residual -> LayerNorm\n","        Pre-LN    : LayerNorm -> SubLayer -> Residual\n","        여기서 SubLayer는 Multi-Head Attention과 Position-wise FFN\n","\n","        Multi-Head Attention은 Q, K, V를 모두 enc_input으로 사용한 Self-Attention\n","        '''\n","        # Self-Attention\n","        residual = enc_input\n","        x = self.layer_norm1(enc_input) # (B, S, d_model)\n","        y, enc_slf_attn = self.slf_attn(x, x, x, mask = src_mask)\n","        y = self.drop(y) + residual\n","\n","        # Position-Wise FFN\n","        residual = y\n","        y = self.layer_norm2(y)\n","        enc_output = self.FFN(y)\n","        enc_output = self.drop(enc_output) + residual\n","\n","        return enc_output, enc_slf_attn"],"metadata":{"id":"AHckEgksK-dA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decoder Layer (Pre-LN)"],"metadata":{"id":"GWmNMEj2QWTV"}},{"cell_type":"code","source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, d_hid, n_head, d_k, d_v, dropout = 0.1):\n","        super().__init__()\n","        self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout = dropout)\n","        self.dec_enc_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout = dropout)\n","        self.FFN = PositionWiseFFN(d_model, d_hid, dropout = dropout)\n","\n","        self.layer_norm1 = nn.LayerNorm(d_model, eps = 1e-6)\n","        self.layer_norm2 = nn.LayerNorm(d_model, eps = 1e-6)\n","        self.layer_norm3 = nn.LayerNorm(d_model, eps = 1e-6)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, dec_input, enc_output, tgt_mask = None, mem_mask = None):\n","        '''\n","        dec_input : (B, T-1, d_model)\n","        enc_output : (B, S, d_model)\n","        tgt_mask : (B, 1, T-1, T-1)\n","        mem_mask : (B, 1, T-1, S)\n","\n","        Pre-LN 방식은 마찬가지\n","        여기서 Sublayer 흐름은 Self Attention (MultiHeadAttention) -> Encoder-Decoder Attention (MultiHeadAttention) -> Position-Wise FFN\n","\n","        Self-Attention의 Q, K, V는 모두 dec_input\n","        Encoder-Decoder Attention의 Q는 Self-Attention을 거친 dec_input, K, V는 enc-output (Encoder의 최종 Embedding Vector)\n","        '''\n","        # Self-Attention\n","        residual = dec_input\n","        x = self.layer_norm1(dec_input)\n","        y, dec_slf_attn = self.slf_attn(x, x, x, mask = tgt_mask)\n","        y = self.dropout(y) + residual\n","\n","        # Encoder-Decoder Attention\n","        residual = y\n","        y = self.layer_norm2(y)\n","        z, dec_enc_attn = self.dec_enc_attn(y, enc_output, enc_output, mask = mem_mask)\n","        z = self.dropout(z) + residual\n","\n","        # Position-Wise FFN\n","        residual = z\n","        z = self.layer_norm3(z)\n","        dec_output = self.FFN(z)\n","        dec_output = self.dropout(dec_output) + residual\n","\n","        return dec_output, dec_slf_attn, dec_enc_attn\n","\n"],"metadata":{"id":"kCCEuP8OQYEx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Encoder"],"metadata":{"id":"0m_717bEVpaZ"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, n_src_vocab, d_word_vec, n_layers, d_model, d_hid,\n","                 n_head, d_k, d_v, pad_idx, dropout = 0.1, n_tokens = 100, scale_emb = False):\n","        '''\n","        n_src_vocab : BPE 과정을 통해 생성된 Token의 총 개수 (source, 우리 코드에서는 영어)\n","        d_word_vec : 임베딩 벡터의 차원 (보통 d_model과 동일)\n","        n_layers : Encoder Layer의 개수\n","        d_model : 각 단어별 임베딩 벡터의 차원\n","        d_hid : FFN에서 사용되는 내부 벡터 차원\n","        n_head : Multi-Head Attention에서 Head의 개수\n","        d_k : Multi-Head Attention에서 Query, Key가 압축되는 벡터의 차원\n","        d_v : Multi-Head Attention에서 Value가 압축되는 벡터의 차원\n","        pad_idx : Padding Token의 인덱스 (우리 코드에서는 0)\n","        dropout : Dropout 비율\n","        n_tokens : 한 문장 내에서 Token의 최대 개수 (1 + 96 + 1인데 널널하게 100으로 잡음)\n","        scale_emb : 단어 Embedding시 스케일링 여부\n","        '''\n","\n","        super().__init__()\n","        assert d_model == d_word_vec, \"d_model must be equal to d_word_vec\"\n","        self.src_word_emb = nn.Embedding(n_src_vocab, d_word_vec, padding_idx = pad_idx) # 각 Token을 Embedding Vector로 바꾸는 신경망\n","        self.position_enc = SinePositionalEncoding(d_model, n_tokens = n_tokens)\n","        self.dropout = nn.Dropout(dropout)\n","        self.layer_stack = nn.ModuleList([\n","            EncoderLayer(d_model, d_hid, n_head, d_k, d_v, dropout = dropout)\n","                                         for _ in range(n_layers)])\n","        self.final_layer_norm = nn.LayerNorm(d_model, eps = 1e-6)\n","        self.scale_emb = scale_emb\n","        self.d_model = d_model\n","\n","    def forward(self, src_seq, src_mask, return_attns = False):\n","        '''\n","        src_seq : (B, S), Index 형태로 저장된 Token 리스트\n","        src_mask : (B, 1, 1, S)\n","        enc_output : (B, S, d_model)\n","        '''\n","\n","        enc_slf_attn_list = [] # attention 결과를 저장할 리스트\n","\n","        # 각 토큰을 Embedding Vector로 반환\n","        enc_output = self.src_word_emb(src_seq) # (B, S) -> (B, S, d_word_vec = d_model)\n","        if self.scale_emb:\n","            enc_output *= self.d_model ** 0.5\n","        enc_output = self.dropout(self.position_enc(enc_output)) # Positional Encoding 추가\n","\n","        for enc_layer in self.layer_stack:\n","            enc_output, enc_slf_attn = enc_layer(enc_output, src_mask)\n","            enc_slf_attn_list += [enc_slf_attn] if return_attns else []\n","        enc_output = self.final_layer_norm(enc_output)\n","\n","        if return_attns:\n","            return enc_output, enc_slf_attn_list\n","        return enc_output, None\n","\n"],"metadata":{"id":"22KQqQ5sVtwd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decoder"],"metadata":{"id":"jaeMy2zret51"}},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, n_tgt_vocab, d_word_vec, n_layers, d_model, d_hid,\n","                 n_head, d_k, d_v, pad_idx, dropout = 0.1, n_tokens = 100, scale_emb = False):\n","        '''\n","        n_tgt_vocab : BPE 과정을 통해 생성된 Token의 총 개수 (Target, 우리 코드에서는 한국어)\n","        d_word_vec : 임베딩 벡터의 차원 (보통 d_model과 동일)\n","        n_layers : Decoder Layer의 개수\n","        d_model : 각 단어별 임베딩 벡터의 차원\n","        d_hid : FFN에서 사용되는 내부 벡터 차원\n","        n_head : Multi-Head Attention에서 Head의 개수\n","        d_k : Multi-Head Attention에서 Query, Key가 압축되는 벡터의 차원\n","        d_v : Multi-Head Attention에서 Value가 압축되는 벡터의 차원\n","        pad_idx : Padding Token의 인덱스 (우리 코드에서는 0)\n","        dropout : Dropout 비율\n","        n_tokens : 한 문장 내에서 Token의 최대 개수 (1 + 96 + 1인데 널널하게 100으로 잡음)\n","        scale_emb : 단어 Embedding시 스케일링 여부\n","        '''\n","\n","        super().__init__()\n","        assert d_model == d_word_vec, \"d_model must be equal to d_word_vec\"\n","        self.tgt_word_emb = nn.Embedding(n_tgt_vocab, d_word_vec, padding_idx = pad_idx) # 각 Token을 Embedding Vector로 바꾸는 신경망\n","        self.position_enc = SinePositionalEncoding(d_model, n_tokens = n_tokens)\n","        self.dropout = nn.Dropout(dropout)\n","        self.layer_stack = nn.ModuleList([\n","            DecoderLayer(d_model, d_hid, n_head, d_k, d_v, dropout = dropout)\n","                                         for _ in range(n_layers)])\n","        self.final_layer_norm = nn.LayerNorm(d_model, eps = 1e-6)\n","        self.scale_emb = scale_emb\n","        self.d_model = d_model\n","\n","    def forward(self, tgt_seq, tgt_mask, enc_output, mem_mask, return_attns = False):\n","        '''\n","        tgt_seq : (B, T-1), Index 형태로 저장된 Token 리스트\n","        tgt_mask : (B, 1, T-1, T-1)\n","        mem_mask : (B, 1, T-1, S)\n","        dec_output : (B, T-1, d_model)\n","        '''\n","\n","        dec_slf_attn_list, dec_enc_attn_list = [], [] # attention 결과를 저장할 리스트\n","\n","        # 각 토큰을 Embedding Vector로 반환\n","        dec_output = self.tgt_word_emb(tgt_seq) # (B, S) -> (B, S, d_word_vec = d_model)\n","        if self.scale_emb:\n","            dec_output *= self.d_model ** 0.5\n","        dec_output = self.dropout(self.position_enc(dec_output)) # Positional decoding 추가\n","\n","        for dec_layer in self.layer_stack:\n","            dec_output, dec_slf_attn, dec_enc_attn = dec_layer(dec_output, enc_output, tgt_mask = tgt_mask, mem_mask = mem_mask)\n","            dec_slf_attn_list += [dec_slf_attn] if return_attns else []\n","            dec_enc_attn_list += [dec_enc_attn] if return_attns else []\n","        dec_output = self.final_layer_norm(dec_output)\n","        if return_attns:\n","            return dec_output, dec_slf_attn_list, dec_enc_attn_list\n","        return dec_output, None, None\n","\n"],"metadata":{"id":"JDTr3cQjevGt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transformer"],"metadata":{"id":"V_RAhf_tiuQ4"}},{"cell_type":"code","source":["class Transformer(nn.Module):\n","    def __init__(self, n_src_vocab, n_tgt_vocab, pad_idx,\n","                 d_word_vec = 512, d_model = 512, d_hid = 2048, n_layers = 6,\n","                 n_head = 8, d_k = 64, d_v = 64, dropout = 0.1, n_tokens = 100,\n","                 tgt_emb_prj_weight_sharing = True, emb_src_tgt_weight_sharing = True,\n","                 scale_emb_or_prj = \"prj\"):\n","        '''\n","        tgt_emb_prj_weight_sharing :\n","        Decoder 첫 부분의 Embedding Layer의 가중치와\n","        디코더 마지막의 최종 출력 벡터를 전체 어휘 크기의 벡터로 바꾸는 과정 (Projection)의 가중치를 공유할 지 여부\n","        즉, (단어 -> 벡터) 과정과 (벡터 -> 단어) 과정의 가중치를 공유하는 것\n","\n","        emb_src_tgt_weight_sharing:\n","        Source Embedding Layer와 Target Embedding Layer의 가중치 공유 여부\n","        Source와 Target의 언어가 같은 때 사용 (두 언어가 다르더라도 embedding 공간을 공유하고 있다면 사용 가능함)\n","\n","        scale_emb_or_prj : Scaling을 embedding을 만드는 과정에서 할 지, 마지막 Projection 과정에서 할 지 여부\n","        #   'emb': multiply \\sqrt{d_model} to embedding output\n","        #   'prj': multiply (\\sqrt{d_model} ^ -1) to linear projection output\n","        #   'none': no multiplication\n","        '''\n","\n","        super().__init__()\n","\n","        self.pad_idx = pad_idx\n","\n","        assert scale_emb_or_prj in ['emb', 'prj', 'none']\n","        scale_emb = (scale_emb_or_prj == 'emb') if tgt_emb_prj_weight_sharing else False\n","        self.scale_prj = (scale_emb_or_prj == 'prj') if tgt_emb_prj_weight_sharing else False\n","        self.d_model = d_model\n","\n","        self.encoder = Encoder(n_src_vocab = n_src_vocab, d_word_vec = d_word_vec, n_layers = n_layers,\n","                               d_model = d_model, d_hid = d_hid, n_head = n_head, d_k = d_k, d_v = d_v,\n","                               pad_idx = pad_idx, dropout = dropout, n_tokens = n_tokens, scale_emb = scale_emb)\n","\n","        self.decoder = Decoder(n_tgt_vocab = n_tgt_vocab, d_word_vec = d_word_vec, n_layers = n_layers,\n","                        d_model = d_model, d_hid = d_hid, n_head = n_head, d_k = d_k, d_v = d_v,\n","                        pad_idx = pad_idx, dropout = dropout, n_tokens = n_tokens, scale_emb = scale_emb)\n","\n","        self.tgt_word_prj = nn.Linear(d_model, n_tgt_vocab, bias = False)\n","\n","        for p in self.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","\n","        if tgt_emb_prj_weight_sharing:\n","            self.tgt_word_prj.weight = self.decoder.tgt_word_emb.weight\n","\n","        if emb_src_tgt_weight_sharing:\n","            assert n_src_vocab == n_tgt_vocab, \"src/tgt vocab must match for weight sharing\"\n","            self.encoder.src_word_emb.weight = self.decoder.tgt_word_emb.weight\n","\n","    def forward(self, src_seq, tgt_seq, src_mask, tgt_mask, mem_mask, return_attns = False):\n","        '''\n","        src_seq : (B, S)\n","        tgt_seq : (B, T-1)\n","        src_mask : (B, 1, 1, S)\n","        tgt_mask : (B, 1, T-1, T-1)\n","        mem_mask : (B, 1, T-1, S)\n","        enc_output : (B, S, d_model)\n","        dec_output : (B, T-1, d_model)\n","        seq_logit : (B, T-1, tgt_vocab_size)\n","        '''\n","        # 만약 attention 결과를 얻고 싶다면 조금 더 예쁘게 고쳐보자.\n","        enc_output, *att1 = self.encoder(src_seq, src_mask, return_attns = return_attns)\n","        dec_output, *att2 = self.decoder(tgt_seq, tgt_mask, enc_output, mem_mask, return_attns = return_attns)\n","        seq_logit = self.tgt_word_prj(dec_output)\n","        if self.scale_prj:\n","            seq_logit *= self.d_model ** -0.5\n","\n","        if return_attns:\n","            return seq_logit, att1, att2\n","        return seq_logit\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRM6P_KjitYp","executionInfo":{"status":"ok","timestamp":1761289808461,"user_tz":-540,"elapsed":5,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"bd063a73-2306-44cb-e7b2-c1078742fb5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<>:18: SyntaxWarning: invalid escape sequence '\\s'\n","<>:18: SyntaxWarning: invalid escape sequence '\\s'\n","/tmp/ipython-input-2273316809.py:18: SyntaxWarning: invalid escape sequence '\\s'\n","  #   'emb': multiply \\sqrt{d_model} to embedding output\n"]}]},{"cell_type":"markdown","source":["# 2. 모델 학습"],"metadata":{"id":"3a7BDFLWx6VO"}},{"cell_type":"code","source":["# ===== 0) 환경/하이퍼 =====\n","import os, re, json, math, glob, random, numpy as np\n","import torch, torch.nn as nn, torch.nn.functional as F\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import LambdaLR\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import sentencepiece as spm\n","import logging, sys\n","from datetime import datetime\n","# ====== 로그 설정 ======\n","LOG_PATH = RUNS_DIR / \"train.log\"\n","\n","for h in logging.root.handlers[:]:\n","    logging.root.removeHandler(h)\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"[%(asctime)s] [%(levelname)s] %(message)s\",\n","    datefmt=\"%H:%M:%S\",\n","    handlers=[\n","        logging.StreamHandler(sys.stdout),                         # 콘솔 실시간 출력\n","        logging.FileHandler(str(LOG_PATH), mode='a', encoding='utf-8')  # 파일 저장\n","    ]\n",")\n","\n","# ---------- 장치/토크나이저 ----------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","sp = spm.SentencePieceProcessor(); sp.load(str(SPM_DIR/\"spm.model\"))\n","VOCAB_SIZE = sp.get_piece_size()\n","\n","# ---------- 모델 하이퍼 ----------\n","d_model, n_layers, n_head = 512, 6, 8\n","d_k = d_v = d_model // n_head\n","d_hid, dropout = 2048, 0.1\n","\n","# ===== 1) 모델 =====\n","model = Transformer(\n","    n_src_vocab=VOCAB_SIZE, n_tgt_vocab=VOCAB_SIZE, pad_idx=PAD_ID,\n","    d_word_vec=d_model, d_model=d_model, d_hid=d_hid, n_layers=n_layers,\n","    n_head=n_head, d_k=d_k, d_v=d_v, dropout=dropout,\n","    n_tokens=max(100, int(max(getattr(train_dl.dataset, 'max_src_len', 0),\n","                              getattr(train_dl.dataset, 'max_tgt_len', 0)))) if hasattr(train_dl, 'dataset') else 500,\n","    tgt_emb_prj_weight_sharing=True, emb_src_tgt_weight_sharing=True,\n","    scale_emb_or_prj=\"prj\"\n",").to(device)\n","\n","# ===== 2) 옵티마이저 & 스케줄러 (Noam) =====\n","base_lr = 1\n","optimizer = AdamW(model.parameters(), lr=base_lr, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.01)\n","warmup_steps = 4000\n","def noam(step):\n","    step = max(1, step)\n","    return (d_model ** -0.5) * min(step ** -0.5, step * (warmup_steps ** -1.5))\n","scheduler = LambdaLR(optimizer, lr_lambda=noam)\n","\n","# ===== 3) 손실함수/AMP/그라드클립 =====\n","criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n","scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n","max_grad_norm = 1.0\n","\n","# ===== 4) 체크포인트/로그 =====\n","os.makedirs(CKPT_DIR, exist_ok=True)\n","HIST_PATH = os.path.join(CKPT_DIR, \"loss_history.json\")  # step별 train/val 손실 저장\n","\n","def save_ckpt_latest_best(step, epoch, best_val, is_best):\n","    state = {\n","        \"model\":       model.state_dict(),\n","        \"optimizer\":   optimizer.state_dict(),\n","        \"scheduler\":   scheduler.state_dict(),\n","        \"scaler\":      scaler.state_dict(),\n","        \"global_step\": step,\n","        \"next_epoch\":  epoch + 1,   # 다음에 시작할 에폭\n","        \"best_val\":    best_val,\n","        \"seed\":        SEED,\n","    }\n","    torch.save(state, os.path.join(CKPT_DIR, \"latest.pt\"))\n","    if is_best:\n","        torch.save(state, os.path.join(CKPT_DIR, \"best.pt\"))\n","\n","def load_latest():\n","    p = os.path.join(CKPT_DIR, \"latest.pt\")\n","    if os.path.exists(p):\n","        return torch.load(p, map_location=device)\n","    return None\n","\n","def load_history():\n","    if os.path.exists(HIST_PATH):\n","        with open(HIST_PATH, \"r\", encoding=\"utf-8\") as f: return json.load(f)\n","    return {\"train_steps\": [], \"train_losses\": [], \"val_steps\": [], \"val_losses\": [], \"best_val\": None}\n","\n","def append_and_save_history(history, train_pair=None, val_pair=None, best_val=None):\n","    if train_pair:\n","        s,l = train_pair; history[\"train_steps\"].append(int(s)); history[\"train_losses\"].append(float(l))\n","    if val_pair:\n","        s,l = val_pair; history[\"val_steps\"].append(int(s)); history[\"val_losses\"].append(float(l))\n","    if best_val is not None:\n","        history[\"best_val\"] = float(best_val)\n","    with open(HIST_PATH, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(history, f, ensure_ascii=False)\n","\n","# ===== 5) 스텝/검증 =====\n","def train_step(batch):\n","    model.train()\n","    src_ids = batch[\"src_ids\"].to(device)\n","    tgt_in  = batch[\"tgt_in\"].to(device)\n","    tgt_out = batch[\"tgt_out\"].to(device)\n","    src_mask = batch[\"src_mask\"].to(device)\n","    tgt_mask = batch[\"tgt_mask\"].to(device)\n","    mem_mask = batch[\"mem_mask\"].to(device)\n","\n","    optimizer.zero_grad(set_to_none=True)\n","    with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n","        logits = model(src_ids, tgt_in, src_mask, tgt_mask, mem_mask, return_attns=False)\n","        loss = criterion(logits.view(-1, logits.size(-1)), tgt_out.reshape(-1))\n","\n","    scaler.scale(loss).backward()\n","    scaler.unscale_(optimizer)\n","    nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","    scaler.step(optimizer); scaler.update()\n","    scheduler.step()\n","    return loss.item()\n","\n","@torch.no_grad()\n","def run_validation(valid_dl, fraction: float = 0.2, min_batches: int = 1):\n","    \"\"\"\n","    검증셋 전체 대신 앞의 일부 배치만 사용(결정론적·빠름).\n","    fraction∈(0,1]: 검증 배치 비율. 예) 0.2~0.3 권장\n","    \"\"\"\n","    model.eval()\n","    total, cnt = 0.0, 0\n","    limit = max(min_batches, int(len(valid_dl) * fraction))\n","    for b_idx, batch in enumerate(valid_dl):\n","        if b_idx >= limit: break\n","        src_ids = batch[\"src_ids\"].to(device)\n","        tgt_in  = batch[\"tgt_in\"].to(device)\n","        tgt_out = batch[\"tgt_out\"].to(device)\n","        src_mask = batch[\"src_mask\"].to(device)\n","        tgt_mask = batch[\"tgt_mask\"].to(device)\n","        mem_mask = batch[\"mem_mask\"].to(device)\n","        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n","            logits = model(src_ids, tgt_in, src_mask, tgt_mask, mem_mask, return_attns=False)\n","            loss = criterion(logits.view(-1, logits.size(-1)), tgt_out.reshape(-1))\n","        total += loss.item(); cnt += 1\n","    return total / max(1, cnt)"],"metadata":{"id":"EK2RhuHEx75l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ===== 6) 학습 루프: 스텝 주기 로깅 + 부분검증 + EPOCH_STEP마다 저장 =====\n","NUM_EPOCHS  = 20\n","EVAL_STEPS  = 500          # N 스텝마다 train/val 로깅\n","VAL_FRACTION= 0.2          # 검증셋의 20%만 사용(결정론: 앞쪽 배치)\n","EPOCH_STEP  = 1            # 매 1 에폭마다 저장(latest/best만 유지)\n","\n","history   = load_history()\n","best_val  = history[\"best_val\"]\n","resume    = load_latest()\n","global_step = 0\n","start_epoch = 1\n","\n","if resume is not None:\n","    model.load_state_dict(resume[\"model\"])\n","    optimizer.load_state_dict(resume[\"optimizer\"])\n","    scheduler.load_state_dict(resume[\"scheduler\"])\n","    scaler.load_state_dict(resume[\"scaler\"])\n","    global_step = int(resume.get(\"global_step\", 0))\n","    start_epoch = int(resume.get(\"next_epoch\", 1))\n","    best_val    = resume.get(\"best_val\", best_val)\n","    print(f\"[Resume] next_epoch={start_epoch}, global_step={global_step}, best_val={best_val}\")\n","\n","total_steps = len(train_dl) * NUM_EPOCHS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPa0SupnsG2I","executionInfo":{"status":"ok","timestamp":1761289843259,"user_tz":-540,"elapsed":10711,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"eb2cee8c-4693-4aca-f466-f149ff4c1e72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Resume] next_epoch=16, global_step=238815, best_val=1.9597890104480724\n"]}]},{"cell_type":"code","source":["NEED_NEW_IR = True\n","scale = 2.5  # 2.5배 빠르게\n","def noam_scaled(step):\n","    step = max(1, step)\n","    return scale * (d_model**-0.5) * min(step**-0.5, step * (warmup_steps**-1.5))\n","if NEED_NEW_IR:\n","    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=noam_scaled, last_epoch=global_step - 1)"],"metadata":{"id":"MPSQ2j7syTzy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ===== 6) 학습 루프: 스텝 주기 로깅 + 부분검증 + EPOCH_STEP마다 저장 =====\n","start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","logging.info(f\"========[ TRAINING START ]========  ({start_time})\")\n","\n","running_loss = 0.0\n","last_val_loss = None\n","\n","for epoch in range(start_epoch, NUM_EPOCHS + 1):\n","    pbar = tqdm(train_dl, desc=f\"Epoch {epoch} [Training]\", leave=False)\n","    for batch in pbar:\n","        loss = train_step(batch)\n","        running_loss += loss\n","        global_step += 1\n","\n","        # 스텝 주기마다: train 평균 + 부분 검증\n","        if global_step % EVAL_STEPS == 0:\n","            avg_train = running_loss / EVAL_STEPS\n","            running_loss = 0.0\n","\n","            val_loss = run_validation(valid_dl, fraction=VAL_FRACTION)\n","            last_val_loss = val_loss\n","\n","            logging.info(\n","                f\"[Step {global_step:6d}/{total_steps:6d}] \"\n","                f\"Train {avg_train:.4f} | Val~{int(VAL_FRACTION*100)}% {val_loss:.4f}\"\n","            )\n","\n","            # 히스토리 누적 저장(중간 종료 대비)\n","            append_and_save_history(history,\n","                                    train_pair=(global_step, avg_train),\n","                                    val_pair=(global_step, val_loss),\n","                                    best_val=best_val)\n","\n","    # ---- 에폭 종료 시점 ----\n","    # EPOCH_STEP마다 저장: latest + 필요 시 best 갱신\n","    if (epoch % EPOCH_STEP) == 0:\n","        # 최근 부분검증 결과를 기준으로 best 갱신\n","        is_best = False\n","        if last_val_loss is not None:\n","            if (best_val is None) or (last_val_loss < best_val):\n","                best_val = float(last_val_loss)\n","                is_best = True\n","        append_and_save_history(history, best_val=best_val)\n","        save_ckpt_latest_best(global_step, epoch, best_val, is_best)\n","        logging.info(f\"[Checkpoint] epoch {epoch} saved \"\n","                     f\"(latest{' + best' if is_best else ''})\")\n","\n","logging.info(\"========[ TRAINING END ]========\")\n"],"metadata":{"id":"T8cCgPl31Ofi","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d48cfd94-7f65-4e30-c320-741ead042a4a","executionInfo":{"status":"error","timestamp":1761298334835,"user_tz":-540,"elapsed":642390,"user":{"displayName":"이민섭","userId":"15860324451243121926"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:10:51] [INFO] ========[ TRAINING START ]========  (2025-10-24 07:10:51)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:   1%|          | 184/15921 [00:22<30:07,  8.71it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:11:41] [INFO] [Step 239000/318420] Train 0.7500 | Val~20% 1.9593\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:   4%|▍         | 684/15921 [01:48<30:23,  8.36it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:13:08] [INFO] [Step 239500/318420] Train 2.0330 | Val~20% 1.9562\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:   7%|▋         | 1184/15921 [03:15<27:45,  8.85it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:14:35] [INFO] [Step 240000/318420] Train 2.0380 | Val~20% 1.9590\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  11%|█         | 1684/15921 [04:42<28:16,  8.39it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:16:02] [INFO] [Step 240500/318420] Train 2.0346 | Val~20% 1.9526\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  14%|█▎        | 2184/15921 [06:09<27:29,  8.33it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:17:29] [INFO] [Step 241000/318420] Train 2.0315 | Val~20% 1.9559\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  17%|█▋        | 2684/15921 [07:36<26:46,  8.24it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:18:56] [INFO] [Step 241500/318420] Train 2.0316 | Val~20% 1.9559\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  20%|█▉        | 3184/15921 [09:03<24:58,  8.50it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:20:23] [INFO] [Step 242000/318420] Train 2.0383 | Val~20% 1.9524\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  23%|██▎       | 3684/15921 [10:30<24:33,  8.30it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:21:50] [INFO] [Step 242500/318420] Train 2.0496 | Val~20% 1.9460\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  26%|██▋       | 4184/15921 [11:57<22:09,  8.83it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:23:17] [INFO] [Step 243000/318420] Train 2.0392 | Val~20% 1.9419\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  29%|██▉       | 4684/15921 [13:24<21:56,  8.54it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:24:44] [INFO] [Step 243500/318420] Train 2.0264 | Val~20% 1.9454\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  33%|███▎      | 5184/15921 [14:51<19:47,  9.04it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:26:11] [INFO] [Step 244000/318420] Train 2.0294 | Val~20% 1.9478\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  36%|███▌      | 5684/15921 [16:18<20:03,  8.51it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:27:38] [INFO] [Step 244500/318420] Train 2.0303 | Val~20% 1.9419\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  39%|███▉      | 6184/15921 [17:45<19:55,  8.15it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:29:05] [INFO] [Step 245000/318420] Train 2.0306 | Val~20% 1.9462\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  42%|████▏     | 6684/15921 [19:12<19:00,  8.10it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:30:32] [INFO] [Step 245500/318420] Train 2.0243 | Val~20% 1.9418\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  45%|████▌     | 7184/15921 [20:39<16:53,  8.62it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:31:58] [INFO] [Step 246000/318420] Train 2.0366 | Val~20% 1.9373\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  48%|████▊     | 7684/15921 [22:06<16:26,  8.35it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:33:25] [INFO] [Step 246500/318420] Train 2.0287 | Val~20% 1.9371\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  51%|█████▏    | 8184/15921 [23:33<15:39,  8.23it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:34:53] [INFO] [Step 247000/318420] Train 2.0227 | Val~20% 1.9400\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  55%|█████▍    | 8684/15921 [25:00<14:27,  8.34it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:36:20] [INFO] [Step 247500/318420] Train 2.0191 | Val~20% 1.9387\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  58%|█████▊    | 9184/15921 [26:27<12:18,  9.12it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:37:47] [INFO] [Step 248000/318420] Train 2.0243 | Val~20% 1.9406\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  61%|██████    | 9684/15921 [27:55<12:47,  8.13it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:39:15] [INFO] [Step 248500/318420] Train 2.0275 | Val~20% 1.9341\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  64%|██████▍   | 10184/15921 [29:22<12:32,  7.62it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:40:42] [INFO] [Step 249000/318420] Train 2.0147 | Val~20% 1.9312\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  67%|██████▋   | 10684/15921 [30:50<10:28,  8.33it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:42:09] [INFO] [Step 249500/318420] Train 2.0178 | Val~20% 1.9354\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  70%|███████   | 11184/15921 [32:17<09:28,  8.34it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:43:36] [INFO] [Step 250000/318420] Train 2.0200 | Val~20% 1.9305\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  73%|███████▎  | 11684/15921 [33:44<08:27,  8.35it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:45:03] [INFO] [Step 250500/318420] Train 2.0188 | Val~20% 1.9279\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  77%|███████▋  | 12184/15921 [35:10<07:37,  8.17it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:46:30] [INFO] [Step 251000/318420] Train 2.0275 | Val~20% 1.9280\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  80%|███████▉  | 12684/15921 [36:38<06:19,  8.52it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:47:58] [INFO] [Step 251500/318420] Train 2.0105 | Val~20% 1.9260\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  83%|████████▎ | 13184/15921 [38:05<05:41,  8.01it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:49:24] [INFO] [Step 252000/318420] Train 2.0218 | Val~20% 1.9210\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  86%|████████▌ | 13684/15921 [39:31<04:31,  8.24it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:50:51] [INFO] [Step 252500/318420] Train 2.0150 | Val~20% 1.9166\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  89%|████████▉ | 14184/15921 [40:58<03:21,  8.62it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:52:18] [INFO] [Step 253000/318420] Train 2.0138 | Val~20% 1.9255\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  92%|█████████▏| 14684/15921 [42:26<02:26,  8.47it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:53:45] [INFO] [Step 253500/318420] Train 2.0058 | Val~20% 1.9230\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  95%|█████████▌| 15184/15921 [43:52<01:30,  8.18it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:55:12] [INFO] [Step 254000/318420] Train 1.9991 | Val~20% 1.9201\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 16 [Training]:  99%|█████████▊| 15684/15921 [45:20<00:28,  8.46it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:56:39] [INFO] [Step 254500/318420] Train 2.0068 | Val~20% 1.9195\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:57:37] [INFO] [Checkpoint] epoch 16 saved (latest + best)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:   2%|▏         | 263/15921 [00:31<30:59,  8.42it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[07:58:36] [INFO] [Step 255000/318420] Train 1.9854 | Val~20% 1.9198\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:   5%|▍         | 763/15921 [01:58<29:16,  8.63it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:00:04] [INFO] [Step 255500/318420] Train 1.9609 | Val~20% 1.9165\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:   8%|▊         | 1263/15921 [03:25<27:26,  8.90it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:01:30] [INFO] [Step 256000/318420] Train 1.9660 | Val~20% 1.9185\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  11%|█         | 1763/15921 [04:52<27:59,  8.43it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:02:57] [INFO] [Step 256500/318420] Train 1.9616 | Val~20% 1.9150\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  14%|█▍        | 2263/15921 [06:19<25:26,  8.95it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:04:24] [INFO] [Step 257000/318420] Train 1.9755 | Val~20% 1.9144\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  17%|█▋        | 2763/15921 [07:45<24:27,  8.96it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:05:51] [INFO] [Step 257500/318420] Train 1.9621 | Val~20% 1.9171\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  20%|██        | 3263/15921 [09:13<24:26,  8.63it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:07:18] [INFO] [Step 258000/318420] Train 1.9604 | Val~20% 1.9098\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  24%|██▎       | 3763/15921 [10:40<23:12,  8.73it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:08:45] [INFO] [Step 258500/318420] Train 1.9602 | Val~20% 1.9087\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  27%|██▋       | 4263/15921 [12:07<24:54,  7.80it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:10:12] [INFO] [Step 259000/318420] Train 1.9675 | Val~20% 1.9084\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  30%|██▉       | 4763/15921 [13:34<21:48,  8.53it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:11:39] [INFO] [Step 259500/318420] Train 1.9661 | Val~20% 1.9094\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  33%|███▎      | 5263/15921 [15:02<22:22,  7.94it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:13:07] [INFO] [Step 260000/318420] Train 1.9632 | Val~20% 1.9082\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  36%|███▌      | 5763/15921 [16:29<19:45,  8.57it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:14:34] [INFO] [Step 260500/318420] Train 1.9677 | Val~20% 1.9063\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  39%|███▉      | 6263/15921 [17:56<19:06,  8.43it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:16:01] [INFO] [Step 261000/318420] Train 1.9676 | Val~20% 1.9045\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  42%|████▏     | 6763/15921 [19:23<18:11,  8.39it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:17:28] [INFO] [Step 261500/318420] Train 1.9682 | Val~20% 1.9040\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  46%|████▌     | 7263/15921 [20:50<17:40,  8.16it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:18:55] [INFO] [Step 262000/318420] Train 1.9687 | Val~20% 1.9024\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  49%|████▉     | 7763/15921 [22:17<15:57,  8.52it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:20:22] [INFO] [Step 262500/318420] Train 1.9645 | Val~20% 1.8997\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  52%|█████▏    | 8263/15921 [23:44<15:38,  8.16it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:21:49] [INFO] [Step 263000/318420] Train 1.9592 | Val~20% 1.9021\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  55%|█████▌    | 8763/15921 [25:11<13:34,  8.78it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:23:16] [INFO] [Step 263500/318420] Train 1.9649 | Val~20% 1.8973\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  58%|█████▊    | 9263/15921 [26:37<13:17,  8.35it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:24:42] [INFO] [Step 264000/318420] Train 1.9649 | Val~20% 1.9006\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  61%|██████▏   | 9763/15921 [28:04<12:02,  8.53it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:26:09] [INFO] [Step 264500/318420] Train 1.9600 | Val~20% 1.8960\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  64%|██████▍   | 10263/15921 [29:31<11:05,  8.50it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:27:36] [INFO] [Step 265000/318420] Train 1.9611 | Val~20% 1.8994\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  68%|██████▊   | 10763/15921 [30:58<09:54,  8.67it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:29:03] [INFO] [Step 265500/318420] Train 1.9508 | Val~20% 1.8972\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  71%|███████   | 11263/15921 [32:25<09:08,  8.50it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:30:30] [INFO] [Step 266000/318420] Train 1.9580 | Val~20% 1.8903\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  74%|███████▍  | 11763/15921 [33:52<08:07,  8.53it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:31:57] [INFO] [Step 266500/318420] Train 1.9599 | Val~20% 1.8930\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  77%|███████▋  | 12263/15921 [35:19<07:28,  8.16it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:33:24] [INFO] [Step 267000/318420] Train 1.9576 | Val~20% 1.8968\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  80%|████████  | 12763/15921 [36:46<06:12,  8.47it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:34:51] [INFO] [Step 267500/318420] Train 1.9575 | Val~20% 1.8930\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  83%|████████▎ | 13263/15921 [38:13<05:04,  8.72it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:36:19] [INFO] [Step 268000/318420] Train 1.9586 | Val~20% 1.8897\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  86%|████████▋ | 13763/15921 [39:41<04:13,  8.52it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:37:46] [INFO] [Step 268500/318420] Train 1.9518 | Val~20% 1.8860\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  90%|████████▉ | 14263/15921 [41:08<03:17,  8.39it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:39:13] [INFO] [Step 269000/318420] Train 1.9616 | Val~20% 1.8863\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  93%|█████████▎| 14763/15921 [42:35<02:18,  8.38it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:40:40] [INFO] [Step 269500/318420] Train 1.9525 | Val~20% 1.8876\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  96%|█████████▌| 15263/15921 [44:02<01:18,  8.43it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:42:07] [INFO] [Step 270000/318420] Train 1.9509 | Val~20% 1.8848\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 17 [Training]:  99%|█████████▉| 15763/15921 [45:29<00:19,  7.99it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:43:34] [INFO] [Step 270500/318420] Train 1.9502 | Val~20% 1.8846\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:43:57] [INFO] [Checkpoint] epoch 17 saved (latest + best)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:   2%|▏         | 342/15921 [00:40<30:11,  8.60it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:45:06] [INFO] [Step 271000/318420] Train 1.9866 | Val~20% 1.8859\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:   5%|▌         | 842/15921 [02:08<30:39,  8.20it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:46:33] [INFO] [Step 271500/318420] Train 2.0076 | Val~20% 1.8774\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:   8%|▊         | 1342/15921 [03:35<28:11,  8.62it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:48:00] [INFO] [Step 272000/318420] Train 2.0146 | Val~20% 1.8774\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  12%|█▏        | 1842/15921 [05:02<29:09,  8.05it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:49:27] [INFO] [Step 272500/318420] Train 2.0159 | Val~20% 1.8771\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  15%|█▍        | 2342/15921 [06:29<28:06,  8.05it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:50:54] [INFO] [Step 273000/318420] Train 2.0195 | Val~20% 1.8808\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  18%|█▊        | 2842/15921 [07:57<25:54,  8.41it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:52:22] [INFO] [Step 273500/318420] Train 2.0241 | Val~20% 1.8774\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  21%|██        | 3342/15921 [09:24<25:31,  8.21it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:53:49] [INFO] [Step 274000/318420] Train 2.0144 | Val~20% 1.8729\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  24%|██▍       | 3842/15921 [10:51<24:18,  8.28it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:55:17] [INFO] [Step 274500/318420] Train 2.0260 | Val~20% 1.8742\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  27%|██▋       | 4342/15921 [12:19<22:44,  8.49it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:56:44] [INFO] [Step 275000/318420] Train 2.0225 | Val~20% 1.8714\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  30%|███       | 4842/15921 [13:46<22:27,  8.22it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:58:11] [INFO] [Step 275500/318420] Train 2.0232 | Val~20% 1.8715\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  34%|███▎      | 5342/15921 [15:13<20:14,  8.71it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[08:59:38] [INFO] [Step 276000/318420] Train 2.0220 | Val~20% 1.8651\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  37%|███▋      | 5842/15921 [16:40<19:04,  8.81it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:01:05] [INFO] [Step 276500/318420] Train 2.0188 | Val~20% 1.8676\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  40%|███▉      | 6342/15921 [18:06<19:41,  8.11it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:02:31] [INFO] [Step 277000/318420] Train 2.0213 | Val~20% 1.8657\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  43%|████▎     | 6842/15921 [19:34<18:08,  8.34it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:03:59] [INFO] [Step 277500/318420] Train 2.0180 | Val~20% 1.8636\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  46%|████▌     | 7342/15921 [21:01<17:35,  8.13it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:05:27] [INFO] [Step 278000/318420] Train 2.0158 | Val~20% 1.8590\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  49%|████▉     | 7842/15921 [22:29<15:39,  8.60it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:06:54] [INFO] [Step 278500/318420] Train 2.0221 | Val~20% 1.8623\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  52%|█████▏    | 8342/15921 [23:56<15:13,  8.29it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:08:21] [INFO] [Step 279000/318420] Train 2.0193 | Val~20% 1.8600\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  56%|█████▌    | 8842/15921 [25:23<14:05,  8.37it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:09:48] [INFO] [Step 279500/318420] Train 2.0151 | Val~20% 1.8568\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  59%|█████▊    | 9342/15921 [26:50<12:35,  8.71it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:11:16] [INFO] [Step 280000/318420] Train 2.0198 | Val~20% 1.8520\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  62%|██████▏   | 9842/15921 [28:18<11:54,  8.50it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:12:43] [INFO] [Step 280500/318420] Train 2.0168 | Val~20% 1.8557\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  65%|██████▍   | 10342/15921 [29:45<10:30,  8.85it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:14:11] [INFO] [Step 281000/318420] Train 2.0094 | Val~20% 1.8552\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  68%|██████▊   | 10842/15921 [31:13<10:00,  8.45it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:15:38] [INFO] [Step 281500/318420] Train 2.0125 | Val~20% 1.8541\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  71%|███████   | 11342/15921 [32:40<08:33,  8.92it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:17:05] [INFO] [Step 282000/318420] Train 2.0196 | Val~20% 1.8509\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  74%|███████▍  | 11842/15921 [34:07<08:10,  8.32it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:18:32] [INFO] [Step 282500/318420] Train 2.0194 | Val~20% 1.8487\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  78%|███████▊  | 12342/15921 [35:34<07:21,  8.10it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:19:59] [INFO] [Step 283000/318420] Train 2.0054 | Val~20% 1.8499\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 18 [Training]:  81%|████████  | 12842/15921 [37:01<06:08,  8.35it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[09:21:26] [INFO] [Step 283500/318420] Train 2.0123 | Val~20% 1.8473\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18 [Training]:  84%|████████▍ | 13342/15921 [38:28<05:11,  8.29it/s]"]},{"output_type":"stream","name":"stdout","text":["[09:22:53] [INFO] [Step 284000/318420] Train 2.0143 | Val~20% 1.8454\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18 [Training]:  87%|████████▋ | 13842/15921 [39:55<04:01,  8.61it/s]"]},{"output_type":"stream","name":"stdout","text":["[09:24:20] [INFO] [Step 284500/318420] Train 2.0139 | Val~20% 1.8449\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18 [Training]:  90%|█████████ | 14342/15921 [41:23<03:04,  8.56it/s]"]},{"output_type":"stream","name":"stdout","text":["[09:25:48] [INFO] [Step 285000/318420] Train 2.0140 | Val~20% 1.8438\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18 [Training]:  93%|█████████▎| 14842/15921 [42:50<02:09,  8.31it/s]"]},{"output_type":"stream","name":"stdout","text":["[09:27:15] [INFO] [Step 285500/318420] Train 2.0074 | Val~20% 1.8402\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18 [Training]:  96%|█████████▋| 15342/15921 [44:17<01:06,  8.65it/s]"]},{"output_type":"stream","name":"stdout","text":["[09:28:42] [INFO] [Step 286000/318420] Train 2.0062 | Val~20% 1.8376\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18 [Training]: 100%|█████████▉| 15842/15921 [45:45<00:09,  8.51it/s]"]},{"output_type":"stream","name":"stdout","text":["[09:30:10] [INFO] [Step 286500/318420] Train 2.0087 | Val~20% 1.8423\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["[09:30:22] [INFO] [Checkpoint] epoch 18 saved (latest + best)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19 [Training]:   3%|▎         | 421/15921 [00:50<30:02,  8.60it/s]"]},{"output_type":"stream","name":"stdout","text":["[09:31:41] [INFO] [Step 287000/318420] Train 1.9567 | Val~20% 1.8424\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4006196253.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch} [Training]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1482902909.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                             )\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             bias_correction1 = [\n\u001b[0;32m--> 755\u001b[0;31m                 \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m             ]\n\u001b[1;32m    757\u001b[0m             bias_correction2 = [\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# ===== 7) 손실 그래프 (이어붙이기 안전) =====\n","with open(HIST_PATH, \"r\", encoding=\"utf-8\") as f:\n","    hist = json.load(f)\n","\n","plt.figure(figsize=(12, 6))\n","if hist[\"train_steps\"]:\n","    plt.plot(hist[\"train_steps\"], hist[\"train_losses\"], label='Training Loss (avg per EVAL_STEPS)')\n","if hist[\"val_steps\"]:\n","    plt.plot(hist[\"val_steps\"], hist[\"val_losses\"], linestyle='--', marker='o',\n","             label=f'Validation Loss (~{int(VAL_FRACTION*100)}% batches)')\n","plt.title('Training & Validation Loss (Resumable, Partial-Valid)')\n","plt.xlabel('Global Steps'); plt.ylabel('Loss')\n","plt.legend(); plt.grid(True); plt.show()"],"metadata":{"id":"cZsUxl5On26e","colab":{"base_uri":"https://localhost:8080/","height":564},"executionInfo":{"status":"ok","timestamp":1761298579695,"user_tz":-540,"elapsed":430,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"61476200-d060-42bc-b420-eeaf3a4aeb03"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAA/IAAAIjCAYAAACgdyAGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAxLdJREFUeJzs3Xd0VNXax/HvZNI7hBYgJBBqaCJFinSkdwQVVEBRFLCjWK6+gFJEBRG8YKOoFBWliHQBKQFBmnQpIfReEkjPnPePmLkMCZCEmUwCv89as2T27HPOMyd7Yp7ZzWQYhoGIiIiIiIiI5Asuzg5ARERERERERLJOibyIiIiIiIhIPqJEXkRERERERCQfUSIvIiIiIiIiko8okRcRERERERHJR5TIi4iIiIiIiOQjSuRFRERERERE8hEl8iIiIiIiIiL5iBJ5ERERERERkXxEibyIyL/69OlDWFhYjo4dOnQoJpPJvgHlc6tXr8ZkMrF69WprWVbv8ZEjRzCZTEybNs2uMYWFhdGnTx+7nvNuNGDAAB566CFnh5EnpX/Wz58/f9u690p7u5Pff02aNKFJkyb2DSgLTCYTQ4cOtT6fNm0aJpOJI0eO3PbYG3+uS5YswdfXl3Pnztk/UBGRm1AiLyJ5nslkytLj+oTxXmOxWPj4448pV64cXl5ehIeH8/zzz3P16tUsHV+tWjVKlSqFYRg3rdOgQQOKFi1KSkqKvcJ2iMjISIYOHcrly5edHYpVepLw119/OTuU24qKiuLrr7/m7bfftpalf7GS/nBxcaFgwYK0adOGDRs2ODFaSW9b6Q9PT0/Kly/PoEGDOHPmjN2uExcXx9ChQ3P99+yLL76IyWTi4MGDN63zzjvvYDKZ+Pvvv3Mxsv9p3bo1ZcuWZdSoUU65vojcm5TIi0ie991339k80nsKbyyvVKnSHV3nq6++Yv/+/Tk69j//+Q/x8fF3dP07MX78eF5//XWqVKnC+PHjefTRR1m6dGmWeg0BevXqxbFjx1i7dm2mrx85coQNGzbwyCOP4OrqmuM47+QeZ1VkZCTDhg3LNJHfv38/X331lUOvn9+NHz+e0qVL07Rp0wyvPfbYY3z33XdMnTqV559/no0bN9K0aVN27tzphEjlesOHD+e7775j4sSJ1K9fn0mTJlGvXj3i4uLscv64uDiGDRuWaSLvyN9/vXr1AmDmzJk3rTNr1iyqVq1KtWrVcnydJ554gvj4eEJDQ3N0fP/+/fniiy+IjY3NcQwiItmR87/GRERyyeOPP27zfOPGjSxfvjxD+Y3i4uLw9vbO8nXc3NxyFB+Aq6vrHSW4d2r27NlUrlyZX375xTrE9f3338disWTp+J49e/LWW28xc+ZMGjVqlOH1WbNmYRiG9Y/qnLqTe2wPHh4eTr1+XpecnMyMGTN47rnnMn39/vvvt/ncNWzYkDZt2jBp0iT++9//5laYkok2bdpQq1YtAPr160dQUBBjx45l/vz5PPbYYzk+r8ViISkp6ZZ1HPn774EHHqBs2bLMmjWL9957L8PrGzZsICoqitGjR9/RdcxmM2azOcfHd+vWjRdeeIGffvqJp5566o5iERHJCvXIi8hdoUmTJlSpUoUtW7bQqFEjvL29rUOD58+fT7t27ShevDgeHh6Eh4fz/vvvk5qaanOOG+dvpw8n/vjjj/nyyy8JDw/Hw8OD2rVrs3nzZptjM5sjajKZGDRoEPPmzaNKlSp4eHhQuXJllixZkiH+1atXU6tWLTw9PQkPD+eLL77I1rxTFxcXLBaLTX0XF5cs/3EdEhJCo0aNmDNnDsnJyRlenzlzJuHh4TzwwANER0czYMAAKlSogJeXF0FBQXTv3j1Lc0szmyN/+fJl+vTpQ0BAAIGBgfTu3TvT3vS///6bPn36UKZMGTw9PSlWrBhPPfUUFy5csNYZOnQor7/+OgClS5e2DjdOjy2zOcuHDx+me/fuFCxYEG9vb+rWrctvv/1mUyd9vv+PP/7IiBEjKFmyJJ6enjRv3vyWQ36za9u2bbRp0wZ/f398fX1p3rw5GzdutKmTnJzMsGHDKFeuHJ6engQFBfHggw+yfPlya53Tp0/Tt29fSpYsiYeHB8HBwXTq1Om2P6N169Zx/vx5WrRokaV4GzZsCMChQ4dsyi9fvszLL79MSEgIHh4elC1blg8//DDDF0uzZ8+mZs2a+Pn54e/vT9WqVRk/frz19Zt9BjKbzxwWFkb79u2tnyUvLy+qVq1q7UH+5ZdfqFq1Kp6entSsWZNt27bZnDMr7et658+fp0ePHvj7+xMUFMRLL71EQkLCbe9ZVu/NnWrWrBmQNlUC4OOPP6Z+/foEBQXh5eVFzZo1mTNnTobj0n9vzZgxg8qVK+Ph4cHkyZMpXLgwAMOGDbN+rtLnmGf2c5o6dSrNmjWjSJEieHh4EBERwaRJk3L0Xnr16sW+ffvYunVrhtdmzpyJyWTiscceIykpiffee4+aNWsSEBCAj48PDRs2ZNWqVbe9RmZtyjAMPvjgA0qWLIm3tzdNmzZl9+7dmR5fpEgRqlWrxvz583P0HkVEsks98iJy17hw4QJt2rTh0Ucf5fHHH6do0aJA2h9ovr6+vPrqq/j6+rJy5Uree+89YmJi+Oijj2573pkzZxIbG0v//v0xmUyMGTOGrl27cvjw4dv2MK9bt45ffvmFAQMG4Ofnx2effUa3bt04evQoQUFBQFry1rp1a4KDgxk2bBipqakMHz7c+odzVvTt29c6tLN///5ZPu56vXr14tlnn2Xp0qW0b9/eWr5z50527dpl7Q3bvHkzkZGRPProo5QsWZIjR44wadIkmjRpwp49e7I1CsIwDDp16sS6det47rnnqFSpEnPnzqV3794Z6i5fvpzDhw/Tt29fihUrxu7du/nyyy/ZvXs3GzduxGQy0bVrV/755x9mzZrFuHHjKFSoEMBN7+WZM2eoX78+cXFxvPjiiwQFBTF9+nQ6duzInDlz6NKli0390aNH4+LiwuDBg7ly5QpjxoyhV69e/Pnnn1l+zzeze/duGjZsiL+/P2+88QZubm588cUXNGnShD/++IMHHngASEuaRo0aRb9+/ahTpw4xMTH89ddfbN261TrtpFu3buzevZsXXniBsLAwzp49y/Llyzl69OgtFxuMjIzEZDJRo0aNLMWcnvQUKFDAWhYXF0fjxo05ceIE/fv3p1SpUkRGRvLWW29x6tQpPv30UyDt5/nYY4/RvHlzPvzwQwD27t3L+vXreemll7J599IcPHiQnj170r9/fx5//HE+/vhjOnTowOTJk3n77bcZMGAAAKNGjaJHjx7s378fFxcXazy3a1/X69GjB2FhYYwaNYqNGzfy2WefcenSJb799tubxpfVe2MP6V+upP+eGT9+PB07dqRXr14kJSUxe/ZsunfvzsKFC2nXrp3NsStXruTHH39k0KBBFCpUiOrVqzNp0iSef/55unTpQteuXQFuOZR90qRJVK5cmY4dO+Lq6sqvv/7KgAEDsFgsDBw4MFvvpVevXgwbNoyZM2dy//33W8tTU1P58ccfadiwIaVKleL8+fN8/fXXPPbYYzzzzDPExsbyzTff0KpVKzZt2sR9992Xreu+9957fPDBB7Rt25a2bduydetWWrZsedMRCjVr1mTevHnZuoaISI4ZIiL5zMCBA40bf301btzYAIzJkydnqB8XF5ehrH///oa3t7eRkJBgLevdu7cRGhpqfR4VFWUARlBQkHHx4kVr+fz58w3A+PXXX61l//d//5chJsBwd3c3Dh48aC3bsWOHARgTJkywlnXo0MHw9vY2Tpw4YS07cOCA4erqmuGcN/Pmm28a7u7uhtlsNn755ZcsHXOjixcvGh4eHsZjjz2W4dyAsX//fsMwMr+fGzZsMADj22+/tZatWrXKAIxVq1ZZy268x/PmzTMAY8yYMdaylJQUo2HDhgZgTJ061Vqe2XVnzZplAMaaNWusZR999JEBGFFRURnqh4aGGr1797Y+f/nllw3AWLt2rbUsNjbWKF26tBEWFmakpqbavJdKlSoZiYmJ1rrjx483AGPnzp0ZrnW9qVOnGoCxefPmm9bp3Lmz4e7ubhw6dMhadvLkScPPz89o1KiRtax69epGu3btbnqeS5cuGYDx0Ucf3TKmzDz++ONGUFBQhvL0z8KwYcOMc+fOGadPnzbWrl1r1K5d2wCMn376yVr3/fffN3x8fIx//vnH5hxvvvmmYTabjaNHjxqGYRgvvfSS4e/vb6SkpNw0nsw+V4bxv/t5/c84NDTUAIzIyEhr2dKlSw3A8PLyMqKjo63lX3zxRYa2mdX2lR5Tx44dbeoOGDDAAIwdO3bYxHR9e8vqvcmO9HuxYsUK49y5c8axY8eM2bNnG0FBQYaXl5dx/PjxTN9fUlKSUaVKFaNZs2Y25YDh4uJi7N6926b83LlzBmD83//9X4YYMvs5ZXY/W7VqZZQpU8amrHHjxkbjxo1v+z5r165tlCxZ0vqZNAzDWLJkiQEYX3zxhWEYab87rv98Gkba56Fo0aLGU089leF9Xv9ebmxTZ8+eNdzd3Y127doZFovFWu/tt982AJufa7qRI0cagHHmzJnbvh8RkTulofUictfw8PCgb9++Gcq9vLys/46NjeX8+fM0bNiQuLg49u3bd9vzPvLIIzY9junDiQ8fPnzbY1u0aEF4eLj1ebVq1fD397cem5qayooVK+jcuTPFixe31itbtixt2rS57fkBPvvsM8aOHcv69et57LHHePTRR1m2bJlNHQ8PD959991bnqdAgQK0bduWBQsWcO3aNSCtx3z27NnUqlWL8uXLA7b3Mzk5mQsXLlC2bFkCAwMzHfp6K4sWLcLV1ZXnn3/eWmY2m3nhhRcy1L3+ugkJCZw/f566desCZPu611+/Tp06PPjgg9YyX19fnn32WY4cOcKePXts6vft2xd3d3fr8+y0hVtJTU1l2bJldO7cmTJlyljLg4OD6dmzJ+vWrSMmJgaAwMBAdu/ezYEDBzI9l5eXF+7u7qxevZpLly5lK44LFy7YtPUb/d///R+FCxemWLFiNGzYkL179/LJJ5/w8MMPW+v89NNPNGzYkAIFCnD+/Hnro0WLFqSmprJmzRrr+7h27ZrNlIA7FRERQb169azP00cxNGvWjFKlSmUov/7nlt32dWOvcnqbXbRo0U3jy+q9yYkWLVpQuHBhQkJCePTRR/H19WXu3LmUKFEiw/u7dOkSV65coWHDhpm+t8aNGxMREZHjWG683pUrVzh//jyNGzfm8OHDXLlyJdvne/zxxzl+/LjNPZo5cybu7u50794dSPvdkf75tFgsXLx4kZSUFGrVqpXt3xErVqwgKSmJF154wWY0xssvv3zTY9I/O1ldZFRE5E4okReRu0aJEiVskqx0u3fvpkuXLgQEBODv70/hwoWtC3Zl5Q/K6xMA+N8fa1lJkm48Nv349GPPnj1LfHw8ZcuWzVAvs7IbxcfH83//93/069ePWrVqWeeldunShXXr1gFw4MABkpKSrMnLrfTq1Ytr165Z53lGRkZy5MgRm0Xu4uPjee+996xzfAsVKkThwoW5fPlytv9Aj46OJjg4GF9fX5vyChUqZKh78eJFXnrpJYoWLYqXlxeFCxemdOnSQNZ+jje7fmbXSt8BITo62qb8TtrCrZw7d464uLibxmKxWDh27BiQtjr55cuXKV++PFWrVuX111+32XbLw8ODDz/8kMWLF1O0aFEaNWrEmDFjOH36dJZiMW6xBeGzzz7L8uXL+fXXX3nllVeIj4/PsNbEgQMHWLJkCYULF7Z5pM+7P3v2LJC2V3358uVp06YNJUuW5Kmnnsp0/YjsuPHnExAQAKStAZFZ+fU/t+y2r3Llytk8Dw8Px8XF5ZbrEGT13uTE559/zvLly1m1ahV79uzh8OHDtGrVyvr6woULqVu3Lp6enhQsWJDChQszadKkTN9b+vu+E+vXr6dFixb4+PgQGBhI4cKFreuW3Orzevr0aZtH+mr4jz76KGaz2bp6fUJCAnPnzqVNmzY2Xz5Nnz6datWqWdePKFy4ML/99luOfjdBxp9z4cKFb/plV/pnJ6trm4iI3AnNkReRu8b1PUDpLl++TOPGjfH392f48OGEh4fj6enJ1q1bGTJkSJYWmLrZSsa3SnjscWxW7N27l8uXL1t7Dl1dXZkzZw7NmjWjXbt2rFq1ilmzZlGkSBHr/Olbad++PQEBAcycOZOePXsyc+ZMzGYzjz76qLXOCy+8wNSpU3n55ZepV68eAQEBmEwmHn30Ubsv2HW9Hj16EBkZyeuvv859992Hr68vFouF1q1bO/S613P0zzMrGjVqxKFDh5g/fz7Lli3j66+/Zty4cUyePJl+/foBab2GHTp0YN68eSxdupR3332XUaNGsXLlylvOfw8KCrrllxLlypWzJp3t27fHbDbz5ptv0rRpU+uK6RaLhYceeog33ngj03Okj+woUqQI27dvZ+nSpSxevJjFixczdepUnnzySaZPnw7cPCG68cuDdDf7+WTl53an7SsryVtW701O1KlTx/ozuNHatWvp2LEjjRo14r///S/BwcG4ubkxderUTLd1y+x3aXYcOnSI5s2bU7FiRcaOHUtISAju7u4sWrSIcePG3fJ+BgcH2zyfOnUqffr0sf4O+/nnn/n888/59ddfiY2NtfmS8fvvv6dPnz507tyZ119/nSJFimA2mxk1alSGBRkdIf2zk742h4iIIymRF5G72urVq7lw4QK//PKLzbZq6Ss5O1uRIkXw9PTMdOXzrKyGnp48pPfWAvj4+LBo0SIefPBBWrVqRUJCAh988EGWtl7z8PDg4Ycf5ttvv+XMmTP89NNPNGvWjGLFilnrzJkzh969e/PJJ59YyxISEjJdaf52QkND+f3337l69apNr/yNe81funSJ33//nWHDhtlsQZXZ8PLs9IaFhoZmuq99+pSLnO4pnV2FCxfG29v7prG4uLjY9CoXLFiQvn370rdvX65evUqjRo0YOnSoNZGHtB7i1157jddee40DBw5w33338cknn/D999/fNI6KFSsyY8YMrly5Yu21vpV33nmHr776iv/85z/W3vTw8HCuXr2apZXv3d3d6dChAx06dMBisTBgwAC++OIL3n33XcqWLWvt+bx8+TKBgYHW424cKXGnstO+rn/t+p7rgwcPYrFYbrmYYHbujT39/PPPeHp6snTpUpvfA1OnTs3yObLzufr1119JTExkwYIFNqMksrJ6/I1TLSpXrmz9d69evViyZAmLFy9m5syZ+Pv706FDB+vrc+bMoUyZMjbbcELalJDsSv/sHzhwwGa6y7lz5276ZVdUVJR1hJKIiKNpaL2I3NXSe+Ku73lLSkrKM3tem81mWrRowbx58zh58qS1/ODBgyxevPi2x1etWpWiRYsyceJEm2G5QUFBTJ06lfPnzxMfH2/zx+7t9OrVi+TkZPr378+5c+cy7B1vNpsz9EBPmDDhpr2kt9K2bVtSUlJstqVKTU1lwoQJGa4JGXu+M1vl28fHByBLXyy0bduWTZs2sWHDBmvZtWvX+PLLLwkLC7vjecJZZTabadmyJfPnz7cZmn3mzBlmzpzJgw8+iL+/P0CG7dB8fX0pW7YsiYmJQNrK6DdugxYeHo6fn5+1zs3Uq1cPwzDYsmVLluIODAykf//+LF26lO3btwNpPdsbNmxg6dKlGepfvnyZlJSUTN+Hi4uLdRX09DjT15e4fl70tWvXrD329pKd9pXu888/t3me3mZvtbZFVu+NvZnNZkwmk81n9MiRI9laYT19N4qsfK4yu59XrlzJ0hcHLVq0sHlc30PfuXNnvL29+e9//8vixYvp2rUrnp6et7zun3/+afP5zqoWLVrg5ubGhAkTbM53qzaxZcsWmzUaREQcST3yInJXq1+/PgUKFKB37968+OKLmEwmvvvuu1wdCn07Q4cOZdmyZTRo0IDnn3+e1NRUJk6cSJUqVazJ0c24uroyceJEHnnkEapWrUr//v0JDQ1l7969TJkyhapVq3L8+HE6derE+vXrrcngrTRu3JiSJUsyf/58vLy8rFtNpWvfvj3fffcdAQEBREREsGHDBlasWGHd5io7OnToQIMGDXjzzTc5cuQIERER/PLLLxnms/r7+1vneicnJ1OiRAmWLVuW6ciKmjVrAmm9xY8++ihubm506NDBmuBf780332TWrFm0adOGF198kYIFCzJ9+nSioqL4+eefrVuT2cuUKVMynQf+0ksv8cEHH7B8+XIefPBBBgwYgKurK1988QWJiYmMGTPGWjciIoImTZpQs2ZNChYsyF9//cWcOXMYNGgQAP/88w/NmzenR48eRERE4Orqyty5czlz5ozNFInMPPjggwQFBbFixQrrPuS389JLL/Hpp58yevRoZs+ezeuvv86CBQto3749ffr0oWbNmly7do2dO3cyZ84cjhw5QqFChejXrx8XL16kWbNmlCxZkujoaCZMmMB9991nXaOgZcuWlCpViqeffprXX38ds9nMlClTKFy4MEePHs3qbb+t7LSvdFFRUXTs2JHWrVuzYcMGvv/+e3r27En16tVvekxW7w1Anz59rG3xVr38WdGuXTvGjh1L69at6dmzJ2fPnuXzzz+nbNmyNusr3IqXlxcRERH88MMPlC9fnoIFC1KlShWqVKmSoW7Lli2toy369+/P1atX+eqrryhSpAinTp3K8fvw9fWlc+fO1ukAN37J2L59e3755Re6dOlCu3btiIqKYvLkyURERHD16tVsXatw4cIMHjyYUaNG0b59e9q2bcu2bdtYvHhxpkPnz549y99//53trfVERHIs9xfKFxG5Mzfbfq5y5cqZ1l+/fr1Rt25dw8vLyyhevLjxxhtvWLelutXWaOlbbmW2jRc3bF10s+3nBg4cmOHYG7ekMgzD+P33340aNWoY7u7uRnh4uPH1118br732muHp6XmTu2BrzZo1RqtWrQx/f3/Dw8PDqFKlijFq1CgjLi7OWLx4seHi4mK0bNnSSE5OztL5Xn/9dQMwevTokeG1S5cuGX379jUKFSpk+Pr6Gq1atTL27duX4X1lZfs5wzCMCxcuGE888YTh7+9vBAQEGE888YSxbdu2DNvPHT9+3OjSpYsRGBhoBAQEGN27dzdOnjyZ6ZZY77//vlGiRAnDxcXFZkupzO79oUOHjIcfftgIDAw0PD09jTp16hgLFy60qZP+Xq7fZs0w/tdGro8zM+lbW93scezYMcMwDGPr1q1Gq1atDF9fX8Pb29to2rSpzXZqhmEYH3zwgVGnTh0jMDDQ8PLyMipWrGiMGDHCSEpKMgzDMM6fP28MHDjQqFixouHj42MEBAQYDzzwgPHjjz/eMsZ0L774olG2bNlM3+fNtrTr06ePYTabrVstxsbGGm+99ZZRtmxZw93d3ShUqJBRv3594+OPP7bGOWfOHKNly5ZGkSJFDHd3d6NUqVJG//79jVOnTtmce8uWLcYDDzxgrTN27Nibbj+X2bZ8mX0OM3s/WW1f6Z/1PXv2GA8//LDh5+dnFChQwBg0aJARHx9vc53M2ltW7o1hGEa3bt0MLy8v49KlS5ne83RZ2drQMAzjm2++McqVK2d4eHgYFStWNKZOnZqt31uGYRiRkZFGzZo1DXd3d5v7ktl5FixYYFSrVs3w9PQ0wsLCjA8//NCYMmVKhp9bVrefS/fbb78ZgBEcHGyzFZ1hGIbFYjFGjhxphIaGGh4eHkaNGjWMhQsXZvp758afa2ZtKjU11Rg2bJgRHBxseHl5GU2aNDF27dqV6c910qRJhre3txETE5Pl9yIicidMhpGHuqVERMSqc+fOt9xmTMQRDh8+TMWKFVm8eDHNmzd3djj3rKJFi/Lkk0/y0UcfOTsUyYIaNWrQpEkTxo0b5+xQROQeoTnyIiJ5QPoWS+kOHDjAokWLaNKkiXMCkntWmTJlePrppxk9erSzQ7ln7d69m/j4eIYMGeLsUCQLlixZwoEDB3jrrbecHYqI3EPUIy8ikgcEBwfTp08fypQpQ3R0NJMmTSIxMZFt27Zl2MdYRERERO5tWuxORCQPaN26NbNmzeL06dN4eHhQr149Ro4cqSReRERERDJQj7yIiIiIiIhIPqI58iIiIiIiIiL5iBJ5ERERERERkXwkX8+Rt1gsnDx5Ej8/P0wmk7PDERERERERkbucYRjExsZSvHhxXFyc0zeerxP5kydPEhIS4uwwRERERERE5B5z7NgxSpYs6ZRr5+tE3s/PD0i7gf7+/k6OJnPJycksW7aMli1b4ubm5uxwJB9TWxJ7UnsSe1J7EntRWxJ7UnsSe7mxLcXExBASEmLNR50hXyfy6cPp/f3983Qi7+3tjb+/v36ByB1RWxJ7UnsSe1J7EntRWxJ7UnsSe7lZW3Lm9G4tdiciIiIiIiKSjyiRFxEREREREclHlMiLiIiIiIiI5CP5eo68iIiIiORvhmGQkpJCamoqycnJuLq6kpCQQGpqqrNDk3xO7Ulyymw24+rqmqe3OFciLyIiIiJOkZSUxKlTp4iLiwPSkvpixYpx7NixPP0HtOQPak9yJ7y9vQkODsbd3d3ZoWRKibyIiIiI5DqLxUJUVBRms5nixYvj7u6OYRhcvXoVX19fXFw0A1TujMViUXuSbDMMg6SkJM6dO0dUVBTlypVzdkiZUiIvIiIiIrkuKSkJi8VCSEgI3t7eQFrilZSUhKenpxIvuWNqT5JTXl5euLm5ER0dTVJSEmaz2dkhZaAWLSIiIiJOowRLRPKivP67KW9HJyIiIiIiIiI2lMiLiIiIiIiI5CNK5EVEREREnCgsLIxPP/00y/VXr16NyWTi8uXLDospL7pw4QJFihThyJEjzg5F8rm6devy888/OzuMO6JEXkREREQkC0wm0y0fQ4cOzdF5N2/ezLPPPpvl+vXr1+fUqVMEBATk6HpZlde+MBgxYgSdOnUiLCzM2aHkqqFDh2ba3ipWrAhA1apVee655zI99rvvvsPDw4Pz589by1q1aoXZbGbz5s0Z6vfp04fOnTvnKM4dO3bQsWNHihQpgqenJ2FhYTzyyCOcPXv2pu/h+kf69TN7rXXr1tbrhIWFWct9fHy4//77+emnn6yvx8XF8dZbbxEeHo6npyeFCxemcePGzJ8/31rnP//5D2+++SYWiyVH7zUvUCIvIiIiIpIFp06dsj4+/fRT/P39bcoGDx5srWsYBikpKVk6b+HCha0r92eFu7s7xYoVu6f2Ro+Li+Obb77h6aefdnYoDpOUlHTT1ypXrmzT1k6dOsW6desAePrpp5k9ezbx8fEZjps6dSodO3akUKFCABw9epTIyEgGDRrElClT7Bb7uXPnaN68OQULFmTp0qXs3buXqVOnUrx4ca5du8bgwYNtYi9ZsiTDhw+3KUvXunXrDO911qxZNtdLP3bbtm3Url2bRx55hMjISACee+45fvnlFyZMmMC+fftYsmQJDz/8MBcuXLAe36ZNG2JjY1m8eLHd7kFuUyIvIiIiInmCYRjEJ6USl5SSqw/DMLIUX7FixayPgIAATCaT9fm+ffvw8/Nj8eLF1KxZEw8PD9atW8ehQ4fo1KkTRYsWxdfXl9q1a7NixQqb8944tN5kMvH111/TpUsXvL29KVeuHAsWLLC+fmNP+bRp0wgMDGTp0qVUqlQJX19fazKULiUlhRdffJHAwECCgoIYMmQIvXv3znHvK8ClS5d48sknKVCgAN7e3rRp04YDBw5YX4+OjqZDhw4UKFAAHx8fKleuzKJFi6zH9urVi8KFC+Pl5UW5cuWYOnXqTa+1aNEiPDw8qFu3rrUsNTWVp59+mtKlS+Pl5UWFChUYP3689fVly5ZRrFixDCMKXnrpJZo1a2Z9/tVXX1m3QezSpQtjx44lMDDwprEcOXIEk8nE7NmzqV+/Pp6enlSpUoU//vjDpt6uXbto06YNvr6+FC1alCeeeMKmZ7xJkyYMGjSIl19+mUKFCtGqVaubXtPV1dWm/RUrVsyanD/++OPEx8dnGCoeFRXF6tWrbb78mDp1Ku3bt+f5559n1qxZmSb/ObF+/XquXLnC119/TY0aNShdujRNmzZl3LhxlC5dGl9fX5vYzWYzfn5+NmXpPDw8MrzXAgUK2Fwv/djy5cvz+eef4+Xlxa+//grAggULePvtt2nbti1hYWHUrFmTF154gaeeesp6vNlspm3btsyePdsu798ZtI+8iIiIiOQJ8cmp1Bu7Mdevu2d4K7zd7fNn8ZtvvsnHH39MmTJlKFCgAMeOHaNt27aMGDECDw8Pvv32Wzp06MD+/fspVarUTc8zbNgwxowZw0cffcSECRPo1asX0dHRFCxYMNP6cXFxfPzxx3z33Xe4uLjw+OOPM3jwYGbMmAHAhx9+yIwZM5g6dSqVKlVi/PjxzJs3j6ZNm+b4vfbp04cDBw6wYMEC/P39GTJkCG3btmXPnj24ubkxcOBAkpKSWLNmDT4+PuzZswdfX18A3n33Xfbs2cPixYspVKgQBw8evGVSuXbtWmrWrGlTZrFYKFmyJD/99BNBQUFERkby7LPPEhwcTI8ePWjevDkBAQH8/PPPPPPMM0Ba8v/DDz8wYsQIIC0Bfe655/jwww/p2LEjK1as4N13383S+3/99df59NNPiYiIYOzYsXTo0IGoqCiCgoK4fPkyzZo1o1+/fowbN474+HiGDBlCjx49WLlypfUc06dP5/nnn2f9+vXZuvfXK1SoEJ06dWLKlCk8/vjj1vJp06ZRsmRJWrZsCaR9UTZ16lQ+//xzKlasSNmyZZkzZw5PPPFEjq+drlixYqSkpDB37lwefvjhXB0t4urqipubm3VEQ7FixVi0aBFdu3bFz8/vpsfVqVOH0aNH51aYdqceeREREREROxk+fDgPPfQQ4eHhFCxYkOrVq9O/f3+qVKlCuXLleP/99wkPD7fpYc9Mnz59eOyxxyhbtiwjR47k6tWrbNq06ab1k5OTmTx5MrVq1eL+++9n0KBB/P7779bXJ0yYwFtvvUWXLl2oWLEiEydOvGWv8+2kJ/Bff/01DRs2pHr16syYMYMTJ04wb948IG0Yd4MGDahatSplypShffv2NGrUyPpajRo1qFWrFmFhYbRo0YIOHTrc9HrR0dEUL17cpszNzY1hw4ZRq1YtSpcuTa9evejbty8//vgjkNbr2rVrV5te199//53Lly/TrVs3631p06YNgwcPpnz58gwYMIA2bdpk6R4MGjSIbt26UalSJSZNmkRAQADffPMNABMnTqRGjRqMHDmSihUrUqNGDaZMmcKqVav4559/rOcoV64cY8aMoUKFClSoUOGm19q5cye+vr42j+vnxT/99NOsXr2aqKgoIC1pnz59Or1797buh75ixQri4uKsPf+PP/64Nd47VbduXd5++2169uxJoUKFaNOmDR999BFnzpzJ9rkWLlyY4b2OHDky07pJSUmMGjWKK1euWEdZfPnll0RGRhIUFETt2rV55ZVXMv2ipHjx4hw7dizfzpNXj3wuOH4Nluw+Q0SJQMIL+zo7HBEREZE8ycvNzIZX6+Ln72dNPnLruvZSq1Ytm+dXr15l6NCh/Pbbb5w6dYqUlBTi4+M5evToLc9TrVo16799fHzw9/fn7NmzN63v7e1NeHi49XlwcLC1/pUrVzhz5gx16tSxvm42m6lZs2aOk5i9e/fi6urKAw88YC0LCgqiQoUK7N27F4AXX3yR559/nmXLltGiRQu6detmfV/PP/883bp1Y+vWrbRs2ZLOnTtTv379m14vPj4eT0/PDOWff/45U6ZM4ejRo8THx5OUlMR9991nfb179+489NBDnDx5kuLFizNjxgzatWtn/RJj//79dOnSxeacderUYeHChbe9B/Xq1bP+29XVlVq1alnf+44dO1i1apV1BML1Dh06RPny5QEyjDK4mQoVKmT48sff39/674ceeoiSJUsydepUhg8fzu+//87Ro0fp27evtc6UKVN45JFHcHVNSwEfe+wxXn/9dQ4dOmTTdnJqxIgRvPrqq6xcuZI///yTyZMnM3LkSNasWUPVqlWzfJ6mTZsyadIkm7IbR6IMGTKE//znPyQkJODr68vo0aNp164dAI0aNeLw4cNs3LiRyMhIfv/9d8aPH8+wYcNsRlt4eXlhsVhITEzEy8vrDt65c6hHPhesPuXCC7N3sHxP9r+REhEREblXmEwmvNzNeLu75urDnsOAfXx8bJ4PHjyYuXPnMnLkSNauXcv27dupWrXqLRc2g7Te5hvvza2S7szqZ3Xuv6P069ePw4cP88QTT7Bz505q1arFhAkTgLTFxqKjo3nllVc4efIkzZs3t1ks8EaFChXi0qVLNmWzZ89m8ODBPP300yxbtozt27fTt29fm3t7//33Ex4ebl0Mbu7cufTq1csxb/g6V69epUOHDmzfvt3mceDAAeuoBMjYXm7G3d2dsmXL2jyKFClifd3FxYU+ffowffp0LBYLU6dOpWnTppQpUwaAixcvMnfuXP773//i6uqKq6srJUqUICUlxa6L3gUFBdG9e3c+/vhj9u7dS/Hixfn444+zdQ4fH58M7/XGRP71119n+/btHD9+nEuXLjFkyBCb193c3GjYsCFDhgxh2bJlDB8+nPfff9+mbVy8eBEfH598mcSDEvlc4f7vXY5PSnVuICIiIiKSq9avX0+fPn3o0qULVatWpVixYrm+D3pAQABFixa12W4sNTWVrVu35viclSpVIiUlhT///NNaduHCBfbv309ERIS1LCQkxLqK+GuvvcZXX31lfa1w4cL07t2b77//nk8//ZQvv/zypterUaMGe/bssSlbv3499evXZ8CAAdSoUYOyZcty6NChDMf27NmTGTNm8Ouvv+Li4mLtuYW0nu4bt2HLbFu2zGzc+L/1HFJSUtiyZQuVKlUC0r5A2L17N2FhYRmS0qwm79nVt29fjh07xi+//MLcuXNtFrmbMWMGJUuWZMeOHTZfLHzyySdMmzaN1FT75ynu7u6Eh4dz7do1u5+7UKFClC1bNsu7N0RERJCSkkJCQoK1bNeuXdSoUcPuseUWDa3PBemJfEKyEnkRERGRe0m5cuX45Zdf6NChAyaTiXfffdcpc3JfeOEFRo0aRdmyZalYsSITJkzg0qVLWUqCdu7cabNomMlkonr16nTq1IlnnnmGL774Aj8/P958801KlChBp06dAHj55Zdp06YN5cuX59KlS6xatcqa6L733nvUrFmTypUrk5iYyMKFC62vZaZVq1a89dZbXLp0ybqCebly5fj2229ZunQppUuX5rvvvmPz5s2ULl3a5tiePXsybNgwRowYwcMPP4yHh4fNfWnUqJF1sbqVK1eyePHiLN2Xzz//nHLlylGpUiXGjRvHpUuXrCujDxw4kK+++orHHnuMN954g4IFC3Lw4EFmz57N119/jdmcvekcKSkpnD592qbMZDJRtGhR6/PSpUvTrFkznn32WTw8POjatav1tW+++YaHH36YKlWq2JwjJCSEt956iyVLlli/4Lhy5Qrbt2+3qRcUFERISMhN41u4cCGzZ8/m0UcfpXz58hiGwa+//sqiRYtuuRtBZhITEzO8V1dXV+sq/bfTpEkTHnvsMWrVqkVQUBB79uzh7bffpmnTpjbTEdauXWtdCDA/Uo98LnD/93Mapx55ERERkXvK2LFjKVCgAPXr16dDhw60atWK+++/P9fjGDJkCI899hhPPvkk9erVw9fXl1atWmU67/xGjRo1okaNGtZH+rzuqVOnUrNmTdq3b0+9evUwDINFixZZh/mnpqYycOBAKlWqROvWrSlfvjz//e9/gbTe2rfeeotq1arRqFEjzGbzLbcCq1q1Kvfff791ITuA/v3707VrVx555BEeeOABLly4wIABAzIcW7ZsWerUqcPff/+dYVh9gwYNmDx5MmPHjqV69eosWbKEV155JUv3ZfTo0YwePZrq1auzbt06FixYYE02ixcvzvr160lNTaVly5ZUrVqVl19+mcDAwByt/7B7926Cg4NtHqGhoRnqPf3001y6dImePXta38OWLVvYsWOHdYG/6wUEBNC8eXObRe9Wr15t8/OuUaMGw4YNu2V8EREReHt789prr3HfffdRt25dfvzxR77++utsr4q/ZMmSDO/1wQcfzPLxrVq1Yvr06bRs2ZJKlSrxwgsv0KpVK5u2c+LECSIjI23WEMhvTIazJ8/cgZiYGAICArhy5YrNtyt5SXJyMq9+tZhfj5p5uGZJPu5e3dkhST6VnJzMokWLaNu2bYZ5cCLZpfYk9qT2JDmRkJBAVFQUpUuXtiYcFouFmJgY/P39c3Wxu3uRxWKhUqVK9OjRg/fff9/Z4WTJb7/9xuuvv86uXbuy1D5y2p6eeeYZ9u3bx9q1azN9/ciRI5QuXZpt27bZLKwn+ceQIUO4dOnSLadzXP87ymw22/x/Li/koRpanwusc+Q1tF5EREREnCA6Opply5bRuHFjEhMTmThxIlFRUfTs2dPZoWVZu3btOHDgACdOnLjlMO/s+vjjj3nooYfw8fFh8eLFTJ8+3TpyQO5ORYoU4dVXX3V2GHdEiXwuSB9ar8XuRERERMQZXFxcmDZtGoMHD8YwDKpUqcKKFStuOS89L3r55Zftfs5NmzYxZswYYmNjKVOmDJ999hn9+vWz+3XysxkzZtC/f/9MXwsNDWX37t25HNGdee2115wdwh1TIp8LtGq9iIiIiDhTSEgI69evd3YYedL1c6ezIiwszOlb++W2jh078sADD2T6mqZUOYcS+Vzg9m8iH6eh9SIiIiIiks/4+fnZ7FwgzqdVRHJB+tD6BPXIi4iIiIiIyB1Sj7yjWVIpk7CHji6xkFAULA3AJXv7RoqIiIiIiIikUyLvSHsW4Lp4CA/HnuRhdyAR+HQStP4QIjo6OzoRERERERHJhzS03lH2LIAfn4TYk7blMafSyvcscE5cIiIiIiIikq8pkXcESyosGQIYmDK8+O8Kl0veTKsnIiIiIiIikg1K5B0hOhJiTt6iggExJ9LqiYiIiEjOWVIhai3snJP233zQUdKkSROb/dDDwsL49NNPb3mMyWRi3rx5d3xte50nP9m/fz/FihUjNjbW2aHcsRvbTm45cuQIJpOJ7du3O+wajz76KJ988onDzn+3USLvCFfP2LeeiIiIiGS0ZwF8WgWmt4efn07776dVHDaFsUOHDrRu3TrT19auXYvJZOLvv//O9nk3b97Ms88+e6fh2Rg6dCj33XdfhvJTp07Rpk0bu17rRtOmTSMwMNCh18iOt99+mxdeeCHH26eNGjWK2rVr4+fnR5EiRejcuTP79++3qZOQkMDAgQMJCgrC19eXbt26cebM//7Wv3jxIh06dMDX15caNWqwbds2m+MHDhyYa0ns6tWrMZlMXL58OVeul1X/+c9/GDFiBFeuXHF2KPmCEnlH8C1q33oiIiIiYit9PaIbR0E6cD2ip59+muXLl3P8+PEMr02dOpVatWpRrVq1bJ+3cOHCeHt72yPE2ypWrBgeHh65cq284NixY/z222/06dMnx+f4448/GDhwIBs3bmT58uUkJyfTsmVLrl27Zq3zyiuv8Ouvv/LTTz/xxx9/cPLkSbp27Wp9fcSIEcTGxrJ161aaNGnCM888Y31t48aN/Pnnn07pac9LqlSpQnh4ON9//72zQ8kXlMg7Qmh98C8OmcyQT2MC/xJp9URERETEVtK1mz+SE2zWI8oofT2iIZB49fbnzYb27dtTuHBhpk2bZlN+9epVfvrpJ55++mkuXLjAY489RokSJfD29qZq1arMmjXrlue9cWj9gQMHaNSoEZ6enkRERLB8+fIMxwwZMoTy5cvj7e1NmTJlePfdd0lOTgbSesSHDRvGjh07MJlMmEwma8w3Dq3fuXMnzZo1w8vLi6CgIJ599lmuXv3ffevTpw+dO3fm448/Jjg4mKCgIAYOHGi9Vk4cPXqUTp064evri7+/Pz169LDpvd6xYwdNmzbFz88Pf39/atasyV9//QVAdHQ0HTp0oECBAvj4+FC5cmUWLVp002vNmzeP6tWrU6JEiRzHu2TJEvr06UPlypWpXr0606ZN4+jRo2zZsgWAK1eu8M033zB27FiaNWtGzZo1mTp1KpGRkWzcuBGAvXv38uijj1K+fHmeffZZ9u7dC0BycjLPPfcckydPxmzO2hbVKSkpDBo0iICAAAoVKsS7776LYfzvs/Ddd99Rq1Yt/Pz8KFasGD179uTs2bNA2hD5pk2bAlCgQAFMJpP1Sw6LxcKYMWMoW7YsHh4elCpVihEjRthc+/DhwzRt2hRvb2+qV6/Ohg0bbF5ft24dDRs2xMvLi5CQEF588UWbLzz++9//Uq5cOTw9PSlatCgPP/ywzfEdOnRg9uzZWboP9zol8o7gYk7bYo6My91Zn7cerf3kRURERDLhMrokjCye+ePHJ7K4HtFJmNLKtvjTqhnPlw2urq48+eSTTJs2zSZx+umnn0hNTeWxxx4jISGBmjVr8ttvv7Fr1y6effZZnnjiCTZt2pSla1gsFrp27Yq7uzt//vknkydPZsiQIRnq+fn5MW3aNPbs2cP48eP56quvGDduHACPPPIIr732GpUrV+bUqVOcOnWKRx55JMM5rl27RqtWrShQoACbN2/mp59+YsWKFQwaNMim3qpVqzh06BCrVq1i+vTpTJs2LcOXGVllsVjo1KkTFy9e5I8//mD58uUcPnzYJr5evXpRsmRJNm/ezJYtW3jzzTdxc3MD0oagJyYmsmbNGnbu3MmHH36Ir6/vTa+3YcMGatasmaM4byZ96HfBggUB2LJlC8nJybRo0cJap2LFipQqVcqa6FavXp2VK1eSkpLC0qVLrSM3xowZQ5MmTahVq1aWY5s+fTqurq5s2rSJ8ePHM3bsWL7++mvr68nJybz//vvs2LGDefPmceTIEWuyHhISws8//wykrR1w6tQpxo8fD8Bbb73F6NGjeffdd9mzZw8zZ86kaFHbEcTvvPMOgwcPZvv27ZQvX57HHnuMlJQUAA4dOkTr1q3p1q0bf//9Nz/88APr1q2ztqe//vqLF198keHDh7N//36WLFlCo0aNbM5fp04dNm3aRGJiYpbvx71K+8g7SkRH6PEtLB5iswVdkncxPNqP0T7yIiIiIjmV1XWGUnPea3wzTz31FB999BF//PEHTZo0AdKG1Xfr1o2AgAACAgIYPHiwtf4LL7zA0qVL+fHHH6lTp85tz79ixQr27dvH0qVLKV487YuGkSNHZpjX/p///Mf677CwMAYPHszs2bN544038PLywtfXF1dXV4oVK3bTa82cOZOEhAS+/fZbfHx8AJg4cSIdOnTgww8/tCZxBQoUYOLEiZjNZipWrEi7du34/fffbYaHZ9Xvv//Ozp07iYqKIiQkBIBvv/2WypUrs3nzZmrXrs3Ro0d5/fXXqVixIgDlypWzHn/06FG6detG1apVAShTpswtr3fs2DHq1q2boXzOnDmMGTOGw4cPU6VKFR5//HG6deuGr68vP/zwA4cPH+a9997LcJzFYuHll1+mQYMGVKlSBYDTp0/j7u6eYV2AokWLcvr0aQDefPNNnn/+ecLDwwkLC+Obb77hwIEDTJ8+nQ0bNvDcc8+xbNkyatWqxVdffUVAQMBN31NISAjjxo3DZDJRoUIFdu7cybhx46w/j6eeespat0yZMnz22WfUrl2bq1ev4uvra/0CokiRItaYY2NjGT9+PBMnTqR3794AhIeH8+CDD9pce/DgwbRr1w6AYcOGUblyZQ4ePEjFihUZNWoUvXr1sk4RKFeuHJ999hmNGzdm0qRJHD16FB8fH9q3b4+fnx+hoaHUqFHD5vzFixcnKSmJ06dPExoaetN7IErkHSuiIynhLTn2VS/KnF9BZGolUjvNo2GFm/9CFREREbnXWd48jovLTQaOmsxwfHPWTtR6pO3zl3feWWCk9bTWr1+fKVOm0KRJEw4ePMjatWsZPnw4AKmpqYwcOZIff/yREydOkJSURGJiYpbnwO/du5eQkBBrEg9Qr169DPV++OEHPvvsMw4dOsTVq1dJSUnB398/W+9l7969VK9e3ZrEAzRo0ACLxcL+/futiXzlypVthn0HBwezc2fO7mX6+0tP4gEiIiIIDAxk79691K5dm1dffZV+/frx3Xff0aJFC7p37054eDgAL774Is8//zzLli2jRYsWdOvW7ZbrEiQkJODp6WlTdvToUT744AOGDx9OaGgoa9as4csvv+SZZ57Bzc2NBx54gEmTJmV6voEDB7Jr1y7WrVuXrfcdEBDAzJkzbcqaNWvGRx99xIwZMzh8+DD79+/nmWeeYfjw4bdc+K5u3bqYTP8b9VuvXj0++eQTUlNTMZvNbNmyhaFDh7Jjxw4uXbpkHV1w9OhRIiIiMj3n3r17SUxMpHnz5rd8H9ff6+DgYADOnj1LxYoV2bFjB3///TczZsyw1jEMA4vFQlRUFA899BChoaGUKVOG1q1b07p1a7p06WLz2fDy8gIgLi7ulnGIhtY7nouZGK+0X1RX8SY+xcnxiIiIiOR17j43f7h5Zn09ojJNb3/eHHj66af5+eefiY2NZerUqYSHh9O4cWMAPvroI8aPH8+QIUNYtWoV27dvp1WrViQlJeXoWpnZsGEDvXr1om3btixcuJBt27bxzjvv2PUa10sf1p7OZDLdcuj5nRo6dCi7d++mXbt2rFy5koiICObOnQtAv379OHz4ME888QQ7d+6kVq1aTJgw4abnKliwIJcuXbIpK1KkCBs3bqRjx45Ur16dF154gU2bNnHhwgUuXLjA2rVrrb3t1xs0aBALFy5k1apVlCxZ0lperFgxkpKSMqwCf+bMmZuOiJg6dSqBgYF06tSJ1atX07lzZ9zc3OjevTurV6/O4p3KKH26hL+/PzNmzGDz5s3We3er9pGeQN/O9W0h/cuE9LZw9epV+vfvz/bt262PHTt2cODAAcLDw/Hz82Pr1q3MmjWL4OBg3nvvPapXr25z3y5evAikLQApt6ZEPhec9a/KhwXfZ1zKw8Qn5/29TUVERETytOvWI8qYzDt+PaIePXrg4uLCzJkz+fbbb3nqqaesSc369evp1KkTjz/+ONWrV6dMmTL8888/WT53pUqVOHbsGKdOnbKWpS+Yli4yMpLQ0FDeeecdatWqRbly5YiOjrap4+7uTmrqrf/urFSpEjt27LBZjGz9+vW4uLhQoUKFLMecHenv79ixY9ayPXv2cPnyZZve4vLly/PKK6+wbNkyunbtytSpU62vhYSE8Nxzz/HLL7/w2muv8dVXX930etWqVWPPnj02ZZ6enhl66SEt6c9sizrDMBg0aBBz585l5cqVlC5d2ub1mjVr4ubmxu+//24t279/P0ePHs10NMW5c+cYPny49QuI1NRU6+KBycnJt/25/fnnnzbPN27cSLly5TCbzezbt48LFy4wevRoGjZsSMWKFa0L3aVzd3e3XjdduXLl8PLysnkP2XX//fezZ88eypYtm+GRfk1XV1datGjBmDFj+Pvvvzly5AgrV660nmPXrl2ULFmSQoUK5TiOe4US+VwQ716I/X512WuEEp+kRF5ERETkjqWvR+QfbFvuXzyt3IHrEfn6+vLII4/w1ltvcerUKZutzcqVK8fy5cuJjIxk79699O/f32ZF9ttp0aIF5cuXp3fv3uzYsYO1a9fyzjvv2NQpV64cR48eZfbs2Rw6dIjPPvvM2uuaLiwsjKioKLZv38758+czXTysV69eeHp60rt3b3bt2sWqVat44YUXeOKJJzIscpZdqampNj2z27dvZ+/evbRo0YKqVavSq1cvtm7dyqZNm3jyySdp3LgxtWrVIj4+nkGDBrF69Wqio6NZv349mzdvplKlSgC8/PLLLF26lKioKLZu3cqqVausr2WmWbNmbNy48bbJ8a0MHDiQ77//npkzZ+Ln58fp06c5ffo08fHxQNqw+aeffppXX32VVatWsWXLFvr27Uu9evUynZ//8ssv89prr1lX0m/QoAHfffcde/fu5csvv6RBgwa3jOfo0aO8+uqr7N+/n1mzZjFhwgReeuklAEqVKoW7uzsTJkzg8OHDLFiwgPfff9/m+NDQUEwmEwsXLuTcuXNcvXoVT09PhgwZwhtvvMG3337LoUOH2LhxI998802W79OQIUOIjIxk0KBBbN++nQMHDjB//nzrYncLFy7ks88+Y/v27URHR/Ptt99isVhsvjRau3YtLVu2zPI172lGPnblyhUDMK5cueLsUG4qKSnJmDdvnjHgu7+M0CELjW/WHnZ2SJJPpbelpKQkZ4cidwG1J7EntSfJifj4eGPPnj1GfHy8tSw1NdW4dOmSkZqamvUTpaYYxuE1hvH3T2n/TU1xQLQZRUZGGoDRtm1bm/ILFy4YnTp1Mnx9fY0iRYoY//nPf4wnn3zS6NSpk7VO48aNjZdeesn6PDQ01Bg3bpz1+f79+40HH3zQcHd3N8qXL28sWbLEAIy5c+da67z++utGUFCQ4evrazzyyCPGuHHjjICAAOvrCQkJRrdu3YzAwEADMKZOnWoYhpHhPH///bfRtGlTw9PT0yhYsKDxzDPPGLGxsdbXe/fubRO7YRjGSy+9ZDRu3Pim92bq1KkGafsA2jzCw8MNwzCM6Ohoo2PHjoaPj4/h5+dndO/e3Th9+rRhGIaRmJhoPProo0ZISIjh7u5uFC9e3Bg0aJC1nQwaNMgIDw83PDw8jMKFCxtPPPGEcf78+UzjSE1NNc6dO2cUL17cWLJkyU3jvZ3M3sv199Qw0trzgAEDjAIFChje3t5Gly5djFOnTmU415IlS4w6derYtPFr164Z3bt3N/z8/IzmzZsbZ86cuWksjRs3NgYMGGA899xzhr+/v1GgQAHj7bffNiwWi7XOzJkzjbCwMMPDw8OoV6+esWDBAgMwtm3bZq0zfPhwo1ixYobJZDJ69+5tvV8ffPCBERoaari5uRmlSpUyRo4caRiGYURFRWU4x6VLlwzAWLVqlbVs06ZNxkMPPWT4+voaPj4+RrVq1YwRI0YYhmEYa9euNRo3bmwUKFDA8PLyMqpVq2b88MMPNvcwICDA2LBhwy1/Hrnl+t9RN/5/Li/koSbDuG7vjHwmJiaGgIAArly5ku3FPXJLcnIyv8+fyZULx1kbHU+lh/owsGlZZ4cl+VBycjKLFi2ibdu2GeaqiWSX2pPYk9qT5ERCQgJRUVGULl3aOszZYrEQExODv7//zRe7E8mi9Pb0/fff8+uvv7J06VJnhyS3MGnSJObOncuyZcucHQpg+zvKbDbb/H8uL+ShWrU+F/gknqH1qTHUcg1mXvITzg5HREREROSe8eyzz3LlyhViY2MznQMveYObm9stFy4UW0rkc4HFJa13wtOURJzmyIuIiIiI5BpXV9cM6wxI3tOvXz9nh5CvaMxSLkg1pa3S6EGyVq0XERERERGRO6JEPhek98h7kEyCeuRFRERERETkDiiRzwWppn+H1qOh9SIiIiLXy8frLovIXSyv/25SIp8LUv/tkXczpZKYlOTkaEREREScL32Hg7i4OCdHIiKSUfrvpry6G4sWu8sFln/nyAOkJCY4MRIRERGRvMFsNhMYGMjZs2cB8Pb2xjAMkpKSSEhI0PZzcscsFovak2SbYRjExcVx9uxZAgMDMZvNWCwWZ4eVgRL5XJDq4saOep8y/o/jxKaYnB2OiIiISJ5QrFgxAGsybxgG8fHxeHl5YTLpbya5M2pPcicCAwOtv6PyIiXyucHkQmzptqxc9RdllciLiIiIAGAymQgODqZIkSIkJyeTnJzMmjVraNSoUZ4dzir5h9qT5JSbmxtms9nZYdySEvlc4uWW1hDitdidiIiIiA2z2Wx9pKSk4OnpqcRL7pjak9zNNFkklxQ+uZKuLmtwS7rs7FBEREREREQkH1OPfC4pvuH/GOt+koeTQ5wdioiIiIiIiORj6pHPLa4eaf9NScRiydt7EoqIiIiIiEjepUQ+l5jcvADwNCWTmJL3ti8QERERERGR/EGJfC4xuXoC4EEScUkpTo5GRERERERE8isl8rnFLW1ovQfJxCdr5XoRERERERHJGSXyucX136H1JJGgRF5ERERERERySIl8bvl3sTsPUzJx2kteREREREREckiJfC6x1OnPB56vsd5ShXgl8iIiIiIiIpJD2kc+lxihD7LB25Wjl2OI09B6ERERERERySH1yOcib3czAAnqkRcREREREZEcUo98bjm3nweTN3DN5El8cnVnRyMiIiIiIiL5lBL5XOKy60deujAeX3Mb4pLaOzscERERERERyac0tD63mNP3kdf2cyIiIiIiIpJzSuRzi6snAB4ka9V6ERERERERyTEl8rnFLS2R9zQladV6ERERERERyTEl8rnEsA6tV4+8iIiIiIiI5JwS+dyiofUiIiIiIiJiB0rkc8t1Q+vjNbReREREREREckiJfC4xilZlT1hvtlrKEhKzBSxK5kVERERERCT7tI98Lgi+vBnX798kIvYkEa7AqYXw6SfQ+kOI6Ojs8ERERERERCQfUY+8g5n2LaR21ASIPWn7Qswp+PFJ2LPAOYGJiIiIiIhIvqRE3pEsqZiXvQ2AKcOLRtp/lrypYfYiIiIiIiKSZUrkHSk6ElPsyUyS+HQGxJyA6MhcDEpERERERETyMyXyjnT1jH3riYiIiIiIyD1Pibwj+Ra1bz0RERERERG55ymRd6TQ+hh+xdNnw2fCBP4lILR+LgYlIiIiIiIi+ZkSeUdyMZPaciQAxg0z5a3PW48GF3NuRyYiIiIiIiL5lBJ5BzMqtmdz6RfAL9i23K849PhW+8iLiIiIiIhItjg1kU9NTeXdd9+ldOnSeHl5ER4ezvvvv49h3Hwwen50KrA2KYO2YRSqAMAnyQ9zvt9mJfEiIiIiIiKSba7OvPiHH37IpEmTmD59OpUrV+avv/6ib9++BAQE8OKLLzozNPtzMWNq+hb/98N6frdUpnvKzTelExEREREREbkZpybykZGRdOrUiXbt2gEQFhbGrFmz2LRpU6b1ExMTSUxMtD6PiYkBIDk5meTkZMcHnAPpcSUnJ0P59ix08+VCUhIxcQkk+7s5OTrJT2zaksgdUnsSe1J7EntRWxJ7UnsSe7mxLeWFNmUynDiOfeTIkXz55ZcsW7aM8uXLs2PHDlq2bMnYsWPp1atXhvpDhw5l2LBhGcpnzpyJt7d3boR8x4ZtNXMx0cQrVVII83N2NCIiIiIiIpIdcXFx9OzZkytXruDv7++UGJyayFssFt5++23GjBmD2WwmNTWVESNG8NZbb2VaP7Me+ZCQEM6fP++0G3g7ycnJLF++nIceegi3xIu889XP7L3kwut9ulOvTJCzw5N8xKYtuWk0h9wZtSexJ7UnsRe1JbEntSexlxvbUkxMDIUKFXJqIu/UofU//vgjM2bMYObMmVSuXJnt27fz8ssvU7x4cXr37p2hvoeHBx4eHhnK3dzc8vyH083NDbfdSxgT9x5LXWuRbOmR52OWvCk/tHfJP9SexJ7UnsRe1JbEntSexF7S21JeaE9OTeRff/113nzzTR599FEAqlatSnR0NKNGjco0kc/3vAoCEGi6yrnkVCcHIyIiIiIiIvmRU7efi4uLw8XFNgSz2YzFYnFSRA7mVQCAQK4Sl6REXkRERERERLLPqT3yHTp0YMSIEZQqVYrKlSuzbds2xo4dy1NPPeXMsBzHO61HvoDpKlcTUpwcjIiIiIiIiORHTk3kJ0yYwLvvvsuAAQM4e/YsxYsXp3///rz33nvODMtx0ofWE8vZmAQnByMiIiIiIiL5kVMTeT8/Pz799FM+/fRTZ4aRe/7tkXc3pXLpyiUnByMiIiIiIiL5kVPnyN9zzB6kmswAFD+zBiyaJy8iIiIiIiLZo0Q+l5j2LYTxVTEbacn7S5dHwadVYM8CJ0cmIiIiIiIi+YkS+VwQfHkz5p/7QsxJ2xdiTsGPTyqZFxERERERkSxTIu9ollSqHp8BGJm8+G/Zkjc1zF5ERERERESyRIm8g5mObcAr+SKmm9YwIOYEREfmYlQiIiIiIiKSXymRd7SrZ+xbT0RERERERO5pSuQdzbeofeuJiIiIiIjIPU2JvIMZIfWIdyuIcdPB9SbwLwGh9XM1LhEREREREcmflMg7mouZnSV7/fvENpm3Ln/XejS4mHMzKhEREREREcmnlMjnglOBtUntNhX8g23KL5kLQ49vIaKjkyITERERERGR/EaJfC4xKraHl3fBw1MBSDZc6BfwlZJ4ERERERERyRYl8rnJxQwV2wPgZrJwLfayc+MRERERERGRfMfV2QHcc1zdiW00lOG/n+RkkkGqxcDscvNd5kVERERERESupx55J/Bu8jK/GE2JtXhw/mqis8MRERERERGRfESJvBOYXUwU9vUA4PSVBCdHIyIiIiIiIvmJhtY7w8UjPOu2kFPmeBIPpkCJ9tp+TkRERERERLJEiXxu27MA5j3PU0lXwQ34YxZsKw6tP9QK9iIiIiIiInJbGlqfm/YsgB+fhKSrtuUxp9LK9yxwTlwiIiIiIiKSbyiRzy2WVFgyBDAyefHfsiVvptUTERERERERuQkl8rnEdGwDxJy8RQ0DYk5AdGSuxSQiIiIiIiL5jxL53HL1jH3riYiIiIiIyD1JiXxu8S1q33oiIiIiIiJyT1Iin0uMkHrgXxww3aSGCfxLQGj93AxLRERERERE8hkl8rnFxZy2xRxwYzJvpD9vPVr7yYuIiIiIiMgtKZHPTREdoce34B9sU5zkXSytXPvIi4iIiIiIyG24OjuAe05ER6jYDqIjmTB/HevPuvJox0foHFHK2ZGJiIiIiIhIPqAeeWdwMUOhcrj5FSLecOd0bLKzIxIREREREZF8Qom8s+z6heeODeYZ10WcvpLg7GhEREREREQkn1Ai7yz/zpMvarrImRgl8iIiIiIiIpI1SuSdxacIAGU4RdD5TWBJdXJAIiIiIiIikh8okXeGPQtgTl8Aglxi+eDym/BplbRyERERERERkVtQIp/b9iyAH5+Eq2dsio2YU2nlSuZFRERERETkFpTI5yZLKiwZAhgZXjKlly15U8PsRURERERE5KaUyOem6EiIOXmLCgbEnEirJyIiIiIiIpIJJfK56Ybh9HdcT0RERERERO45SuRzk29R+9YTERERERGRe44S+dwUWh/8iwOmm1QwgX+JtHoiIiIiIiIimVAin5tczND6w3+f2Cbz1uXvWo9OqyciIiIiIiKSCSXyuS2iI/T4FvyDbYovmgunlUd0dFJgIiIiIiIikh8okXeGiI7w8i54bJa16CnvCUriRURERERE5LaUyDuLixkqtMXi7g9A8qXjpFoy7i8vIiIiIiIicj0l8k5mKlAKgI6s5sKu38GS6uSIREREREREJC9TIu9MexZgunAQgOdcF1Lkl27waRXYs8DJgYmIiIiIiEhepUTeWfYsgB+fhJQE2/KYU2nlSuZFREREREQkE0rkncGSCkuGcN2mc9f5t2zJmxpmLyIiIiIiIhkokXeG6EiIOXmLCgbEnEirJyIiIiIiInIdJfLOcPWMfeuJiIiIiIjIPUOJvDP4FrVvPREREREREblnKJF3htD64F8cMN2kggn8S6TVExEREREREbmOEnlncDFD6w//fWKbzBvpz1uPTqsnIiIiIiIich0l8s4S0RF6fAv+wTbF18wB8PC0tNdFREREREREbqBE3pkiOkKrUeDuay3yTb0My97SPvIiIiIiIiKSKSXyzrRnAfzUB5Ku2hQbMafgxyeVzIuIiIiIiEgGSuSdxZIKS4YARoaXTOllS95MqyciIiIiIiLyLyXyzhIdCTEnb1HBgJgTafVERERERERE/qVE3lmunrFvPREREREREbknKJF3Ft+i9q0nIiIiIiIi9wQl8s4SWh/8i3PjPvI2TC4QdyHXQhIREREREZG8T4m8s7iYofWHt65jWNJWtdfq9SIiIiIiIvIvJfLOFNERHp6W1vN+K1q9XkRERERERP6lRN7ZfILSet5vSqvXi4iIiIiIyP8okXc2rV4vIiIiIiIi2aBE3tm0er2IiIiIiIhkgxJ5Z8vK6vVeBdPqiYiIiIiIyD1PibyzWVevN25eJ/4i7Pst10ISERERERGRvEuJfF5QsV1ar/tNmbRyvYiIiIiIiABK5POG6Mi0Xveb0sr1IiIiIiIikkaJfF6gletFREREREQki5TI5wVZXZH+wiHHxiEiIiIiIiJ5nhL5vCArK9cDrB4FexbkSkgiIiIiIiKSNymRzwuysnI9pL2uRe9ERERERETuaUrk84qIjtDk7dvX06J3IiIiIiIi9zQl8nlJUHjW6u1f5Ng4REREREREJM9SIp+XZHXRux0/aHi9iIiIiIjIPUqJfF4SWh+8g25fL/4CrPnY8fGIiIiIiIhInqNEPi9xMUO1R7JWd/VIrWAvIiIiIiJyD1Iin9dUaJv1ulrBXkRERERE5J6jRD6vse4pnwUxJyBqrWPjERERERERkTzF6Yn8iRMnePzxxwkKCsLLy4uqVavy119/OTss57HuKZ9FP/TUEHsREREREZF7iFMT+UuXLtGgQQPc3NxYvHgxe/bs4ZNPPqFAgQLODMv5srqnPGAkXYMfn1AyLyIiIiIico9wdebFP/zwQ0JCQpg6daq1rHTp0k6MKA9pNBg2fQFxF25ZzQQYgOnXl6Biu7QefREREREREblrOTWRX7BgAa1ataJ79+788ccflChRggEDBvDMM89kWj8xMZHExETr85iYGACSk5NJTk7OlZizKz2unMTnUqU75k2Tb1vPBBB/kdRVo7A0GpLt60j+cCdtSeRGak9iT2pPYi9qS2JPak9iLze2pbzQpkyGYRjOurinpycAr776Kt27d2fz5s289NJLTJ48md69e2eoP3ToUIYNG5ahfObMmXh7ezs83twWFLuXBw+OynJ9A9gcOoBTBes6LigREREREZF7WFxcHD179uTKlSv4+/s7JQanJvLu7u7UqlWLyMhIa9mLL77I5s2b2bBhQ4b6mfXIh4SEcP78eafdwNtJTk5m+fLlPPTQQ7i5uWXvYEsqrhNrQOzJtF73LDAAS6XOWDp/oWH2d5k7aksiN1B7EntSexJ7UVsSe1J7Enu5sS3FxMRQqFAhpybyTh1aHxwcTEREhE1ZpUqV+PnnnzOt7+HhgYeHR4ZyNze3PP/hzFmMbtDmw7TF7LLIBJj3zsN8aAV0/ByqdM7mNSWvyw/tXfIPtSexJ7UnsRe1JbEntSexl/S2lBfak1NXrW/QoAH79++3Kfvnn38IDQ11UkR5UERH6PEduPtm77ikqxhzesOydx0Tl4iIiIiIiDiFUxP5V155hY0bNzJy5EgOHjzIzJkz+fLLLxk4cKAzw8p7IjrCG1Hg4ZftQ43Iz2D3PPvHJCIiIiIiIk7h1ES+du3azJ07l1mzZlGlShXef/99Pv30U3r16uXMsPImV3fo9N9sHWL695H8c39ISXJIWCIiIiIiIpK7nJrIA7Rv356dO3eSkJDA3r17b7r1nJDWM//wdMjy0ndp3CwJJI4oybVtma89ICIiIiIiIvmH0xN5yaYqneHhKdk+zMNIxHv+U1yb8QRYUu0fl4iIiIiIiOQKJfL5UZWuUP/FbB9mAnwOLCBlZAjGrrn2j0tEREREREQcTol8ftXyfeg+HdyyuZo94JpyDeb0IX5mb/XOi4iIiIiI5DNK5POzyp3hraMQ1jDbh5oAr3/mkTQihOSdv9g9NBEREREREXEMJfL5nYsZnpwPXgVydLh76jVcf+5L7HeaOy8iIiIiIpIfKJG/G7iYocNnOT7cBPgdWkDCByWJ2fKT/eISERERERERu1Mif7eI6Ag9vgPPwByfwtMSh9+v/bg0/XH1zouIiIiIiORRSuTvJhEd4Y3DULlrjk9hAgpE/UrCByW5unWO/WITERERERERu1Aif7dxMUP3qTle0T6dpyUOn/lP88/E7iQnJ9sxQBEREREREbkTSuTvVukr2t9J77wJyp9fRtKIEM5v+sF+sYmIiIiIiEiOKZG/m9mpd96HeIIWPcuJLx/FkpJixwBFREREREQku5TI3wvs0TsPlDi5mLgPSrB67lckp1rsFp6IiIiIiIhknRL5e4Wdeud9SaDx9sH880Fd/vz9F1LVQy8iIiIiIpKrlMjfa+w0d76ysZ8H1vYl4YPiLJ/0KmcuX7NfjCIiIiIiInJTSuTvRXbqnQfwIZGHznyD/7hQNk4ZTEJikp2CFBERERERkcwokb+X2aF3Pp2XKZm6R78iZWQIH3/6Ed9tOEJsgratExERERERsTcl8vc6O/bOA/iQwGuXPuDcwmE0/2gl6w6ct0OQIiIiIiIikk6JvKSxU++8yZT2eNXtF1amPMGm6W/w0eLdpGiVexEREREREbtwdXYAkoek985HdIJ5AyH56h2dzteUyKuuPxOz8Tf+b8sgLBGdaFMlmPrhQbia9R2SiIiIiIhITiibkozsOHcewN+UwAfJH/Pwtr5MmjaFjp/9wcGzd/YlgYiIiIiIyL1KPfKSuet75+cPgqTYOzqdyQQ1zQeZZR5J/GU3Vk+8n99CuhNUpTmVSxTgvpBATCaTnYIXERERERG5eymRl1ur3BkqdYA1H0PkeEi68/3ivUzJtDH9SZsTf3L1uAdfpLRnXOl+9GtUjtphBfFyN9953CIiIiIiIncpDa2X23MxQ5Mh8OYxeGI+lKxtt1P7mhJ5ze1nJh7rwsxpn1Fn5Ap++/uU3c4vIiIiIiJyt1GPvGSdixnCm6Q9ds+zy4J46fxNCUxy/4ytqb/x2w912bW4KAFFQ2nbrhulCvvZ5RoiIiIiIiJ3AyXykjPpQ+7/GAN/jLbLKU1ATfMhapoPQTxwBE5NHMasMq9RsWkv/L3cKFPIR3PpRURERETknqah9ZJzLmZo+hb0+A68CjjkEsW4yCOH32HlF6/x0CereHLKJi5cTSTVYjjkeiIiIiIiInmdeuTlzkV0hIrtIGotrPoAjm+226lNprSe+tfcfqaf6yJ+imrEwJG1+cuoSINyRenbIIwmFYrY7XoiIiIiIiJ5nRJ5sY8b58/bYcu6GwWY4unnupR+LOWK4cVPhxsx+WBtfq7chKcblaNaiQBcXDTsXkRERERE7m4aWi/2V7kzvBkNTd4Gdx+HXCI9qZ/t/gH/908XJk/6hGafrGbxzlMYhobdi4iIiIjI3Us98uIY6VvWNRqcNuR+yxT4ZymkJNj9UoVMsUxy+4wvLx/i+Rm9qBlagEdqhVDY34OGZQvhatb3VSIiIiIicvdQIi+Odf2Qe0uqQ+bRQ9pc+mfdfqOOeT9jjvXgzegILLhQvqgvr7eqSLOKRTBr2L2IiIiIiNwFlMhL7nHwPHoTUMPlILPcR5KIO39wP1PPNaP/tzEEB/rQ84FS9KgVQmE/D7tdU0REREREJLcpkRfnSN+Hfs3HEDkekq7Z9fQeJNGSjbR038g1PJgc255Plnbh0xX/0LpKMI8/UIo6pQtqT3oREREREcl3lMiL82Q2j37PfLtfxodEXnP7mQFuC1iZeh+Hdpfg050RnAqoSetqJXmqQRhF/D3tfl0RERERERFHyFEif+zYMUwmEyVLlgRg06ZNzJw5k4iICJ599lm7Bij3gOuH3O9ZAEuGQMxJu1/Gi2TamTcDm3mReVyN8+CLde1pvL4bjSsUo2rJAIIDPGlSoQgFfdztfn0RERERERF7yNFy3j179mTVqlUAnD59moceeohNmzbxzjvvMHz4cLsGKPeYiI7w8i7ovRAeeB48/B12KV9TWk/9X+be1Nr/IWuXz2Xwj9to+vFqpqyL4tjFOIddW0REREREJKdylMjv2rWLOnXqAPDjjz9SpUoVIiMjmTFjBtOmTbNnfHIvcjFD6YbQZjQMOeLwpN7HlGzdk36H57O8kPw1yxbNofGY33n0yw2s3n+W5FSLQ64tIiIiIiKSXTkaWp+cnIyHR9rK3ytWrKBjx44AVKxYkVOnTtkvOpH0pL50Q2g1AqIjIXICHFjqkMv5EUc/16X0YykXDD/eOdKXPofrEujtRtcaJelcozghBbwpoKH3IiIiIiLiJDnqka9cuTKTJ09m7dq1LF++nNatWwNw8uRJgoKC7BqgiFV6Ut/rR+g+Hdz9HHq5IFMsk9w/Y7LnRGLiEpmyPoqOE9dT4/3l9Jm6ifUHz5OYkurQGERERERERG6Uox75Dz/8kC5duvDRRx/Ru3dvqlevDsCCBQusQ+5FHMrB29elMwGtieQf762s9GnDz9fuY3lcOKv3n2P1/nN4uZnpUD2Yx+qU4r6QQG1nJyIiIiIiDpejRL5JkyacP3+emJgYChQoYC1/9tln8fb2tltwIreU2fZ1/yyFlAS7X8rVkkDL2Lm0ZC6pfn5s8GvFd5ersjwunB//Os6Pfx2nRKAX77SrRNuqwXa/voiIiIiISLocJfLx8fEYhmFN4qOjo5k7dy6VKlWiVatWdg1Q5Lau377OkpqW1K/6AI5vdsjlzMmxPHhxDg8yhxRfH5b6P8yQ8605cTmeATO20qxiEbreX4KKxfwIC/LB1ZyjGSwiIiIiIiKZylEi36lTJ7p27cpzzz3H5cuXeeCBB3Bzc+P8+fOMHTuW559/3t5ximTN9Un97nnw22sQd95hl3NNuUa7i9Np6zqT/YUa8v7puqzeF8HKfWcBCA7wpHf9MNpVDSakoEariIiIiIjInctRV+HWrVtp2LAhAHPmzKFo0aJER0fz7bff8tlnn9k1QJEcq9wZBv+Ttn1d16+g5QdQopZDLmWyJFPx4kpmuI9kr/czvB/4G37uJk5dSWD04n00HLOKVuPWMGbJPrZEXyTVYjgkDhERERERufvlqEc+Li4OP7+0FcOXLVtG165dcXFxoW7dukRHR9s1QJE7kr7Sfbr6Lzi8p97DEs8TCTN43P1n/indjVmx1ZhxuiT7z8Sy/0ws/119iGL+nnS8rzid7itORLC/FskTEREREZEsy1GPfNmyZZk3bx7Hjh1j6dKltGzZEoCzZ8/i7+9v1wBF7O76nvoHngcPx7RZU0oCFaJnMPTiEPb7Ps+KSot5pdwZAjxdOB2TwJdrDtPus3W0HLeGz1cd5NjFOIfEISIiIiIid5ccJfLvvfcegwcPJiwsjDp16lCvXj0grXe+Ro0adg1QxCHSe+rbjIYhR/6X1Js9HXO5pBjKRn3HS8deYbv7s6yusoQXy5zG0xUOnL3KR0v303DMKvpN/4v9p2MdEoOIiIiIiNwdcpTIP/zwwxw9epS//vqLpUuXWsubN2/OuHHj7BacSK64Pql/5yRU7urQy5mSYgg7+C2vnnyVPd7PsbTCbzxd8jhmk4UVe8/QevwaXvlhO0cvqIdeREREREQyytEceYBixYpRrFgxjh8/DkDJkiWpU6eO3QITcQoXM3SfChGdHL7iPaT11FeInsG7zOCtgIJMDRzEiCMVmbvtBAv/Pkm7qsHcH1qAdlWD8ffQNnYiIiIiIpLDHnmLxcLw4cMJCAggNDSU0NBQAgMDef/997FYLPaOUST35dI8+uu5JlzkmdPD2RXyMc+WPEZqairztp/kvfm7aTRmFaOX7OfgFUhK0WdMRERERORelqMe+XfeeYdvvvmG0aNH06BBAwDWrVvH0KFDSUhIYMSIEXYNUsQp0ofcl24IrUZAdCTs+w22TIOUeIdd1vfcVt5mK0O8PTgQ2IDpic344UIY36yPBlyZMmoVlYL9KeLvQdMKRWhTNRhfjxwPrhERERERkXwmR3/9T58+na+//pqOHTtay6pVq0aJEiUYMGCAEnm5+9yY1EethS1T4J+lkJLgkEuaLYlUvLiSUazkfR9vlgb04K2zzYlJgr+iLwGwaOdphv+6h54PlKLr/SUpX9RXW9mJiIiIiNzlcpTIX7x4kYoVK2Yor1ixIhcvXrzjoETyNBczhDdJe1hS05L6VR/A8c0Ou6RrahztLk6jldsMztV8nm3h/TlwNp75209w+Pw1vlhzmC/WHKaQrzsVivnRo1YIbasG42bWvHoRERERkbtNjv7Kr169OhMnTsxQPnHiRKpVq3bHQYnkG+lJfb8V0H06eBdy6OVcjWSCd3xG23n38dKF91nRGb5+vAYtKhXB3ezC+atJrD94gZdmb6fF2D+Y8Wc087efIPrCNYfGJSIiIiIiuSdHPfJjxoyhXbt2rFixwrqH/IYNGzh27BiLFi2ya4Ai+UblzlCpw//m0m+fAYkxjrmWJRn2zsdl73xamD1pUb4VCU/24aD3faz85wLTI48QfSGOd+buAsBkgrZVgnm+SThVSgQ4JiYREREREckVOeqRb9y4Mf/88w9dunTh8uXLXL58ma5du7J7926+++47e8cokn9cvyf9kCO5s+p9agLsnY/nrC5UmVaJF8+/z7oeZga3CKdOWEGqhwRiGPDbzlO0n7COxh+tYuDMrWw4dAHDMBwXl4iIiIiIOESOl7ouXrx4hkXtduzYwTfffMOXX355x4GJ5Hs3W/XekT31/yb1XnvnM8jsyaDyraD20+z1qM/ktUf4dcdJoi/EEX0hjt/+PkWVEv4807AM7asVx+yiRfJERERERPID7VklkhucsZXdv0k9e+dTyc2H8Q1eYmi7F9l79hqLdp5izpbj7DoRw0uztzNh5UE6VCtO1ZL+VC0RSGE/D8fEJCIiIiIid0yJvEhuuzGpX/MxRI6HJAcuSJd8DVaPpMC6cdS/vzf1q7fn1eZN+O7P40xZH8XBs1cZt+Ifa/XgAE/qhxfixeZlCQ3ycVxcIiIiIiKSbdqbSsSZXMzQZAi8eQyemA8RncDV03HXS4mHTZNhensKTizPS0lfE/moGx90rEjX+0tQrogvJhOcupLAz1uP0/yTP3jlh+3sPH7FcTGJiIiIiEi2ZKtHvmvXrrd8/fLly3cSi8i9ywl705MYA5sm47NpMo97B/F427HQozNXE1P4+9hlvlx7mNX7zzF32wnmbjvBQxFFaV6xCBWD/Slf1Bdvdw3oERERERFxhmz9JR4QcOttqwICAnjyySfvKCCRe971Sf3ueTB/ECTFOvaacRdgTm/YUAvfyl2o71uE+k2C2dGsLlM2HOXXHSdZvucMy/ecAcDVxUTH+4rzSK0QyhbxJchXc+pFRERERHJLthL5qVOnOioOEclM+t70UWtJ3fw1xv4luBrJjrveib/SHv+q7h3E+LZjGdS0OT9tOc7eUzHsPRXL+auJ/LL1BL9sPQFA6UI+dLqvOM81DsfTzey4+ERERERERIvdieR5//bQW0o1YNFvC2kX4Yfr9m/hn6WQkuDYa//bU1+uUAXertQemjaGsKbsOBHLl2sPs+PYZU5cjifq/DU+XXGABdtPMqprVR4oE+TYuERERERE7mFK5EXyE5MLRunGUL7F/+bSb5ni+KT+/H5Yux/WfgJuPlRv8BKfPzoYXMxciU9m5b4zjFq0j8Pnr/HIlxvp37gMLSOKUinYX3PpRURERETsTH9hi+RXmS2QlxtJ/b9b2RE5ATpOJKBKZ7rUKEmzikUZumA3c7ed4Is/DvPFH4cBaF8tmJ51SlE9JBAfD/3KERERERG5U/qrWuRu4IxV75NirQvkUbkLAb5FeK6UL/O3WbBct7Plwr9PsfDvU5hMUCesIN1qlqRemSBKFvDCZDI5Lj4RERERkbuUEnmRu82Nq97/9hrEnXfc9a5bIK8CsMnDj/8k92WJpS6vPlSek5fjWbnvLGdjE/kz6iJ/Rl0EIDjAkyYVCvNKi/IU8fd0XHwiIiIiIncZJfIid7P0Ve+jI2Hfb7B9Rtr+8Q5UyBTLJLfP+MeYQ6LrSKp16Qgu1Th+KY5ftp5g5b6z7DpxhVNXEpi16RgL/z5F73phtKlajPJF/XAzu9z+IiIiIiIi9zAl8iJ3OxczlG6Y9mg14n9J/ZZpkBLvkEuaTFDBdBJW9YE/3KBCW0rWfpoXmz7Ii83LEZeUwuYjl/hk2X7+Pn6FiasOMnHVQdxdXWhTpRiP1SnFfSGB2spORERERCQTSuRF7iU3JvVrPobI8ZB0zXHXtCTD3vlpDzcfaPAS3o0G07h8YR4sW4jFu04xd+sJNkVdJDYxhfnbTzJ/+0nczS5ULRlArdAC1CldkMblC+Oq3noRERERESXyIvcsFzM0GQKNBqctjhe9Ds7uh4PLHdZTb13xft04uL835krtaV+lPu2rFcdiMdh54grTNxxhzT/nOH81iS3Rl9gSfYkv1hymXpkgJvasQZCvh2NiExERERHJJ5TIi9zrrl8cD9JWvXd0T31KPGyanPbw8IfqPXGp1J7qofUZ2+M+DMMg+kIcf0VfYkv0RRZsP8mGwxdoPvYPnqwbSrNKRYkI9sfdVT30IiIiInLvUSIvIrZu7Kk/sgb2/gbn9znmeokxGZJ6U6X2hIXWJ6xQSR6uWZKnGpRmwIytHDh7lc9WHuSzlQfxcHXhvpBA2lcvTsdqxQnwdnNMfCIiIiIieYy6s0Qkc+k99c3fg0F/Qvfp4O7n2GumJ/XT28PH5WDXPADKFfVjycuNmNizBi0qFaGAtxuJKRb+jLrIu/N2UXvECgbO2MqqfWdJTEl1bIwiIiIiIk6mHnkRyZr0rexyY4E8gLgLMKc3bKwNzd7FHPYg7asVp3214hiGQdT5a6zcd5Y5W46z73Qsv+08xW87T+FigvJF/fhPuwgeLFfIsTGKiIiIiDiBEnkRybqbLZD3zxKwJDnmmsc3w7cd00YDdJwIVTpjMpkoU9iXMoV96dewDLtPXmHOluMs2H6SC9eS2Hc6lse/+ZP7SwVSpUQAveuHEV7Y1zHxiYiIiIjkMiXyIpJ9mS2Q93M/jN2/YHLUNZNibXroCXswLQ6gcvEAKhcP4L32EZyNTWTiyoN8tzGarUcvs/XoZb7fGE1EcX9qlirA803KUizA01FRioiIiIg4XJ6ZIz969GhMJhMvv/yys0MRkexyMUP3qWx5fD/vJ/dkW2o4iYaDvidM76EfFQKrP0z7EuFfJpOJov6evN+5Cr+/1pjPHkubU28xYNeJGKZviKbZJ6t59YftLPz7JIZhOCZGEREREREHyhM98ps3b+aLL76gWrVqzg5FRO6EqzvfpLbnm9T2uGBhdx9vvNaNSku+7e2GPemp1B5C61t76cML+xJe2JeO1Ytz7GIcu05c4au1h9l69DK/bDvBL9tOsLT6Gfo9WJqwIB+tei8iIiIi+YbTe+SvXr1Kr169+OqrryhQoICzwxERO7HggrlsU+i3Im3Fe28HLTyXvif9DSvdXy+koDdtqgbz8/P1mdHvAZ5pWBpXFxO/7jhJp8/XU2vEcgbO2MrRC3GOiVFERERExI6c3iM/cOBA2rVrR4sWLfjggw9uWTcxMZHExETr85iYGACSk5NJTk52aJw5lR5XXo1P8o/80JZSUlJsCywpJCeboHw7KNsa07ENmPYvwuXv2ZgSY+wfQNwFjDm9MSJrYWnyNkZoA2sPfbo6oQHUCQ2gaflCjF1xgGMX4zkTm8hvO0+x7eglZj9Th+B7YA59fmhPkn+oPYm9qC2JPak9ib3c2JbyQpsyGU6cJDp79mxGjBjB5s2b8fT0pEmTJtx33318+umnmdYfOnQow4YNy1A+c+ZMvL29HRytiNzO4RgYvzvt+0EXDMbVu8me7oaFoKv7KXb5L0pdXI+7xTE94Sm4cSagOlGFmnPBrxKYMh+EdPwaTP/HzNkEE4HuBo2DLTxQ2MBHo+1FRERE5AZxcXH07NmTK1eu4O/v75QYnJbIHzt2jFq1arF8+XLr3PjbJfKZ9ciHhIRw/vx5p93A20lOTmb58uU89NBDuLkpK5Ccyw9taUv0JR79Om0+vIerC7v+r8XtD7Kk/q+nftt3mFLiHRKb4eaDpd4gLA1ezdBLD3Dycjw9v9nMicsJALi7utCmclE6VQ8m2WJQoagvJQK9HBKbM+SH9iT5h9qT2IvaktiT2pPYy41tKSYmhkKFCjk1kXfa0PotW7Zw9uxZ7r//fmtZamoqa9asYeLEiSQmJmI22/6x7eHhgYeHR4Zzubm55fkPZ36IUfKHvNyWXF3/9yvF3eySxTjdoGzTtEeb0bDmY1j3CaQk3v7QbDAlX8O85kPMkZ9lujheaGE3lr3SmF93nOT7P6PZdSKG+TtOMX/HqbT34+rCJ92r06F6cbvG5Wx5uT1J/qP2JPaitiT2pPYk9pLelvJCe3JaIt+8eXN27txpU9a3b18qVqzIkCFDMiTxIpK/uJpzsKO8ixmaDIFGg+GPMbD+U0hJsG9g6YvjbZoM3kHQdixU6QyAj4crj9YpxaN1SvH38cvM2HiUdQfPY3YxcfRiHC/M2sYXaw7xSO1S9KpTCheXHLxHEREREZE75LRE3s/PjypVqtiU+fj4EBQUlKFcRPIfV/MdbIrhYoamb0HjN9J66CPHQ9I1+wWXLu4CzOkNG2tDs3ch7EFrD321koFUezgQgFSLwZgl+/hq7WF2nYhh14ldTFsfxeW4ZIIDPXmkVggd7ytBgJfzv50VERERkbuf07efE5G7k5s9eqvTe+jfPAZPzIeSte/8nJk5vhm+7QgjisMPT8LhP8Dyv4X6zC4m3mpbic3vtOA/7Srh7W7m0LlrXLiWxK4TMbw7fzd1Rqzg/+bv4nJckmNiFBERERH5l9O3n7ve6tWrnR2CiNiJm6sdvyd0MUN4k7TH7nnw22sQd95+50+XmgB756c93HygwUtpw/z/7aUP8vWgX8MytKkazMZDFwgr5MOOY5eZvfko/5y5yvQN0czafIxi/p7UKxPEE/VCqVIiwP5xioiIiMg9LU8l8iJy93B11Pzxyp2hUgeIjoR9v8GWaWnz3u0t+RqsHgmRE6DjROs8eoASgV50q1kSgJqhBejbIIzIQxcY/use9p+J5ejFOI5ejOOHv47xWJ0QBjQpS8kCXphMmlMvIiIiIndOibyIOITbncyRvx0XM5RumPZoNcKx8+iTYtPm0e9oCfVftFnpPp3JZKJB2UIsfqkhRy/GcexSHD/9dZwFO04ya9MxZm06RmE/D2qWKkDnGsVpGVFMC+WJiIiISI4pkRcRh8jRqvU5cf1K91FrYcsU+Gep/Ve7P7As7XHDSvc2obiYCCvkQ1ghHxqWK0yvB0rx0dL9bD92mXOxiSzZfZolu09TtogvzzcOp03VYni769ewiIiIiGSP/oIUEYdwaI98Zq6fR29JTUvqV32QtpCdPd1ipfsbPVAmiDnP1ychOZWdJ66wat9ZvtsYzcGzV3ntpx0M+flvqpUMoO6/8+mDA7zsG6uIiIiI3JW0ar2IOISbixN/vaQn9f1WQPfp4F3I/tdIX+l+VAis/tBmlfsbebqZqR1WkDdaV2T9m814o3UFSgR6kWIx2Hr0Mv9dfYiW49YwdX0UR85fwzAM+8crIiIiIncN9ciLiEPk2tD623H04njpi+KtGwf394ZK7TOdR5/O39ONAU3K8nzjcI5fimfj4Qt8/+dRdhy7zLBf9zDs1z0U8fOgTumC1C0TROcaJfD10K9qEREREfkf/XUoIg7hmttD628lNxbHS4mHTZPTHreYR5/OZDIRUtCbkILedKlRgukbolmy6xQ7jl3hbGwiC/8+xcK/TzFh5QEeqV2KEoGeNK9UlEK+HvaLWURERETyJSXyIuIQ7nmlR/5GubE4Xjbm0UPalx5PP1iapx8sTUJyKtuPXWZT1EXmbDnO0YtxfPb7gbR6LrtoULYQzSoW4eGaJfFRT72IiIjIPUl/BYqIQ7g6c458VmS2ON7K9+HEX/a7Rvo8erMnlG8FtZ++bVLv6Wambpkg6pYJ4tlGZfhh8zH2nY5h98kY/j5+hT/+Occf/5xjwsoDPP1gGR6uWZLCfuqlFxEREbmXKJEXEYfIM3Pks+L6pH7pf2DDBPuePzUB9s5Pe7j5QIOX0kYE3CKhh7Skvnf9MOvzA2diWbnvLLM2HeXIhTg+XLKPT5btp0WlorzUohyVgv3tG7eIiIiI5El5vMtMRPKrXN9+zl5afeC4le7hf4vjjSwBi4akjQS4xYr31ytX1I/+jcNZ/mpjxjxcjftCAkmxGCzZfZqeX23kTIwdpweIiIiISJ6lHnkRcQi3/NQjfyNHr3QPtovjefhD9Z63XfE+nZvZhR61QuhRK4R9p2N45Ycd7D0Vw8AZW+lUowQPli1E6UI+9o1XRERERPIMJfIi4hB5atX6nMiNle7TJcZka8X761Us5s/EnjVo/9k6/oq+xF/RlzC7mGhRqQgBXm6EFfLhgdJB1AwtYP+4RURERMQplMiLiEO4ueTjHvkb3bjS/aoP0hayc4T0Fe9PDEr7AiELwgv78t3TdZi56SgnL8ez8fBFlu4+Y1OnYblCPF43lLplggjwcnNE5CIiIiKSS5TIi4hD5Pse+cxcvyje7nnw22sQd94x19owEY5uhObv3Xale4BaYQWpFVYQgK1HL7E56iKJKRb2nY5h+Z4zrD1wnrUHzuNigqolAuhaozg+FseELiIiIiKOpUReRBwi3y52l1W5MY/+xF/Z3r4O4P5SBbi/1P+G0kdfuMaUdVGsPXiew+euseP4FXYcv4ILZj7a+wfF/D25LySQ/o3DKR7oZd/3ICIiIiJ2p0ReRBwiXy92l1W5NY/++u3rspnUA4QG+TCsUxUATl2JZ/HO03y19jCnriRwJiaRMzGJ7Dh+hVmbjtGofGE61yhO2yrBuNxN0yNERERE7iJK5EXEIVxd7vIe+RvdOI9+yxT4Zymk2HlLuBzuSZ8uOMCLpx4sTa/aJZg9fzFVajfgdGwy0zccYVPURVbsPcOKvWcoU/gfyhfxI6SgFzVDC9CsYlHcXe+xn6mIiIhIHqVEXkQcwvVe6JHPzPXz6C2pjl0cL31P+nXj4P7eWd6+DsDFxUSgB1QrGUBNNzfaVi3G3lOxLN51immRRzh87hqHz6WNLPhqbRTF/D3pUask9cILUbKAF8UDvTCrx15ERETEKZTIi4hDuN/tc+SzIrcWx7uDPenTmUwmIor7E1Hcn34PlmHNgXNcvJbEgbOxLN9zhtMxCXy28iCfrTwIQDF/T7rVLMGzjcK1Cr6IiIhILlMiLyIOcc/2yN/MjYvjbZ+Rtn+8vd3BnvTpArzd6FC9uPX5u+0j+O3vU/y+7yw7jl3mbEwip2MS+HzVIX786zh1ywRhAkoX8qFt1WAqFPOz73sSERERERtK5EXEIe7K7efu1I2L40VHQuQEOLDUMddL35N+Y21o9m6WF8e7kYerma73l6Tr/SUBSExJZcWes3yybD+Hz1/j1x0nrXUnrDxA5xolaBlRjMblC+Plnv3riYiIiMitKZEXEYdw0/zpW7s+qd89D+YPgqRYx1zr+OaM29iVeCDHp/NwNdOuWjAtIoowf/tJriakkJxqYfORS6zYe4Zftp7gl60n8Pd0pUVEUYJ83Akr5MP9pQpQKdjfjm9MRERE5N6kRF5EHOKu30fentKH3Ttq+7p0161472r2pJZvFUxRvlC2SY576nvUCrE+798YtkRfYsH2E/y+7yzHL8Xzy9YTNsdUCvane82SNChbCC83MyEFvTCZ9KWPiIiISHYokRcRh9Ac+WzKre3r/mVKTaDElb9gZtcc7U1/MzVDC1AztAD/18FgzYFz7Dx+hcvxyfxzJpY/D19k76kYhi/cY61ft0xBhneqQvmimlcvIiIiklVK5EXEIdQjn0OZbV/n4KTeZm96V69sb2WXGRcXE00qFKFJhSLWsstxSSzYcZKftxwn+mIcVxNS2Hj4Ip0mrmf6U3WoU7qgvd6RiIiIyF1NibyIOISr5sjfudzckz6dHbayu5lAb3eerBfGk/XCADh2MY435vzNhsMXeGraZnrUCqFFRBHqhxeywxsRERERuXspkRcRh3BzVY+8XeXWnvTXu34rOzsn9QAhBb2Z0qc2fadtYuPhi0xZH8WU9VE8ULogQb7ueLm5UrKAFyUKeAHg4epCq8rF8HTTSvgiIiJyb1MiLyIO4eaiRN5hcmtP+us5KKn3cjcz/ak6LNl1msiDF/h563H+jLp40/ohBb14+P4QggM8KRbgSdkivgQHeGrBPBEREbmnKJEXEYfQYncOltme9Pt+gy3T0obHO5Kdk3oPVzOd7itBp/tK8FyTcH7fewY3swtXE1M4fimOE5cTMAH7T8dy7GI841b8Y3N8cIAnzzYqQ7OKRXAxmTh/NZGKxfy1h72IiIjctZTIi4hDuCmRzz03JvWO3sbuetcn9e5+UKYJFK6YFksOVsAvXciHfg3LZPratcQUZm06ysGzVzl1JYGTl+OJOn+NU1cSGPbrHob9+r/V8Av6uPN43VA63Vec8MK+d/IORURERPIcJfIi4hBatd5JcnkbOxtJsbDv17TH2o/suq0dgI+Ha4YkPyE5lZ+3Hmfa+iMcuxRHqsXA292Vi9eS+Oz3A3z2+wFKBHpRtUQAxQO9qBceRMNyhTTPXkRERPI1JfIi4hCumiPvXM7Yxu5G129rZ+ekPp2nm5leD4TS64FQDMNIu6zFYPGu0/y89TjrDpznxOV4TlxOm24wZX0UXm5m6ocH4e/lhmEYuLu60LZqMI3LF9ZcexEREckXlMiLiENoaH0ekklSn7r5a9i3CDOpuRPDjUl9uZZQ6gHwLQJ+wXZZCT89CXc1m+hQvTgdqhfnWmIK245e5uDZWA6du8bKfWc5cTme3/edtTn2x7+OU7aIL081KE3X+0uox15ERETyNCXyIuIQrhpanzf9m9RbSjVg0W8Lae+3G/OfkyDpau7FkJoA+xakPdK5+0LdQdDkDbv11kPacPwHyxXiwXJpe9MPNwx2n4xhU9RFLP/24B+/FM+cLcc5ePYqb8/dyUdL93F/qQKkWAyuxCdTqqA3jcsXpnxRP8IKeePn6Wa3+ERERERyQom8iDiEeuTzAZMLlkZDMDd9K3e3sstM0lVYMxrWfQIV2tp9CH46k8lElRIBVCkRYFP+Wsvy/LD5GNMij3D8km2P/fZjl1mw46T1eYlALzpUL84T9UIpEehl1/hEREREskKJvIg4hBa7y0dutpWdM5J6S7LDh+Bnxs/TjX4Ny9CnfhhrD5znbGwCLiYTfp6u7Dh+hb+OXCTqfBznryZy4nI8k/84xLTIKF5oVo5+DUvj4aqh+CIiIpJ7lMiLiN1YjP/929VFPfL5Ul5K6jMdgn/nW9zdiqvZhaYVi9iUta4SbP13TEIykQfPM2XdETYduchHS/cz+Y9DJKVYMJnghWbleLJeqIbfi4iIiEMpkRcRu0lJtVj/rTnyd4G8lNSny2yLu1zqtQfw93SjdZVgWlUuxrztJ3jlhx3EJqRYX/9o6X4+Wro/02NfblGOJ+uFEX3hGpWLB+Duqs+IiIiI5IwSeRGxm+TruuTdlcjfXfJiUg+Z99p7+EP1nlCpvcOSepPJRJcaJblwNYkPftubpWM+XXGAT1ccsD7v92BpShf2ITnFQpnCvtQKK4C3u/63LCIiIrenvxhExG6SU67vkdfQ+rtWZkl97Cm4egaObYIDy3Jvr/rMJMbApslpj/Sh+IXKg3dBu/fa+3ik/W+0RaWifN27FrEJyfx39SEWbD/J2dgEklONmx779bqom75mdjHxTMMyPBRRlPtLBWp/exEREbGhRF5E7CbFcl0irzny94b0pP56/+5Vz5Yp8M9S5yb16UPxb+TmA5U6Qtlmd5TYp/w7CiW9vft5ujGkdUWGtK6Yoe7pKwnM336CP/45R+ShC7c8b6rFYPIfh5j8xyFrWe96oUQU96dlRDEK+LhnO1YRERG5eyiRFxG7ub73UT2I97B/96onvEneSuqvl3wN/p6V9oAcL6Jn+TeRN2dhBEqxAE/6Nw6nf+NwAAzDwDAgKdXCyn1nmbXpKBsPX7hpL/70DdEAvDtvNyUKeOHjYcbPw43Kxf0JLeTDxatJPFguiBohBbgYl0SQj7s+hyIiIncpJfIiYjfJ1y12JwJkntRHr4Oz++HgckiJd3aEaXK4iN6NPfLZYTKZMJnA08VM26rBtK36v9XxLRaDjVEX2BR10WZefUSwP3tOxRB1/pq1bMPh//Xuj1sBXm5m4pNTKVXQmwZlC1HQx402VYKpUiIg2zGKiIhI3qREXkTsJuUW84FFbJJ6yLu99XDrre+um29f5IKBC96Y7TyVxMXFRP3wQtQrE8SPm49x8koCU/vWpmmFIhw+d5VzsYnEJaVy8VoSm49c5PzVRDxczSzbc5r45FQAjl6M4+imowB8vuoQlYL9KVvEl6SUVCoF+/NsozL/396dx0dZ3fsD/zyzz2Qymex7ICEh7AFBICBoy6a2SG3v1aq3F621V4XW/rTa2tb12mprr6/etkqv7VV7b1WqXqhWgYrIIsguYSeQEEgIZN8mmcz6nN8fw0wyMNkmk8xM8nm/XvNi8jxnJt+QMzP5Puec72FxPSIioijFT3AiChmnzBF5GoBomILfXYD19ssBLNYq0HYmE/jvTKDwK8Dc+wFVaNawl9W142KrDRqVAnNzEwEAeclG5CUbfW2+MTPLd7+x3Y7GDgfS4nTYVlqP8rp2lNe3Y9OxGpy81IaTlzw7DPzjeC3+74sL+MWtU7GgIDkksRIREdHwYSJPRCHDEXkKWm9T8Cu2hXeLuz7oJRl6ZxVQVQVU7QE+eQIwpgLp0z0/lyYWKPomkHf9gAvqbT9dDwCYk5sAvabvxyYatUg0agEAtxRl+I7XWWz44nwLKps6IEHC67sqUNXUiW/99z6MS45BjFaFiWkmOGUZdqeMu+bkYF5+0oBiJSIiouHDRJ6IQoZr5CkkAk3Bj7Qt7vrSXguc+UfX10f/6vnXkATE5wKpUz3r7+Mye62Y703krx8/uFHzlFgdbpyS5vv6jjk5+PU/SvHn3edQXu9Zb3/kQqvv/EdHLyExRoMUkw6FqUZcbLGhuqUTMVolpmWZMSc3AbE6FfQaFdQKCbLsht09qBCJiIhoAJjIE1HIjE2MCXcINBL1tsVdlIza+1gbPLfq/cAXr3mOKTRA/BjAkAiMvwlILwI6G2HTJWH/WU+SfUNhSkjDMGpVePqWybhn/lhUN3eizebEseo2aFUK1Lfb8fa+SjR2ONDY4fBNx/c6XduO9w5euOo5NQolNrR8gYQYLdLidMhOMCA73oCseD3S4nTQqQe+vR8REREFxkSeiEJm0cQUPLtiMiZnsDo2DbGeRu1PfQSUvBkdSb2X7AAaz3huVXt8h3UADquUuKhOxdg9y4CcuX2O4A/UmMQYjLl8Ae7GKV1V8x9ZWoiLLZ240NyJ0po2pMTqkJ9qRKvViZ1lDThda4HV4Uanww2nW4bF5kRNmx3bTjf0+L00KgXMejXGp8Zi6eRUTEgzweZ0o9nqwIzseKSbdXDLni35dGoFt84jIiLqBRN5IgoZSZLwr8Vjwx0GjUbeUfvcBcCyn/tPxe9sAepPR9Z2d/2kldzIxUXgi9c9N8C/er7eDNhaAUien33sdSFJ8uP0asTp1ZiYbsKSSal+57404erZAQ6HA6+8sxGJedPQ4ZRxsaUTVU1WVDV34kKzFTanDIdLRp3FjjqLHTvLek74ASAxRoOxSTFo63SiKNuMr8/IhEmvhkopIcOsh0mnHvTPSEREFM2YyBMR0cgSaCo+EL3T8a8UoHo+AOCzFwGlDihY6ll/b0wBYtNDOoLfE0mSkBsL3HxtFtRq/yRbCIF2uwutnU40dTiwu7wRO8sacK6xA1qVEkatCseqW+GSu4pleqf1A8CZOv+p/AaNEq9+axauK2AxPiIiGr2YyBMR0egwEoro9cVtA0594Ll5aWKB3OsBTQwQl+EpuDfMSX6sTo1YnRpZ8QZMyzLj364f59fG5nTD7pShUAACwJnadtS02qBVKfD3IxdxqLIFTreMDrsLbTYXvvM/+/HC16dheVEGFBLgcMtQSBIUkoSz9e0wGzRIjtUO6c81WFVNVpyps8Bic0EIwKRXQa1UAPAUDt1/rhkA8O35uRH/sxAR0fBjIk9ERKPTSCqi1xuHBSj9MPC57tP0DQnDmuB3p1Mr/YrhzRwT77u/uNvUfrvLjX/734PYVlqPH/y1BI++dxiuy+vqAUCpkOCWBdRKCd+8NgdNVgcMaiWuK0jC+UYrZCGQHW9ATqKnEF9KrBYKxfCvxX9p82n8dsuZfrVdu68SD96Qj2tzE1DbZkOsToW8JCPS4nRDHCUREUUyJvJERERefY3ad7YAZ7cB1QfhGTuOcj1N0x+GdfjB0KqU+MO/zMR/bT+LNz6vQLPV6XfeLQtoVQrYXTL+d8953/F3A1TZBzxF9SZnxGFMogFWuxt7KhqRZtLhyxNSkJ1gQFqcDhqlAnUWG2aNSUB2giEkP8fes40AgDGJnqr+ANDW6bp8UcLTryamm3CqxoKTl9rw8w0nr3qO/BQj4vRqCCGgUSlw26xsfG16ZlguTBAR0fBjIk9ERNSTQKP2i54AXA5g/x+xc+9edDRWYp7uAmKd9eGJcSj0Zx1+9rWeBF8IKDSxmHDxIBRbvwCMyUM6sq9TK/HQ4gLcf0Me6i12aFVKaNUKuN0CnU43Uk06bDlZi4+OXsK4ZCPqLXYcqmpGfrIRWpUSVc1WVDZZcanVBptTxsHzzTh4vtn3/C1WJ07VWK76vkqFhIUFSTDq1DhxsRU2p4xpWXFYXpSBa3Lica6xA25ZIE6vxphEA2J7KcjX6XQDAJ5aPglfnpDaYzuHS8Z7By/gnQNVuNDciUyzDha7C+caOlBW1+7Xds/ZJvz6H6UoSI3FrDHxMBvUaLE6UZBqxNQsMzLidNwJgIhoBGEiT0RENFAqDVC8Cusq52NdTTV+umQi7puXBexZA5RuADoagbZKwGUPd6ShF2AdvhJAIQDUXtFWHQNM+CpgzgaECOn0fa1Kiax4/xFy74T8pZPTsHRyWq+Pd7llnGu04vjFVlxssUEWAnNyE1DR0IEvKltQ22ZDTasNdpcbMVoVjlxoxdZS/4s11S2d2HisJuDzeyvvj0k0YGxiDC62dKK6pRNPfnUSOuwuAIBB0/ufYRqVAnfOycGdc3L8jjd3OPBFZTOcbgFJAs7UWrBmWzkuttpwsdWG7aevvqiUGKPB1Kw4JBm1MGpVWDo5FSqFAp1ON+aNS/StzycioujARJ6IiChI3krrSoXkSe6ve8hzA7qm5bdVA+d3A3XHgaYKwNqIETEtvz+cHcDRvwY+F+bp+yqlAvkpRuSnGP2OzxqbgH+elX1V+6MXWnGoqhmdDjfyU4yI0arw2Zl6vL2vCi1WB3ISDNCoFGjqcKCh3eGrvN99tB8A/vW1fbjU6imo+PfDF3GxpRMOlwyH27NFX4xWhUUTUpBi6nkNfHyMBosmdo3kL5uchn+dNxanLllwqqYNeyua4HDJiNWqcKrGgtJaCxo7HNjW7ULEG5+f893PNOuRnaCHQpJwXUESpmeZMSHdhIQYzYD+T4mIaPgwkSciIgqS+3Iir1IGmLLcfVp+0Te7jstuoHybJ8G1tXlGqi8dBtovDX3AkWSA0/fDvVZ/alYcpmbF+R2bm5eIh5cUwumW/Yr1tdmcqGy0oqKhA+cbO3Cu0Yp4gxqfnqpDeX2Hr93be8+hfP8mpKAFdTBjnzwBMhSQJODp5ZOxct7Yfsdn0qkxOzcBs3MT8K/F/o+zOd04eakNxy62od3mQkVDO/5xvBZ6tRIOt4zqy7MFAODzcs/6fY1SgYcWFyA3KQadDjfGJhlwTU48p+cTEUUIJvJERERBcskygMsj8v2lUAIFizw3vydzoHX777F760folDS4aXoudBf3AY3lAOTQBR0NAm2j111vyX5nM9BaDZizPNvuDXHCr1RIUF7x/CadGlMy4zAl0z/xXzk3Gy+//gbSmw8gX1GNhcrjMMLqO98p6fE5puNP9i/haFU6gLEhiVGnVmJGTjxm5HTtBvCrf/L8a3O6sflELWQh0NbpxPbTDThTZ8H5Rite/Eep3/PcPW8snr5lckhiIiKiwWEiT0REFCTfiHwoKoWrNNgY+0/4sasQM3LMuPUb8z3Hu2+JJ8tdI9PexPXCfuDMx4DLNvgYoklfyT4AfPYfgRP+cGy1d+IDZP39+3i+sxnooQ6eXnRiEXZjkWY33KX/Aaxd1hX3EM1E0KmVWF6U4fv6W8VjIYTA/31Rjf/aXg6DVgWjVoldZY348+5z+Po1mZiWZQ7Z9yciouAwkSciIgqSd428IkTTjb1Fyq4fn9x18Mot8QLpnuzXlQIV2wB7W0hiinp9JfyB1uqHeir/iQ+Ad741oIcoZfvVcQeaiTAECb4kSfinmVn4p5lZvmMP/7UE6w5V477/OYBMsx5jE2OQlWCAwyXji8pmjE004Kc3T0Kcoedq/UREFDpM5ImIiILU6xr5AXK6Zew80wDgikS+P65M9r2F9iyXgPZawNrkmW7u7AAqdjDJ766ntfrd9bVuv7dRftkNbHwsdPEGujDx2YuAQgtkzQJyZgOGpJDPOPjRTRPw8Yla1LbZUdtmxxeVLX7n91U0YWtpPdyygFsWSDJqIAvPiH+qSYuJ6SYkG7VQSJ7lCJIkIcmowZcnpEKjYsV8IqKBYiJPREQUJJfbW7V+8IlISVULLHYXzAb14Kcudy+0d6Urk/zOFqD+NEfx+9Kfqfxe3bfda670/F8PNdkOVO7y3LoL0e4AqSYd1j84DycutUGlUKC8vh31FjtkIVCQYsSfdlbgQnOnr31rp9N3/+Ql+FXM7y7NpINOrYDNKWPeuEQYtUpUVyqgPF6LCRlxyDQboNcMX1FDIqJowUSeiIgoSG4RujXy2y8nOgsKkgdWPG+gekryAyX4o30dfrB623ZvuPW1O8D4ZcDMuz39oqMeMKb2OIpfkBqLgtTYgN/m1muysLu8EelxOujUSjR22KFSKGB1uHChuRMnLrXBYnNBFgLy5VH7Q1UtqGnr6lPrDlVfvqfAlrWHfceTjBosLEjG5Mw4NLbbEW/QQKdRQpYF8lOMGJdsRJJRA5WSI/tENHowkSciIgqSu/s+8oMUcH38cOptFB/oteieWxOLsuMHkW8WUJZvAVydPT8PRQ63DTj5vufWnSYGyFsE5Mzp9xT9OL0aN05J63YkcMLfnc3pxrbSehi1KigkYM/ZRjhdbhw+VY5mRRwuNHfCYnehod2BdYequyX6V5MkIDFGg+RYHVJitUg1aZESq0N2gh7LJqfBbND0GQ8RUTRhIk9ERBQkV4iq1je023G0uhUAsHB80qDjGhK9FN2TnU6cat6AvJtvhlKpCJzwc/p+9HB0XL2MoPsU/RBV/deplX7J/7z8JDidTmxwnsHNNxdDrVajtdOJ0hoLPjpyEfXtdiQZtWixOmF3uSELoLTGguqWTrhlgYZ2BxraHTh5xUqGJ94/jnuvy8WjSwuhGMrZLkREw4iJPBERUZDcwewjH8BnZzyj8ZMzTEiJ1Q06rrDqrco+p+9Hr56m6HevBzAEW/vF6dWYnZuA2bkJPbZxywJNHQ7UWWyoa7N3+9eOA+ebcfJSG9ZsK8eF5k6s+tI4XGzpRIPFgQXjk5Aep4cQAi1WJ+L0aib6RBQ1mMgTEREFqavY3eD++PcWAgvbtPrhMojp+0z2I1Rv9QCGYBQ/EKVCQnKsFsmxWkzO8D8nhMD6Q9V47L0j+Pvhi/j74Yt+5006FWQBtNtdlx9vgsXmQmunExKAJKMWLllGcqwWCwqSUVpjgVGrwh1zcpBp1ofsZyAiGigm8kREREEKxRp5tyywI9zr4yNFb6P5Xn0l+53NQOVe4OJBJvzh1tMofqBK+pdH8yVdAhItlYC8DMDg96SXJAlfvyYLaXE6/GH7Wewpb0RyrBYpJi1KqlrQZnP52tZb7FdV1z9T1+67v+Foje/+H7aX43++PRvz8iN0KQwRjXhM5ImIiILk20d+ENvPHatuRbPVCaNWhWvGxIcqtJGrP8k+0HPCz7X64ddTgg/PH6bXARC//r3ndxyi0XyjVoXseD2yZmUhJ8GAqZlxyEkwwO7yLI9JjtXizb3nUVLZgnEpRhTnJUIhSb7q+0erW7H/XBMmpMXi4xO1qLfYUd7QwUSeiMKGiTwREVGQvNvPDWZE3lutfn5+ItTcPit0gl2rH5FT+SVPErviZaDy864LExETX+hJzl5G83Ov91TWj8sA9Ame3xkkz7KNsdcFTPR/uekUdpU1Bvxe3tev98IcTtRi49FLuG9hHmaOicelFhumZJpwQ2EyJmeYsOGop5repydroVFKuG1WNiSJa+uJaHgxkSciIgqSd438YKrWd207lxKSmKgf+lqr311fU/m9o/xlm4d2272bfgnkf9lzCxTfuR1AywXPmvWKHSN3xoHDApR+GPjcZy8CSh1QsBTIvtbzu5HdgK0Vq2tP4OtqJaqzV+C04RocudiOyiYrgK4E3qRTITvBgMomK841WvHT9cd6DWVraT22ltajpKoFCwuSIQvgQrMVW0vrkB1vwH0L85Bs1EKplKCUJCgVnptKITHxJ6JBYyJPREQUpMGukW+1OnGoshlABG87N9oNdir/FSP9H5y2QnXxAJZojkAt2/v+/qZM4MYXgEm39D++0bw7gNt29dZ5AIoBQAng4i4AEpCQD8eceXBq4iAkCbI2Dka5AwoJsKtNOFZ+HmcbO7HBko+LcdcgLkaP6pZOVLd0XayZnZuA/eea8Pa+Kry9r8rv++1BE949eCFgiBqVAlnxejR3OOCWBeaNS8KYJAPSTTpMyzZjUroJOrUSsixYRZ+IesREnoiIKEi+feSVwf2xvbOsAbIA8lOMyIo3hDI0Gm79TPj/UfsFPqpcgGdvmoCkhv0o27cRGXFa/NP8KX5F3wa1Jry/uwMcfA0o2wI42ntuOyIJoOkMNE1noAlwVgtg5uXbPysAtKsA82zgumX4aP9J2JqqEJ+Why8v+Wd8bJ2ON3ZXwemWIUkSYjRKzM9Pwq6yBmw/XQ/vbP3uHC4ZZ+s7fF9vOl7jd16lkGDUqdDa6cT8cUm4//pxuK6AF/qIyB8TeSIioiD59pEPcprs9tN1AFitfjTpcHiqpOu0GrxxaQz2uW/Dk/MmAfNzhy+I7hcdvKP37bWAIQkQsmcdfl0piwJ6CRdQ9TlQ9Tm+AnhG9ut3Af/zv1iq1GFpwVIgZ063iy9j8J0FeRBCQBaemTtuWcAtBNxugdZOJ6qarTAb1HC4ZOw+24gGiwOVTR0oqWpBQ7sDLVYnAM/Fvl3lDfjPb87A9eOToVJIiNGqUNVkhcMtY2xizKC3vySi6MREnoiIKEiuQUytF0J0Wx/PRH60sNrdAIAOuwv7zzcBAG6ckha+gAKN3nvX4Qeaoj8c9QCiSaCp/Je315OSxkOpN0N5xRKLOCGQ411uAQkzvEX6AIjzu9BUW4cOdRIcmXPx+21n8beSi3ho7SEIAaiVErLiDaho8Izox2iUWF6UgZxEA0prLPiishkWmwsxGhWKsuMwMc0EjUqB4xfboFYqoFQA1S2dGJsYg1lj45EVb0CH3QW3LJAcq4VerUScQY1ko5br+IkiHBN5IiKiIA1m+7lTNRbUttmhUyswOzch1KFRhLI6PSPyO880QAhgerYZGWZ9mKPqQU9T9Lm1X+962V4voM9eBBRqQKGE5LIhEUAiAGhi8VLu9bgz2Y59zXo0ixiYYQVagFZVLFoUZlxwmfHOfidk+L8HtVidqG7pxIajNQG+IbCrrBFv7q3sMaRYrQq5yTHIS4qBSa/GrrIGqBQKTM8243SdBQ6XjFSTDgWpRugvr+efnBkHtVJCa6cTGqUSYxINGJ8aC42Ku3EQDQUm8kREREHyFbsLYo28dzS+OC8ROvXA98Wm6OQdkd991rMV2s1TwzgaH6yBbu3HBL9vstNz685hgaL0Q8wGMLunv9g1QCcMKI2ZBXv8OCQnp8IsdaDD7sb5TjU62xrhdMkwxSdD57bA7RbQxsajtbkR9RYbauwaJKrskBQSPnNMxG55AlpsMix2F45caMWRC61+36601uK7f/xiGz49Vdfrj5Vk1OCj7y9AqkkXxH8KEfUmrIn8888/j3Xr1uHUqVPQ6/WYN28efvnLX6KwsDCcYREREfVL14h8EIl8KafVj0beNfJWhyehv2lKejjDCb3eRvF7qqTP0fxB0cOK6R07gI4dwOVC+QkAsrs3aunlCTxdEd8EAKUO7mlL0BQ/Da3N9XA3X0CtlIjEpDSonK2ot9gRF58Mo2iHxebCBZsGOpcFsixwtl0Fk2SFVq3CYeUUrK0fi4Z2B0prLD0m8kIIHLnQiv3nmjAlMw6zxyawUj9RP4U1kd++fTtWrVqFa6+9Fi6XCz/5yU+wdOlSnDhxAjExMeEMjYiIqFdCiKDXyLfbXThweX309YXcP3408SbwADAl04TshFGyW0FflfQBQHbDdXYHSnZsxIyCDCgdFib4w81tg7L070jG3+G9xFgIALXd7l/qaj4t0HPYgFsB/EStxHHFGJz431y8pjTBJgu4VbFI09qhUSlhgQF2SzOsLjdahAGdsOKkRoX0tDQYRRv0tjrUSwlol2KRpLZBq1JhfXMujqimYFqWGUsMZZhoL4FGIaFRxKDWbYJFk4yieTcjLT4GzVYH6lutqLF6ZsCU1lpxbW4CJqbH4vjFNqTH6ZBm0o2KWgBOt4xmqwNNHQ5UNlqhUysxNTMOn5c3osnqQEqsFmqlBEmSoFYokGjUQAjA6nDBbFAjMUYLhSThTJ0FSoWEtDgdko1aNFudaO10ItmohUmv8v1ftlqdqGmzQa2UMDYxhhdnhkhYE/lNmzb5ff3GG28gJSUFBw8exMKFC8MUFRERUd+6bys10BH53eWNcLoFchIMGJs4ShI5ghDCL5EfcaPxg6VQQoy5DtWJbSiaezOUarXn+JWj+dYmoLUaiMsA9AnAhf3AmY8Bly288ZMfDdyYoTyLGTjrOaAAIAO4sk5i92xEwO9CwZWKAdiFEmiVoJVcvuMpACZevt/6hQ6b5ak4KzLQIgwww4rDx/8PLcKAz2DFHqUC9W4dzLBCpVTApjBibIwD4/VtUMVn4pJDj2SVDRPTYqEwxPuKEqJbUULfTg/G1OC2iBxibllg7f5KbDh6Cccvtvl2QRhKqSYtchIMqG2zo7LJ6juek2DA1Kw4nKm1oNPphsMlw+UWkIVAolGLiekmxOpUcLhkCAH8cNl4pMdFaN2QCBNRa+RbWz3rcBISAhf9sdvtsNvtvq/b2jxXZ51OJ5zOoe+gwfDGFanxUfRgX6JQYn8aPLtL9t2X3S44nf1P5ree8hSgWpCfCJfL1UfryMf+1D92p9u3HAMAlkxI4v/ZFXrsS1lze37Q7AcA2Q3p/E5I53d5ttDTmT0JWEMpFBXbIDmtPT+eoopWcvd6Pk6y4SvK/b0/yZX19zou3xouzzoAgPIr2nz2IoRCDSEpoXB3XTQS6ljIedcDifld/Q6i//c7mwHLRSA2A9BfvnAgSRBjroMYMx8AIFXt9l04ENnFvV44qG2zYfXawyip8q9vIElAnE6NrHg9GtrtqGmzIztej/GpRjR2OOCWPcm1wyWjod0BpUKCTq1Ea6cTFpvncyo9zrNEot5ih0sWkCQgRqNCu92F2jY7atu68rR4gxpWhxuVTVa/xL67ZqsTZXXtfsdqWjvx+sprIm6mxJXvTZHw3i0JIUTfzYaeLMu45ZZb0NLSgp07dwZs8/TTT+OZZ5656vhbb70Fg4EjGkRENHzsbuCxfZ7r4b+a7YK2nwMyQgDPHlKiyS7hvkI3piRExMcwDYN2J/DTA54+k24Q+HFR7wkJhYiQ8e7+M0gSjbgvqRTZtlOIcdRCCbnvxxKFkRNKCCigQVfSaIUOFbopaNVkoNphgFnZAbMGkJUGaIUVhxoVuOA0IFFhRZ5RwGjQwyxZoZIAp8oAjWyFkIF2yQCj6IDB1QSrKgFOdSzs6jjY1PFoNBYCUtfVDpcMuASgu/w5Jwugw+X5Wq3wfB5WtQMWp4RYtUC6AYhRAw43cKhRgsUJZBoAvUpApfBcR5EkoMkuobbT83iFBGy+oIBTSPiXfDeuTY7sz0ar1Yo777wTra2tMJlMYYkhYhL5Bx54ABs3bsTOnTuRlZUVsE2gEfns7Gw0NDSE7T+wL06nE5s3b8aSJUug9k4RIwoC+xKFEvvT4FlsTlzz860AgGNPLYa2n1ssVTR0YOl/7oJaKWH/419CjDaiJscFhf2pf6pbOnHDf3wGAPj+l8fhe18aF+aIIs9Q9aXJz3wCh0vG9kcWeLb762kEv/uIacNpKCq2cjSfRp1BzzLwzirwzh6w1vdrNsEftp/Ff3xShniDGpu+Px8JMZqh/2H76cr3pra2NiQlJYU1kY+Ivx5Wr16NDz/8EDt27OgxiQcArVYLrVZ71XG1Wh3xfzhEQ4wUHdiXKJTYn4KncHZdB9drNf0ueLfrbDMA4NqxCTAbR9Y6QPan3jnkrum4Xy3K5P9VL0Ldl7xLGnRazeXnVQPjF3tuvZHdEOd34Wd/3gydswH3XROHNDR1rc9nxX0agSSnBcrSD0P/xJoYIG8RkH2tZ0lB91oXtlY8KGTo4luQnpmD+AYt1KbrIq7+gPe9KRLev8OayAsh8L3vfQ/r16/Htm3bkJubG85wiIiI+s3Vba3zQGrdefePv6GQ286NNvEGDdRKCZPSTShIMYY7nFFDCOFL5Ae6wwQUSlyIm4U3bRaolRIevWUZoA6QWPS1vV6g+yzSR6ONowM49YHnFoASwH0AUHb5ZsoAbvwlMOmW4YsxioQ1kV+1ahXeeustvP/++4iNjUVNjaf4T1xcHPT6kTVKQUREI0v3PeT7W5TH5nRjd3kjAOD68dx2brRJjtVix2NfQqxOHXGFnEay7gUGB7rDBAAcqmoBAExKN0EXKIkH+re9XiCyG6j4DDi/01Ox3VsBvb02cIV+zgCg0aTtIvDOvwK3/Q+T+QDCmsivWbMGAHDDDTf4HX/99ddx9913D39ARERE/RTMHvJ7K5pgd8lIM+kwPpUjsqMRt1Uaft1nzwx4RB7A4cuJ/PRsc4gi6kahBMbd4LkNRDAzADgzgKLVph8DE74ScdPswy3sU+uJiIiikdvdNSLfX9tLPdPqrx+fzBFZomHiPyLfv6KU3ZVcTuSLhiKRD1awMwB60n1mgCx7EvwAa5j7dVGgdCMgh39rLhopBNBW7blwFco+PwJERLE7IiKiaOOSPVtXKQaSyJ+uAwBcz/XxRMNmMCPyTreMY9We/biHZEQ+UgQ7MyAQ2Q2Ub8Mn7/wOLlsb6oQZ43OyMDcvqf+zBK68iNDTrAGlDkibAjSc5lKDka69NtwRRBwm8kREREHovka+P6qarCiv74BSIWF+ftJQhkZE3QxmjXxpjQV2lwyTToXcpJhQhzYyKZRAwSK8ZNTghMWTXD8ybjzmLioY3PNeWU8gdwEw9nJV8x6WGrg1sSg7fhD548ZBGZPY/wsHXHoQeYyp4Y4g4jCRJyIiCoJbeNfI92+q7o4znmn1M7LNiNOHf9saotHCO3tGkgY2gwboKnRXlG3mcphBUKsGvqThKr3NGuhhqYHsdOJU8wbkfelmKAezXVhfRQkHU6Ogv7MPRi3JU71+zLxwBxJxmMgTEREFwTXANfLd18cT0fAZ6OyZ7koqWwB4LsBR8DTKECTy4RTKpQf9MZQXDgJdRHB2ABU7Ind5wo0vsNBdAEzkiYiIgjCQfakdLhmfe7ed4/p4omHlvegWVMX6Cy0AgOk55hBGNPqEZER+NBnuCwdA6HdCKP8UcLQPLiZTpieJ59ZzATGRJyIiCoK3gJZK2Xdy8EVlM9rtLiTGaDAlI26oQyOibrpG5AeWTLbZnCiv9yQiRVnmUIc1qmijfUR+NBiKnRDOf+65KGBIAoQMVH7e964IhgTAmALEpnfNRKCAmMgTEREFYSAj8tsuT6tfOD55wGt0iWhwXAN4rXZ3pKoVQgDZCXokGrVDEdqooeGI/OgT6MJA/pfDE8sIxVcVERFRELwFtJT9KIC1/TTXxxOFS7Br5H3T6rPjQx3SqKPmiDxRyPFVRUREFIT+jsjXttlw8lIbJAlYUMBt54iGm++i20Ar1l8udFeUxeUwg8UReaLQ46uKiIgoCP1dI7/j8mj81Mw4Ts8lCoNgRuSFECi5vPXcDBa6GzR1P2qJENHAMJEnIiIKguwbke/9o5TT6onCy7dGfgDJZHVLJxra7VApJExmgcpB44g8UejxVUVERBQEVz9G+dyywGdnGgAwkScKl2Cq1h+uagUATEiPhU7NqtmDFfX7yBNFIL6qiIiIgtCfNfKHL7SgtdOJWJ0K07PNwxQZEXU3kB0mvEqqmgGAr9sQ4Yg8UejxVUVERBSE/ozIb7+87dyCgiSoOCJFFBbBrJH3ro9nxfrQYCJPFHp8VREREQXB3Y9K2FwfTxR+A91H3uWWcbTaM7WeI/Khwe3niEKPryoiIqIguNy9JwfNHQ7fPtTXj08ZrrCI6Arei279HZEvrbXA5pQRq1MhLylmKEMbNbhGnij0+KoiIiIKQl/TdXecqYcQwIS0WKTF6YYzNCLqpq+LblfyTqsvyjJDMcC95ykwTq0nCj2+qoiIiILgFr0nB5xWTxQZBlq1/rBvfbx5iCIaHeTL75EAR+SJhgJfVUREREHoLTmQZYEdp7ntHFEk8K6R7+/uc74ReSbyg+Jwy777HJEnCj2+qoiIiILQ23TdE5fa0NBuh0GjxMyxrHpNFE4DGZG32Jw4U9cOgCPyg+VwdSXyLHZHFHp8VREREQWhtzXy3mn188YlQqtSDmtcRORvIFXrj1a3Qggg06xHcqx2qEMb0fwTedYaIAo1JvJERERB6Jqu23Miz2n1ROE3kKr1JVwfHzLOblPrJYmJPFGoMZEnIiIKQk/JQZvNiS/ONwPgtnNEkWAgI/IllS0AmMiHQvcReSIKPSbyREREQegpOfi8rBEuWSA3KQY5iYZwhEZE3fiWwfQxvVsI0TUin2Me4qhGPqdb9N2IiILGRJ6IiCgIcg9r5DmtniiydBWm7P3P3po2G+osdigVEqZkxA1HaCNa96r1RBR6TOSJiIiC0DUi3/VRKoTA9tI6AMD1hUzkiSJBb4Upu/NOqy9MjYVewyKVRBTZmMgTEREFIdB03bK6dlxstUGjUmBubmK4QiOibvq7Rp7T6okomjCRJyIiCkKg5MA7rX5ObgJH9IgiRH+r1vsS+SzzEEdERDR4TOSJiIiC4B2RV0pXJ/JcH08UOfozIu+WBY5WtwLgiDwRRQcm8kREREFwXR7l8yYHVocLe882AQBu4Pp4oojRnzXyp2stsDrcMGpVGJdsHK7QiIiCxkSeiIgoCFcmB3vPNsHhlpFp1jMRIIoggQpTXunw5Wn107Li+rXfPBFRuDGRJyIiCoJvav3lYnfeafULxydDkpgIEEWK/uwj710fX5RtHoaIRhdeFyEaGkzkiYiIguC6YkSe6+OJIlPXPvJ9J/LTmciHnEbFdINoKPCVRUREFAR3t+m65xs7UNHQAZVCwvx8bjtHFEn6qlrfYXfhdK0FADCDiXzIqZVMN4iGAl9ZREREQeg+Iu8djZ85Jh6xOnU4wyKiK/RVtf5odStkAaTH6ZBi0g1naKOCliPyREOCrywiIqIguC9P11UoJGwvvTytntXqiSKOLHqvWs9p9UNLwxF5oiHBVxYREVEQvKN8sizweXkjAK6PJ4pEXWvkA//ZW1LZAoCJ/FBRc0SeaEjwlUVERBQE77rbQ5XN6HS6kRyrxaR0U5ijIqIr9bWP/OELLQBYsX6ocESeaGjwlUVERBSEy4N82FnmGY1fWMBt54giUW9r5GvbbLjUaoNCAqZmxg13aKMCi90RDQ2+soiIiILgHZFvaLcD4Pp4okjV2z7yhy5Pqx+fGosYrWo4wxo1uP0c0dDgK4uIiCgI3nW3ACBJwIL8pDBGQ0Q9cV2+6BZoRN47rZ7r44cOp9YTDQ2+soiIiILgHeUDgKIsM+JjNGGMhoh60tsaeRa6G3ockScaGnxlERERBcHVLZFntXqiyNW1Rt7/z163LHDEOyKfYx7mqEYPJvJEQ4OvLCIioiB0H5Hn+niiyNXTiHx5fTs6HG4YNEoUpMSGI7RRQR2gNgERDR4TeSIioiB4R/nMBjWKsszhDYaIetS1j7x/QumdVj81My7g+nkKDY1KGe4QiEYkJvJERERB8FatX1CQzCSAKIL1NCJ/qKoFAKfVDzWOyBMNDSbyREREQfDOrOf6eKLI1lPV+sPeRJ4zaoaUlmvkiYYEX1lERERB+Oa12VhQkIQbp6SFOxQi6kWgfeQ7HW6U1loAcER+qHH7OaKhoQp3AERERNHoOwvy8J0FeeEOg4j6EKhq/dHqVrhlgVSTFulx+nCFNiqMTYoJdwhEIxITeSIiIiIasQKtkS+pagbA/eOH0v/eOxs7TtfjX+aOCXcoRCMSE3kiIiIiGrG6RuS7EvnDVa0AgCIm8kNmQUEyFhSwhgjRUOGiFSIiIiIasQKPyLcA4Ig8EUUvJvJERERENGJdWbW+zmJDdUsnJAmYxor1RBSlmMgTERER0YjldvtPrfdOqy9IMcKo5SpTIopOTOSJiIiIaMS6co08C90R0UjARJ6IiIiIRqyuNfKeP3u71sfHhyskIqJBYyJPRERERCNW9xF5WRY44qtYHxfOsIiIBoWJPBERERGNWN2r1p9taIfF7oJerURhamyYIyMiCh4TeSIiIiIasdzdRuQPVbYAAKZmxkGl5J/BRBS9+A5GRERERCOWb0ReKeHwhRYAnFZPRNGPiTwRERERjVjd95FnoTsiGimYyBMRERHRiCTLApcH5OFyC5y6ZAEATM8xhy8oIqIQYCJPRERERCOSWwjf/VM1bXDJAklGLTLidGGMioho8JjIExEREdGI5F0fDwDHqtsAANOzzZAkKVwhERGFBBN5IiIiIhqRXN0S+aPVnv3jZ3BaPRGNAEzkiYiIiGhEcru7j8h7EvmiLHOYoiEiCh0m8kREREQ0Inkr1gPApVYbJAmYxq3niGgEYCJPRERERCNS9zXyADAu2QiTTh2maIiIQoeJPBERERGNSK4rEvnp2ebwBEJEFGJM5ImIiIhoRLpyRL6IiTwRjRBM5ImIiIhoRLpyRH4GE3kiGiGYyBMRERHRiOTuVuxOq1KgMC02jNEQEYUOE3kiIiIiGpG6j8hPyYyDWsk/fYloZOC7GRERERGNSK5u+8iz0B0RjSRM5ImIiIhoROpe7I6JPBGNJEzkiYiIiGhEcjGRJ6IRiok8EREREY1oiTEaZMXrwx0GEVHIqMIdABERERHRUJiSacI3rsnCdQWJkCQp3OEQEYVMRIzIv/zyyxg7dix0Oh3mzJmDffv2hTskIiIiIopyWpUS/3FbEW6dkRXuUIiIQirsifxf//pXPPzww3jqqafwxRdfoKioCMuWLUNdXV24QyMiIiIiIiKKOGFP5F966SXcd999uOeeezBp0iT84Q9/gMFgwGuvvRbu0IiIiIiIiIgiTljXyDscDhw8eBCPP/6475hCocDixYuxe/fuq9rb7XbY7Xbf121tbQAAp9MJp9M59AEHwRtXpMZH0YN9iUKJ/YlCif2JQoV9iUKJ/YlC5cq+FAl9ShJCiL6bDY2LFy8iMzMTn3/+OYqLi33HH3vsMWzfvh179+71a//000/jmWeeuep53nrrLRgMhiGPl4iIiIiIiEY3q9WKO++8E62trTCZTGGJIaqq1j/++ON4+OGHfV+3tbUhOzsbS5cuDdt/YF+cTic2b96MJUuWQK1WhzscimLsSxRK7E8USuxPFCrsSxRK7E8UKlf2Je/M8HAKayKflJQEpVKJ2tpav+O1tbVIS0u7qr1Wq4VWq73quFqtjvgXZzTESNGBfYlCif2JQon9iUKFfYlCif2JQsXblyKhP4W12J1Go8HMmTOxZcsW3zFZlrFlyxa/qfZERERERERE5BH2qfUPP/wwVq5ciVmzZmH27Nn4zW9+g46ODtxzzz3hDo2IiIiIiIgo4oQ9kb/99ttRX1+PJ598EjU1NZg+fTo2bdqE1NTUcIdGREREREREFHHCnsgDwOrVq7F69epwh0FEREREREQU8cK6Rp6IiIiIiIiIBoaJPBEREREREVEUYSJPREREREREFEWYyBMRERERERFFESbyRERERERERFGEiTwRERERERFRFGEiT0RERERERBRFmMgTERERERERRRFVuAMYDCEEAKCtrS3MkfTM6XTCarWira0NarU63OFQFGNfolBif6JQYn+iUGFfolBif6JQubIvefNPbz4aDlGdyFssFgBAdnZ2mCMhIiIiIiKi0cRisSAuLi4s31sS4byMMEiyLOPixYuIjY2FJEnhDiegtrY2ZGdno6qqCiaTKdzhUBRjX6JQYn+iUGJ/olBhX6JQYn+iULmyLwkhYLFYkJGRAYUiPKvVo3pEXqFQICsrK9xh9IvJZOIbCIUE+xKFEvsThRL7E4UK+xKFEvsThUr3vhSukXgvFrsjIiIiIiIiiiJM5ImIiIiIiIiiCBP5IabVavHUU09Bq9WGOxSKcuxLFErsTxRK7E8UKuxLFErsTxQqkdiXorrYHREREREREdFowxF5IiIiIiIioijCRJ6IiIiIiIgoijCRJyIiIiIiIooiTOSJiIiIiIiIoggT+SH08ssvY+zYsdDpdJgzZw727dsX7pBomD399NOQJMnvNmHCBN95m82GVatWITExEUajEd/4xjdQW1vr9xyVlZX4yle+AoPBgJSUFDz66KNwuVx+bbZt24ZrrrkGWq0W+fn5eOONN66Khf0xuuzYsQPLly9HRkYGJEnC3/72N7/zQgg8+eSTSE9Ph16vx+LFi3HmzBm/Nk1NTbjrrrtgMplgNptx7733or293a/NkSNHsGDBAuh0OmRnZ+NXv/rVVbG8++67mDBhAnQ6HaZOnYoNGzYMOBYKr7760913333Ve9WNN97o14b9iQDg+eefx7XXXovY2FikpKTga1/7GkpLS/3aRNJnW39iofDoT1+64YYbrnpvuv/++/3asC8RAKxZswbTpk2DyWSCyWRCcXExNm7c6Ds/It+XBA2JtWvXCo1GI1577TVx/Phxcd999wmz2Sxqa2vDHRoNo6eeekpMnjxZXLp0yXerr6/3nb///vtFdna22LJlizhw4ICYO3eumDdvnu+8y+USU6ZMEYsXLxaHDh0SGzZsEElJSeLxxx/3tTl79qwwGAzi4YcfFidOnBC/+93vhFKpFJs2bfK1YX+MPhs2bBA//elPxbp16wQAsX79er/zL7zwgoiLixN/+9vfxOHDh8Utt9wicnNzRWdnp6/NjTfeKIqKisSePXvEZ599JvLz88Udd9zhO9/a2ipSU1PFXXfdJY4dOybefvttodfrxX/913/52uzatUsolUrxq1/9Spw4cUL87Gc/E2q1Whw9enRAsVB49dWfVq5cKW688Ua/96qmpia/NuxPJIQQy5YtE6+//ro4duyYKCkpETfffLPIyckR7e3tvjaR9NnWVywUPv3pS9dff7247777/N6bWltbfefZl8jrgw8+EB999JE4ffq0KC0tFT/5yU+EWq0Wx44dE0KMzPclJvJDZPbs2WLVqlW+r91ut8jIyBDPP/98GKOi4fbUU0+JoqKigOdaWlqEWq0W7777ru/YyZMnBQCxe/duIYTnj2+FQiFqamp8bdasWSNMJpOw2+1CCCEee+wxMXnyZL/nvv3228WyZct8X7M/RrcrEy9ZlkVaWpp48cUXfcdaWlqEVqsVb7/9thBCiBMnTggAYv/+/b42GzduFJIkierqaiGEEK+88oqIj4/39SUhhPjRj34kCgsLfV/fdttt4itf+YpfPHPmzBH/9m//1u9YKLL0lMivWLGix8ewP1FP6urqBACxfft2IURkfbb1JxaKHFf2JSE8ifxDDz3U42PYl6g38fHx4k9/+tOIfV/i1Poh4HA4cPDgQSxevNh3TKFQYPHixdi9e3cYI6NwOHPmDDIyMpCXl4e77roLlZWVAICDBw/C6XT69ZMJEyYgJyfH1092796NqVOnIjU11ddm2bJlaGtrw/Hjx31tuj+Ht433OdgfR56KigrU1NT4/U7j4uIwZ84cv75jNpsxa9YsX5vFixdDoVBg7969vjYLFy6ERqPxtVm2bBlKS0vR3Nzsa9Nb/+pPLBQdtm3bhpSUFBQWFuKBBx5AY2Oj7xz7E/WktbUVAJCQkAAgsj7b+hMLRY4r+5LXm2++iaSkJEyZMgWPP/44rFar7xz7EgXidruxdu1adHR0oLi4eMS+L6kG1Jr6paGhAW63268jAEBqaipOnToVpqgoHObMmYM33ngDhYWFuHTpEp555hksWLAAx44dQ01NDTQaDcxms99jUlNTUVNTAwCoqakJ2I+853pr09bWhs7OTjQ3N7M/jjDe332g32n3fpGSkuJ3XqVSISEhwa9Nbm7uVc/hPRcfH99j/+r+HH3FQpHvxhtvxNe//nXk5uaivLwcP/nJT3DTTTdh9+7dUCqV7E8UkCzL+MEPfoD58+djypQpABBRn239iYUiQ6C+BAB33nknxowZg4yMDBw5cgQ/+tGPUFpainXr1gFgXyJ/R48eRXFxMWw2G4xGI9avX49JkyahpKRkRL4vMZEnGkI33XST7/60adMwZ84cjBkzBu+88w70en0YIyMi6vLNb37Td3/q1KmYNm0axo0bh23btmHRokVhjIwi2apVq3Ds2DHs3Lkz3KFQlOupL333u9/13Z86dSrS09OxaNEilJeXY9y4ccMdJkW4wsJClJSUoLW1Fe+99x5WrlyJ7du3hzusIcOp9UMgKSkJSqXyquqDtbW1SEtLC1NUFAnMZjPGjx+PsrIypKWlweFwoKWlxa9N936SlpYWsB95z/XWxmQyQa/Xsz+OQN7fW2+/07S0NNTV1fmdd7lcaGpqCkn/6n6+r1go+uTl5SEpKQllZWUA2J/oaqtXr8aHH36IrVu3Iisry3c8kj7b+hMLhV9PfSmQOXPmAIDfexP7EnlpNBrk5+dj5syZeP7551FUVIT//M//HLHvS0zkh4BGo8HMmTOxZcsW3zFZlrFlyxYUFxeHMTIKt/b2dpSXlyM9PR0zZ86EWq326yelpaWorKz09ZPi4mIcPXrU7w/ozZs3w2QyYdKkSb423Z/D28b7HOyPI09ubi7S0tL8fqdtbW3Yu3evX99paWnBwYMHfW0+/fRTyLLs+0OouLgYO3bsgNPp9LXZvHkzCgsLER8f72vTW//qTywUfS5cuIDGxkakp6cDYH+iLkIIrF69GuvXr8enn3561XKKSPps608sFD599aVASkpKAMDvvYl9iXoiyzLsdvvIfV8aUGk86re1a9cKrVYr3njjDXHixAnx3e9+V5jNZr9KiDTyPfLII2Lbtm2ioqJC7Nq1SyxevFgkJSWJuro6IYRn+4mcnBzx6aefigMHDoji4mJRXFzse7x3K4ylS5eKkpISsWnTJpGcnBxwK4xHH31UnDx5Urz88ssBt8Jgf4wuFotFHDp0SBw6dEgAEC+99JI4dOiQOH/+vBDCs0WX2WwW77//vjhy5IhYsWJFwO3nZsyYIfbu3St27twpCgoK/LYLa2lpEampqeJb3/qWOHbsmFi7dq0wGAxXbRemUqnEr3/9a3Hy5Enx1FNPBdwurK9YKLx6608Wi0X88Ic/FLt37xYVFRXik08+Eddcc40oKCgQNpvN9xzsTySEEA888ICIi4sT27Zt89sSzGq1+tpE0mdbX7FQ+PTVl8rKysSzzz4rDhw4ICoqKsT7778v8vLyxMKFC33Pwb5EXj/+8Y/F9u3bRUVFhThy5Ij48Y9/LCRJEh9//LEQYmS+LzGRH0K/+93vRE5OjtBoNGL27Nliz5494Q6Jhtntt98u0tPThUajEZmZmeL2228XZWVlvvOdnZ3iwQcfFPHx8cJgMIhbb71VXLp0ye85zp07J2666Sah1+tFUlKSeOSRR4TT6fRrs3XrVjF9+nSh0WhEXl6eeP3116+Khf0xumzdulUAuOq2cuVKIYRnm64nnnhCpKamCq1WKxYtWiRKS0v9nqOxsVHccccdwmg0CpPJJO655x5hsVj82hw+fFhcd911QqvViszMTPHCCy9cFcs777wjxo8fLzQajZg8ebL46KOP/M73JxYKr976k9VqFUuXLhXJyclCrVaLMWPGiPvuu++qC33sTySECNiPAPh97kTSZ1t/YqHw6KsvVVZWioULF4qEhASh1WpFfn6+ePTRR/32kReCfYk8vv3tb4sxY8YIjUYjkpOTxaJFi3xJvBAj831JEkKIgY3hExEREREREVG4cI08ERERERERURRhIk9EREREREQURZjIExEREREREUURJvJEREREREREUYSJPBEREREREVEUYSJPREREREREFEWYyBMRERERERFFESbyRERERERERFGEiTwREVGYSJKEv/3tb/1uf/fdd+NrX/vaoL7nuXPnIEkSSkpKBvU8REREFD5M5ImIiEKspqYGDz30EPLz86HT6ZCamor58+djzZo1sFqt4Q6vTxUVFbjzzjuRkZEBnU6HrKwsrFixAqdOnQLAiwFEREThpgp3AERERCPJ2bNnMX/+fJjNZvziF7/A1KlTodVqcfToUbz66qvIzMzELbfcEu4we+R0OrFkyRIUFhZi3bp1SE9Px4ULF7Bx40a0tLSEOzwiIiICR+SJiIhC6sEHH4RKpcKBAwdw2223YeLEicjLy8OKFSvw0UcfYfny5T0+9ujRo/jyl78MvV6PxMREfPe730V7e/tV7Z555hkkJyfDZDLh/vvvh8Ph8J3btGkTrrvuOpjNZiQmJuKrX/0qysvL+x3/8ePHUV5ejldeeQVz587FmDFjMH/+fDz33HOYO3cuACA3NxcAMGPGDEiShBtuuMH3+D/96U+YOHEidDodJkyYgFdeecV3zjuSv3btWsybNw86nQ5TpkzB9u3bfW2am5tx1113ITk5GXq9HgUFBXj99df7HT8REdFowESeiIgoRBobG/Hxxx9j1apViImJCdhGkqSAxzs6OrBs2TLEx8dj//79ePfdd/HJJ59g9erVfu22bNmCkydPYtu2bXj77bexbt06PPPMM37P8/DDD+PAgQPYsmULFAoFbr31Vsiy3K+fITk5GQqFAu+99x7cbnfANvv27QMAfPLJJ7h06RLWrVsHAHjzzTfx5JNP4uc//zlOnjyJX/ziF3jiiSfw5z//2e/xjz76KB555BEcOnQIxcXFWL58ORobGwEATzzxBE6cOIGNGzfi5MmTWLNmDZKSkvoVOxER0aghiIiIKCT27NkjAIh169b5HU9MTBQxMTEiJiZGPPbYY77jAMT69euFEEK8+uqrIj4+XrS3t/vOf/TRR0KhUIiamhohhBArV64UCQkJoqOjw9dmzZo1wmg0CrfbHTCm+vp6AUAcPXpUCCFERUWFACAOHTrU48/x+9//XhgMBhEbGyu+9KUviWeffVaUl5f7zvf0HOPGjRNvvfWW37F///d/F8XFxX6Pe+GFF3znnU6nyMrKEr/85S+FEEIsX75c3HPPPT3GRkREREJwRJ6IiGiI7du3DyUlJZg8eTLsdnvANidPnkRRUZHfSP78+fMhyzJKS0t9x4qKimAwGHxfFxcXo729HVVVVQCAM2fO4I477kBeXh5MJhPGjh0LAKisrOx3vKtWrUJNTQ3efPNNFBcX491338XkyZOxefPmHh/T0dGB8vJy3HvvvTAajb7bc889d9XU/uLiYt99lUqFWbNm4eTJkwCABx54AGvXrsX06dPx2GOP4fPPP+933ERERKMFi90RERGFSH5+PiRJ8ku8ASAvLw8AoNfrhzyG5cuXY8yYMfjjH/+IjIwMyLKMKVOm+K2j74/Y2FgsX74cy5cvx3PPPYdly5bhueeew5IlSwK2967l/+Mf/4g5c+b4nVMqlf3+vjfddBPOnz+PDRs2YPPmzVi0aBFWrVqFX//61wOKn4iIaCTjiDwREVGIJCYmYsmSJfj973+Pjo6OAT124sSJOHz4sN/jdu3aBYVCgcLCQt+xw4cPo7Oz0/f1nj17YDQakZ2djcbGRpSWluJnP/sZFi1ahIkTJ6K5uXnQP5ckSZgwYYIvNo1GAwB+a+hTU1ORkZGBs2fPIj8/3+/mLY7XPWYvl8uFgwcPYuLEib5jycnJWLlyJf7yl7/gN7/5DV599dVB/wxEREQjCRN5IiKiEHrllVfgcrkwa9Ys/PWvf8XJkydRWlqKv/zlLzh16lSPo9N33XUXdDodVq5ciWPHjmHr1q343ve+h29961tITU31tXM4HLj33ntx4sQJbNiwAU899RRWr14NhUKB+Ph4JCYm4tVXX0VZWRk+/fRTPPzwwwOKv6SkBCtWrMB7772HEydOoKysDP/93/+N1157DStWrAAApKSkQK/XY9OmTaitrUVraysATzX9559/Hr/97W9x+vRpHD16FK+//jpeeuklv+/x8ssvY/369Th16hRWrVqF5uZmfPvb3wYAPPnkk3j//fdRVlaG48eP48MPP/RL8omIiIhT64mIiEJq3LhxOHToEH7xi1/g8ccfx4ULF6DVajFp0iT88Ic/xIMPPhjwcQaDAf/4xz/w0EMP4dprr4XBYMA3vvGNq5LgRYsWoaCgAAsXLoTdbscdd9yBp59+GgCgUCiwdu1afP/738eUKVNQWFiI3/72t37bw/UlKysLY8eOxTPPPOPbLs779f/7f/8PgGdd+29/+1s8++yzePLJJ7FgwQJs27YN3/nOd2AwGPDiiy/i0UcfRUxMDKZOnYof/OAHft/jhRdewAsvvICSkhLk5+fjgw8+8FWm12g0ePzxx3Hu3Dno9XosWLAAa9eu7Xf8REREo4EkhBDhDoKIiIhGvnPnziE3NxeHDh3C9OnTwx0OERFR1OLUeiIiIiIiIqIowkSeiIiIiIiIKIpwaj0RERERERFRFOGIPBEREREREVEUYSJPREREREREFEWYyBMRERERERFFESbyRERERERERFGEiTwRERERERFRFGEiT0RERERERBRFmMgTERERERERRREm8kRERERERERR5P8D4zNaLYbX0ooAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# 3. 모델 테스트"],"metadata":{"id":"3dAR7Pqxk2pp"}},{"cell_type":"code","source":["# ---------- 장치/토크나이저 ----------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","sp = spm.SentencePieceProcessor(); sp.load(str(SPM_DIR/\"spm.model\"))\n","VOCAB_SIZE = sp.get_piece_size()\n","\n","d_model, n_layers, n_head = 512, 6, 8\n","d_k = d_v = d_model // n_head\n","d_hid, dropout = 2048, 0.1\n","n_tokens = 100  # not critical at inference as long as >= max len\n","\n","# You must have the Transformer class defined (from your training code).\n","# If it's in a module file, you can: from your_module import Transformer\n","\n","model = Transformer(\n","    n_src_vocab=VOCAB_SIZE, n_tgt_vocab=VOCAB_SIZE, pad_idx=PAD_ID,\n","    d_word_vec=d_model, d_model=d_model, d_hid=d_hid, n_layers=n_layers,\n","    n_head=n_head, d_k=d_k, d_v=d_v, dropout=dropout, n_tokens=n_tokens,\n","    tgt_emb_prj_weight_sharing=True, emb_src_tgt_weight_sharing=True,\n","    scale_emb_or_prj=\"prj\"\n",").to(device)\n","model.eval()\n","\n","# pick best.pt if present, else latest.pt\n","ckpt_path = CKPT_DIR / (\"best.pt\" if (CKPT_DIR / \"best.pt\").exists() else \"latest.pt\")\n","assert ckpt_path.exists(), f\"Checkpoint not found: {ckpt_path}\"\n","state = torch.load(str(ckpt_path), map_location=device)\n","model.load_state_dict(state[\"model\"])\n","print(f\"Loaded checkpoint: {ckpt_path.name}, global_step={state.get('global_step','?')}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecz05ICPldC_","executionInfo":{"status":"ok","timestamp":1761298734628,"user_tz":-540,"elapsed":2268,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"a17fa1b7-8206-48ad-8878-22d44aa94961"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded checkpoint: best.pt, global_step=286578\n"]}]},{"cell_type":"code","source":["# ------- (5) Greedy decoding -------\n","@torch.no_grad()\n","def translate(text: str, max_len: int = 100, print_tokens: bool = True):\n","    \"\"\"\n","    Because you trained a joint BPE (shared vocab), both directions work without tags,\n","    but quality may vary depending on training mixture.\n","    \"\"\"\n","    # 1) Source encode (BOS/EOS added)\n","    src_ids = [BOS_ID] + sp_encode(text) + [EOS_ID]\n","    src = torch.tensor(src_ids, dtype=torch.long, device=device).unsqueeze(0)  # [1,S]\n","    S = src.size(1)\n","\n","    # 2) Masks for encoder\n","    src_lens = torch.tensor([S], device=device)\n","    src_pad = make_padding_mask(src_lens, S, device=device)    # [1,S]\n","    src_mask = src_pad.unsqueeze(1).unsqueeze(2)               # [1,1,1,S]\n","\n","    # 3) Start decoding with BOS\n","    tgt = torch.tensor([[BOS_ID]], dtype=torch.long, device=device)  # [1,1]\n","\n","    for _ in range(max_len):\n","        T = tgt.size(1)\n","        # Build decoder masks per step\n","        tgt_pad = make_padding_mask(torch.tensor([T], device=device), T, device=device) # all False\n","        causal  = make_causal_mask(T, device=device)\n","        tgt_mask = (tgt_pad.unsqueeze(1).unsqueeze(2) | causal.unsqueeze(0).unsqueeze(1))  # [1,1,T,T]\n","        mem_mask = src_pad.unsqueeze(1).unsqueeze(2).expand(1,1,T,S)                       # [1,1,T,S]\n","\n","        # Forward\n","        logits = model(src, tgt, src_mask, tgt_mask, mem_mask, return_attns=False)  # [1,T,V]\n","        next_token = int(logits[0, -1].argmax(dim=-1).item())\n","\n","        # Append\n","        tgt = torch.cat([tgt, torch.tensor([[next_token]], device=device)], dim=1)\n","\n","        if next_token == EOS_ID:\n","            break\n","\n","    out_ids = tgt[0].tolist()  # [BOS, ..., EOS]\n","    # strip BOS/EOS and decode\n","    decoded = sp_decode(out_ids)\n","    if print_tokens:\n","        print(f\"src: {text}\")\n","        print(f\"out_ids: {out_ids}\")\n","    return decoded\n","\n","# ------- (6) Quick smoke test -------\n","print(\"Ready. Example:\")\n","# === Translation Test Sentences (for your model) ===\n","\n","# === Translation Test Sentences (EN → KO) ===\n","print(translate(\"I woke up late because my alarm didn’t go off this morning.\"))\n","print(translate(\"The professor explained the algorithm in a way that was surprisingly easy to understand.\"))\n","print(translate(\"If it rains tomorrow, we might have to cancel the outdoor event.\"))\n","print(translate(\"Artificial intelligence is changing the way people learn and work.\"))\n","print(translate(\"I couldn’t decide whether to buy the laptop or wait for the new model.\"))\n","print(translate(\"She smiled as if she already knew the answer.\"))\n","print(translate(\"This project aims to improve energy efficiency in public schools.\"))\n","print(translate(\"The movie was much better than I expected, especially the ending.\"))\n","print(translate(\"Data security has become one of the most important issues in the digital age.\"))\n","print(translate(\"Don’t forget to back up your files before you reinstall the system.\"))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Im9ujHm7kzfJ","executionInfo":{"status":"ok","timestamp":1761298956110,"user_tz":-540,"elapsed":1689,"user":{"displayName":"이민섭","userId":"15860324451243121926"}},"outputId":"2dad6359-d8ad-4929-870d-97b0cdcca91c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ready. Example:\n","src: I woke up late because my alarm didn’t go off this morning.\n","out_ids: [1, 1852, 14398, 1613, 1182, 636, 4424, 14921, 12257, 9151, 15350, 829, 14900, 2]\n","오늘 아침에 농사가 안 내려서 늦게 일어났어요.\n","src: The professor explained the algorithm in a way that was surprisingly easy to understand.\n","out_ids: [1, 3450, 15335, 14925, 10871, 15056, 2883, 14911, 14565, 10286, 3817, 14946, 15574, 14910, 2876, 14900, 2]\n","교수님은 놀라운 이해가 쉬운 방법으로 알고리즘을 설명했다.\n","src: If it rains tomorrow, we might have to cancel the outdoor event.\n","out_ids: [1, 4541, 7497, 535, 14988, 12744, 6301, 3600, 4946, 1450, 868, 2652, 1234, 14900, 2]\n","내일 비가 오면 야외 이벤트를 취소해야 할 수도 있습니다.\n","src: Artificial intelligence is changing the way people learn and work.\n","out_ids: [1, 11196, 14904, 3677, 14462, 478, 390, 14322, 8223, 14917, 410, 14900, 2]\n","인공지능이 사람들이 배우고 일하는 방식을 바꾸고 있다.\n","src: I couldn’t decide whether to buy the laptop or wait for the new model.\n","out_ids: [1, 759, 15060, 15152, 14910, 3230, 13527, 10543, 2355, 4643, 14910, 4078, 15371, 1380, 428, 1023, 1059, 2564, 14900, 2]\n","노트북을 구매할지 아니면 새로운 모델을 기다릴지는 정하지 못했습니다.\n","src: She smiled as if she already knew the answer.\n","out_ids: [1, 5326, 3048, 14910, 2417, 3817, 524, 7130, 5420, 723, 14900, 2]\n","그녀는 답을 이미 알고 있는 것처럼 웃었다.\n","src: This project aims to improve energy efficiency in public schools.\n","out_ids: [1, 310, 9672, 2814, 1803, 14912, 6261, 4272, 14910, 980, 4923, 1272, 14587, 14900, 2]\n","이 사업은 공공학교의 에너지 효율을 높이기 위한 사업이다.\n","src: The movie was much better than I expected, especially the ending.\n","out_ids: [1, 387, 13862, 1867, 1761, 2289, 12897, 7781, 766, 892, 15184, 14940, 14903, 1729, 2013, 14904, 12059, 14940, 14900, 2]\n","그 영화는 내가 기대했던 것보다 훨씬 더 좋았어, 특히 끝이 났어.\n","src: Data security has become one of the most important issues in the digital age.\n","out_ids: [1, 7597, 397, 3844, 5403, 7657, 14904, 1300, 4237, 8589, 456, 13208, 3351, 14900, 2]\n","디지털 시대에 데이터 보안이 가장 중요한 이슈 중 하나가 됐다.\n","src: Don’t forget to back up your files before you reinstall the system.\n","out_ids: [1, 10966, 1620, 14947, 806, 3836, 1139, 3959, 1797, 8606, 14915, 13728, 14900, 2]\n","시스템을 복원하기 전에 파일을 다시 잊지 마세요.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"IP7n1yDblfZo"},"execution_count":null,"outputs":[]}]}